## Updated on 2025.09.18
> Usage instructions: [here](./docs/README.md#usage)

<details>
<summary>Table of Contents</summary>
<ol>
  <li><a href=#多模态>多模态</a></li>
  <li><a href=#生成模型>生成模型</a></li>
  <li><a href=#大语言模型>大语言模型</a></li>
  <li><a href=#transformer>Transformer</a></li>
  <li><a href=#多模态大模型>多模态大模型</a></li>
  <li><a href=#大模型peft>大模型PEFT</a></li>
  <li><a href=#大模型强化学习>大模型强化学习</a></li>
</ol>
</details>

## 多模态

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-09-17**|[VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement](http://arxiv.org/abs/2509.14060)|null|目前的多目标跟踪（MOT）算法通常忽略低质量视频中固有的问题，导致在面对真实世界的图像劣化时，跟踪性能显著下降。因此，推进MOT算法在真实世界的低质量视频场景中的应用，是一项关键且有意义的工作。为了解决低质量场景带来的挑战，受视觉-语言模型的启发，本文提出了一种视觉语义增强引导的多目标跟踪框架（VSE-MOT）。具体来说，我们首先设计了一个三分支架构，利用视觉-语言模型从图像中提取全局视觉语义信息，并将其与查询向量融合。随后，为了进一步提高视觉语义信息的利用率，我们引入了多目标跟踪适配器（MOT-Adapter）和视觉语义融合模块（VSFM）。MOT-Adapter使提取的全局视觉语义信息适应多目标跟踪任务，而VSFM提高了特征融合的效率。通过大量的实验，我们验证了该方法在真实世界的低质量视频场景中的有效性和优越性。其跟踪性能指标优于现有方法约8%到20%，同时在传统场景中保持了稳健的性能。
|
|**2025-09-17**|[MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment](http://arxiv.org/abs/2509.14001)|null|我们介绍了MOCHA (多模态对象感知跨架构对齐)，这是一种知识蒸馏方法，可以将大型视觉-语言教师模型(例如，LLaVa)的区域级多模态语义迁移到轻量级的纯视觉对象检测器学生模型(例如，YOLO)。一个翻译模块将学生模型的特征映射到一个联合空间中，学生模型和翻译器的训练由一个双重目标损失函数引导，该函数同时强制执行局部对齐和全局关系一致性。与以往专注于密集或全局对齐的方法不同，MOCHA在对象级别上运行，从而能够在不修改教师模型或在推理时不需要文本输入的情况下高效地迁移语义。我们在四个个性化检测基准测试中，以少样本的方式验证了我们的方法。结果表明，相对于基线，我们的方法获得了持续的提升，平均得分提高了+10.1。尽管MOCHA的架构紧凑，但其性能可与更大的多模态模型相媲美，证明了其适用于现实世界的部署。
|
|**2025-09-17**|[Can Current AI Models Count What We Mean, Not What They See? A Benchmark and Systematic Evaluation](http://arxiv.org/abs/2509.13939)|null|视觉计数是一项基础但具有挑战性的任务，特别是当用户需要在复杂场景中计数特定类型的对象时。虽然最近的模型，包括类别无关的计数模型和大型视觉语言模型（VLMs），在计数任务中显示出希望，但它们执行细粒度、意图驱动的计数能力仍不清楚。在本文中，我们介绍PairTally，这是一个专门用于评估细粒度视觉计数的基准数据集。PairTally中的681张高分辨率图像中的每一张都包含两个对象类别，要求模型根据形状、大小、颜色或语义上的细微差异进行区分和计数。该数据集包括类别间（不同类别）和类别内（密切相关的子类别）设置，使其适用于严格评估选择性计数能力。我们对各种最先进的模型进行了基准测试，包括基于范例的方法、语言提示模型和大型VLM。我们的结果表明，尽管最近取得了进展，但当前的模型难以可靠地计数用户想要的内容，尤其是在细粒度和视觉模糊的情况下。PairTally为诊断和改进细粒度视觉计数系统提供了一个新的基础。
|
|**2025-09-17**|[EDITS: Enhancing Dataset Distillation with Implicit Textual Semantics](http://arxiv.org/abs/2509.13858)|null|数据集蒸馏旨在从原始的大规模数据集中合成一个紧凑的数据集，从而在保持具有竞争力的模型性能的同时，实现高效的学习。然而，传统技术主要捕获低层次的视觉特征，忽略了图像中固有的高层次语义和结构信息。在本文中，我们提出 EDITS，这是一个新颖的框架，它利用图像数据中隐含的文本语义来实现增强的蒸馏。首先，通过视觉语言模型（VLM）生成的外部文本通过全局语义查询模块与图像特征融合，形成先验聚类缓冲区。然后，局部语义感知从缓冲区中选择代表性样本，以构建图像和文本原型，其中后者是通过使用精心设计的提示指导大型语言模型（LLM）生成的。最终，双原型指导策略通过扩散模型生成最终的合成数据集。大量的实验证实了我们方法的有效性。源代码可在以下网址获取：https://github.com/einsteinxia/EDITS。
|
|**2025-09-17**|[Diving into Mitigating Hallucinations from a Vision Perspective for Large Vision-Language Models](http://arxiv.org/abs/2509.13836)|null|大型视觉语言模型（LVLMs）中的对象幻觉现象严重阻碍了它们在现实世界中的应用。作为精确解释视觉信息的主要组成部分，视觉编码器的选择至关重要。我们假设，不同视觉编码器所采用的多样化训练范式赋予了它们不同的归纳偏置，从而导致它们产生不同的幻觉表现。现有的基准测试通常侧重于粗粒度的幻觉检测，而未能捕捉到我们假设中阐述的各种幻觉。为了系统地分析这些影响，我们推出了VHBench-10，这是一个综合性的基准测试，包含约10,000个样本，用于评估LVLMs在十个细粒度幻觉类别中的表现。我们的评估证实，不同的编码器表现出独特的幻觉特征。基于这些见解以及简单特征融合的次优性，我们提出了一种新颖的上下文感知路由网络VisionWeaver。它利用全局视觉特征来生成路由信号，从而动态地聚合来自多个专业专家的视觉特征。全面的实验证实了VisionWeaver在显著减少幻觉和提高整体模型性能方面的有效性。
|
|**2025-09-17**|[VocSegMRI: Multimodal Learning for Precise Vocal Tract Segmentation in Real-time MRI](http://arxiv.org/abs/2509.13767)|null|准确分割实时磁共振成像(rtMRI)中的发音结构仍然具有挑战性，因为大多数现有方法几乎完全依赖于视觉线索。然而，同步的声学和音韵信号提供了补充上下文，可以丰富视觉信息并提高精度。在本文中，我们介绍VocSegMRI，这是一个多模态框架，通过交叉注意力融合整合视频、音频和音韵输入，以实现动态特征对齐。为了进一步增强跨模态表示，我们引入了一种对比学习目标，即使在推理时音频模态不可用，也能提高分割性能。在USC-75 rtMRI数据集的一个子集上进行评估，我们的方法实现了最先进的性能，Dice系数为0.95，第95百分位Hausdorff距离(HD_95)为4.20毫米，优于单模态和多模态基线。消融研究证实了交叉注意力和对比学习对分割精度和鲁棒性的贡献。这些结果突出了综合多模态建模对于准确声道分析的价值。
|
|**2025-09-16**|[Intelligent Healthcare Imaging Platform An VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation](http://arxiv.org/abs/2509.13590)|null|人工智能（AI）在医疗影像领域的快速发展彻底改变了诊断医学和临床决策过程。本文提出了一种智能多模态医学图像分析框架，该框架利用视觉-语言模型（VLMs）进行医疗诊断。该框架集成了谷歌Gemini 2.5 Flash，用于在包括CT、MRI、X射线和超声在内的多种成像模式中实现自动肿瘤检测和临床报告生成。该系统结合了视觉特征提取和自然语言处理，以实现上下文图像解释，结合坐标验证机制和概率高斯建模来分析异常分布。多层可视化技术生成详细的医学插图、叠加比较和统计表示，以增强临床信心，定位测量平均偏差达到80像素。结果处理利用精确的提示工程和文本分析来提取结构化的临床信息，同时保持可解释性。实验评估表明，该系统在多种模式下的异常检测中表现出高性能。该系统具有用户友好的Gradio界面，可用于临床工作流程集成，并展示了零样本学习能力，以减少对大型数据集的依赖。该框架代表了自动化诊断支持和放射科工作流程效率的显著进步，但在广泛采用之前，有必要进行临床验证和多中心评估。
|
|**2025-09-16**|[Using Visual Language Models to Control Bionic Hands: Assessment of Object Perception and Grasp Inference](http://arxiv.org/abs/2509.13572)|null|本研究探讨了利用视觉语言模型（VLMs）来提高半自主假肢手的感知能力的潜力。我们引入了一个统一的基准，用于端到端感知和抓取推理，评估单个VLM以执行传统上需要复杂流程的任务，这些流程具有用于对象检测、姿态估计和抓取规划的独立模块。为了确定这种方法的可行性和当前局限性，我们对八个当代VLM进行了基准测试，评估它们执行对仿生抓取至关重要的统一任务的能力。根据单个静态图像，它们应该（1）识别常见物体及其关键属性（名称、形状、方向和尺寸），以及（2）推断适当的抓取参数（抓取类型、腕部旋转、手部孔径和手指数量）。一个相应的提示，请求一个结构化的JSON输出，被用于一个包含34个常见物体快照的数据集。分析了关键性能指标，包括分类属性（例如，对象名称、形状）的准确性和数值估计（例如，尺寸、手部孔径）的误差，以及延迟和成本。结果表明，大多数模型在对象识别和形状识别方面表现出较高的性能，而在估计尺寸和推断最佳抓取参数（特别是手部旋转和孔径）方面的准确性则差异较大。这项工作强调了VLM作为半自主控制仿生肢体的高级感知模块的当前能力和局限性，展示了它们在有效假肢应用中的潜力。
|
|**2025-09-16**|[3D Aware Region Prompted Vision Language Model](http://arxiv.org/abs/2509.13317)|null|我们提出了空间区域3D（SR-3D）感知视觉-语言模型，该模型通过共享的视觉令牌空间连接单视图2D图像和多视图3D数据。SR-3D支持灵活的区域提示，允许用户使用边界框、任意帧上的分割掩码或直接在3D中注释区域，而无需详尽的多帧标注。我们通过使用3D位置嵌入来丰富2D视觉特征来实现这一点，这使得3D模型能够利用强大的2D先验知识，从而在帧之间进行更精确的空间推理，即使感兴趣的对象没有在同一视图中共同出现。在通用2D视觉语言和专门的3D空间基准上的大量实验表明，SR-3D实现了最先进的性能，突显了其在统一场景理解的2D和3D表示空间方面的有效性。此外，我们观察到该模型适用于没有感官3D输入或真实3D标注的真实视频，其中SR-3D可以准确地推断空间关系和度量测量。
|
|**2025-09-16**|[Image Realness Assessment and Localization with Multimodal Features](http://arxiv.org/abs/2509.13289)|null|量化人工智能生成图像的感知真实度并识别视觉不一致区域的可靠方法，对于人工智能生成图像的实际应用以及通过训练期间的真实度反馈来提高生成式人工智能的照片真实感至关重要。本文介绍了一个框架，该框架使用视觉-语言模型生成视觉不一致的文本描述来实现人工智能生成图像的整体客观真实度评估和局部不一致性识别，这些视觉-语言模型是在大型数据集上训练的，可以作为人类注释的可靠替代。我们的结果表明，所提出的多模态方法提高了客观真实度预测性能，并生成了密集的真实度图，有效地区分了真实和不真实的 spatial 区域。
|

<p align=right>(<a href="#updated-on-20250918">back to top</a>)</p>

## 生成模型

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-09-17**|[Defending Diffusion Models Against Membership Inference Attacks via Higher-Order Langevin Dynamics](http://arxiv.org/abs/2509.14225)|null|生成式人工智能应用的最新进展引发了新的数据安全问题。本文着重于防御扩散模型免受成员推理攻击。当攻击者可以确定某个数据点是否被用于训练模型时，就会发生此类攻击。尽管扩散模型本质上比其他生成模型更能抵抗成员推理攻击，但它们仍然容易受到攻击。本文提出的防御方法利用临界阻尼高阶朗之万动力学，该方法引入了几个辅助变量以及沿这些变量的联合扩散过程。其思想是，辅助变量的存在混合了外部随机性，这有助于在扩散过程的早期破坏敏感的输入数据。我们在玩具数据集和语音数据集上对这一概念进行了理论研究和验证，使用的指标包括受试者工作特征曲线下面积（AUROC）和FID指标。
|
|**2025-09-17**|[Active Inference Framework for Closed-Loop Sensing, Communication, and Control in UAV Systems](http://arxiv.org/abs/2509.14201)|null|集成感知与通信 (ISAC) 是 6G 的一项核心技术，其在闭环感知、通信和控制 (SCC) 中的应用能够实现各种服务。现有的 SCC 解决方案通常将感知和控制分开处理，导致次优的性能和资源利用率。在这项工作中，我们将主动推理框架 (AIF) 引入到支持 SCC 的无人机 (UAV) 系统中，以实现联合状态估计、控制和感知资源分配。通过构建统一的生成模型，该问题简化为最小化用于推理的变分自由能和用于动作规划的期望自由能。仿真结果表明，相对于基线，控制成本和感知成本均有所降低。
|
|**2025-09-17**|[Quantum Reinforcement Learning-Guided Diffusion Model for Image Synthesis via Hybrid Quantum-Classical Generative Model Architectures](http://arxiv.org/abs/2509.14163)|null|扩散模型通常采用静态或启发式无分类器引导（CFG）策略，这些策略通常无法适应不同的时间和噪声条件。在这项工作中，我们引入了一种量子强化学习（QRL）控制器，可以动态调整每个去噪步骤的CFG。该控制器采用混合量子-经典Actor-Critic架构：一个具有环形纠缠的浅层变分量子电路（VQC）生成策略特征，这些特征通过一个紧凑的多层感知器（MLP）映射到关于 $\Delta$ CFG的高斯动作，而一个经典Critic估计价值函数。该策略使用近端策略优化（PPO）和广义优势估计（GAE）进行优化，并由一个平衡分类置信度、感知改进和动作正则化的奖励函数引导。在CIFAR-10上的实验表明，与经典RL Actor和固定策略相比，我们的QRL策略提高了感知质量（LPIPS、PSNR、SSIM），同时减少了参数数量。对量子比特数和电路深度的消融研究揭示了准确性和效率之间的权衡，扩展评估证实了在长扩散策略下的稳健生成。
|
|**2025-09-17**|[MIMIC-D: Multi-modal Imitation for MultI-agent Coordination with Decentralized Diffusion Policies](http://arxiv.org/abs/2509.14159)|null|随着机器人与社会的融合日益加深，它们在多模态任务（具有多个有效解决方案的任务）中与其他机器人和人类进行协调的能力至关重要。我们建议通过模仿学习 (IL) 从专家演示中学习此类行为。然而，当专家演示是多模态时，标准的 IL 方法可能难以捕捉到多样化的策略，从而阻碍有效的协调。众所周知，扩散模型在处理单智能体系统中复杂的多模态轨迹分布方面非常有效。扩散模型在多智能体场景中也表现出色，在这些场景中，多模态更为常见，并且对于学习协调行为至关重要。通常，基于扩散的方法需要集中式规划器或智能体之间的显式通信，但这种假设在现实世界的场景中可能会失效，在这些场景中，机器人必须独立运行，或者与无法直接通信的人类等智能体一起运行。因此，我们提出了 MIMIC-D，一种用于多模态多智能体模仿学习的集中训练、分散执行 (CTDE) 范例，该范例使用扩散策略。智能体在充分信息的情况下联合训练，但仅使用本地信息执行策略以实现隐式协调。我们在仿真和硬件实验中证明，我们的方法可以在各种任务和环境中恢复智能体之间的多模态协调行为，同时优于最先进的基线方法。
|
|**2025-09-17**|[Supervised and Unsupervised Deep Learning Applied to the Majority Vote Model](http://arxiv.org/abs/2509.14155)|null|我们采用深度学习技术来研究多数投票模型中连续相变的关键性质。除了深度学习之外，还利用主成分分析来分析相变。对于监督学习，密集神经网络在通过动力学蒙特卡罗方法生成的自旋构型数据上进行训练。使用独立模拟的构型数据，神经网络可以准确地识别正方形和三角形格子上的临界点。使用主成分分析的经典无监督学习重现了磁化强度，并能够估计通常通过蒙特卡罗重要性抽样获得的临界指数。此外，使用变分自动编码器执行深度无监督学习，变分自动编码器重建输入自旋构型并生成人工输出。自动编码器通过损失函数检测相变，量化基本数据特征的保存。我们定义了真实数据和重建数据之间的相关函数，并发现该相关函数在临界点是通用的。变分自动编码器还可以作为生成模型，产生人工自旋构型。
|
|**2025-09-17**|[FlightDiffusion: Revolutionising Autonomous Drone Training with Diffusion Models Generating FPV Video](http://arxiv.org/abs/2509.14082)|null|我们提出了FlightDiffusion，这是一个基于扩散模型的框架，用于从第一人称视角（FPV）视频中训练自主无人机。我们的模型从单帧生成逼真的视频序列，并丰富了相应的动作空间，从而能够在动态环境中实现基于推理的导航。除了直接策略学习之外，FlightDiffusion还利用其生成能力来合成多样化的FPV轨迹和状态-动作对，从而无需高昂的真实世界数据收集成本即可创建大规模训练数据集。我们的评估表明，生成的轨迹在物理上是合理的并且可执行的，平均位置误差为0.25米（RMSE为0.28米），平均方向误差为0.19弧度（RMSE为0.24弧度）。这种方法能够改进策略学习和数据集可扩展性，从而在下游导航任务中实现卓越的性能。在模拟环境中的结果突出了增强的鲁棒性、更平滑的轨迹规划以及对未见条件的适应性。方差分析显示，模拟和现实环境中的性能之间没有统计学上的显著差异（F(1, 16) = 0.394, p = 0.541），成功率分别为M = 0.628 (SD = 0.162) 和M = 0.617 (SD = 0.177)，表明了强大的从模拟到真实的迁移能力。生成的数据集为未来的无人机研究提供了宝贵的资源。这项工作引入了基于扩散的推理，作为统一空中机器人导航、动作生成和数据合成的一种有前景的范例。
|
|**2025-09-17**|[RFM-Editing: Rectified Flow Matching for Text-guided Audio Editing](http://arxiv.org/abs/2509.14003)|null|扩散模型在文本到音频生成方面取得了显著进展。然而，文本引导的音频编辑仍处于早期阶段。此任务侧重于修改音频信号中的目标内容，同时保留其余部分，因此需要根据文本提示进行精确定位和忠实编辑。现有的基于训练和零样本方法依赖于完整字幕或昂贵的优化，通常难以处理复杂的编辑或缺乏实用性。在这项工作中，我们提出了一种新颖的端到端高效的基于修正流匹配的扩散框架用于音频编辑，并构建了一个具有重叠多事件音频的数据集，以支持复杂场景中的训练和基准测试。实验表明，我们的模型实现了忠实的语义对齐，而无需辅助字幕或掩码，同时在各项指标上保持了具有竞争力的编辑质量。
|
|**2025-09-17**|[Noise-Level Diffusion Guidance: Well Begun is Half Done](http://arxiv.org/abs/2509.13936)|null|扩散模型在图像生成方面取得了最先进的成果。然而，用于启动扩散过程的随机高斯噪声会影响最终输出，导致图像质量和提示词 соответствие 出现变化。现有的噪声水平优化方法通常依赖于额外的数据集构建、附加网络或基于反向传播的优化，从而限制了它们的实用性。在本文中，我们提出了一种简单、高效且通用的噪声水平优化方法，即噪声水平引导 (NLG)，它通过增加初始噪声与通用引导对齐的可能性来优化初始噪声，而无需额外的训练数据、辅助网络或反向传播。所提出的 NLG 方法提供了一个统一的框架，可以推广到条件和无条件扩散模型，并适应各种形式的扩散水平引导。在五个标准基准上的大量实验表明，我们的方法提高了输出生成质量和输入条件 соответствие。通过与现有引导方法无缝集成，同时保持计算效率，我们的方法将 NLG 确立为扩散模型的一种实用且可扩展的增强方法。代码可在 https://github.com/harveymannering/NoiseLevelGuidance 找到。
|
|**2025-09-17**|[Towards Robust Defense against Customization via Protective Perturbation Resistant to Diffusion-based Purification](http://arxiv.org/abs/2509.13922)|null|由于 Stable Diffusion 等扩散模型具有强大的定制功能，因此在视觉合成任务中变得突出，但也带来了重大的安全风险，包括深度伪造和侵犯版权。为了应对这种情况，出现了一类被称为保护性扰动的方法，它通过注入难以察觉的对抗性噪声来减轻图像的滥用。然而，净化可以去除保护性扰动，从而使图像再次暴露于恶意伪造的风险中。在这项工作中，我们正式确定了反净化任务，强调了阻碍现有方法的挑战，并提出了一种简单的诊断性保护性扰动，名为 AntiPure。AntiPure 暴露了“净化-定制”工作流程中净化的漏洞，这归功于两种引导机制：1) 分块频率引导，它减少了模型对净化图像中高频分量的影响；2) 错误的时间步长引导，它扰乱了模型在不同时间步长上的去噪策略。通过额外的引导，AntiPure 嵌入了在代表性的净化设置下持续存在的难以察觉的扰动，从而实现了有效的后定制失真。实验表明，作为净化的压力测试，AntiPure 实现了最小的感知差异和最大的失真，优于“净化-定制”工作流程中的其他保护性扰动方法。
|
|**2025-09-17**|[Inverse Design of Amorphous Materials with Targeted Properties](http://arxiv.org/abs/2509.13916)|null|无序（非晶）材料，如玻璃，正成为能量存储、非线性光学和催化等应用领域中极具前景的候选材料。它们缺乏长程有序性，且具有复杂的短程和中程有序结构，这些结构取决于成分以及热历史和压力历史，从而提供了广阔的材料设计空间。为此，依赖机器学习方法而不是反复试验是有希望的，在这些方法中，逆向设计已成为发现具有所需性能的新型材料的工具。尽管基于扩散模型的逆向设计方法已在晶体材料和分子方面显示出成功，但针对非晶材料的类似方法仍欠发达，这主要是由于缺乏大规模数据集以及对更大模拟单元的需求。在这项工作中，我们提出并验证了一种用于非晶材料的逆向设计方法，引入了AMDEN（非晶材料去噪网络），这是一个基于扩散模型的框架，用于生成非晶材料的结构。这些低能量构型通常是通过热运动驱动的类随机搜索过程获得的，而标准去噪程序无法复制该过程。因此，我们引入了一种基于能量的AMDEN变体，该变体实现了哈密顿蒙特卡洛精炼，用于生成这些弛豫结构。我们进一步引入了具有不同性质和成分的多个非晶材料数据集，以评估我们的框架并支持未来的发展。
|

<p align=right>(<a href="#updated-on-20250918">back to top</a>)</p>

## 大语言模型

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-09-10**|[FRIT: Using Causal Importance to Improve Chain-of-Thought Faithfulness](http://arxiv.org/abs/2509.13334)|**[link](https://github.com/Anut-py/frit)**|思维链 (CoT) 推理已成为提高大型语言模型在复杂任务中性能的强大工具，但最近的研究表明，推理步骤往往无法有效地影响最终答案，从而导致输出结果脆弱且不可信。以往的方法主要侧重于衡量忠实度，而系统性地提高忠实度的方法仍然有限。我们介绍了一种通过干预训练实现忠实推理的方法 (FRIT)，这是一种可扩展的对齐方法，通过学习系统性损坏的示例来训练模型以产生因果一致的推理。FRIT 通过干预模型生成的 CoT 中的单个推理步骤来生成合成训练数据，从而创建忠实/不忠实对，突出显示推理何时中断。然后，我们应用直接偏好优化来教导模型优先选择因果一致的推理路径。在 Qwen3-8B 和 Mistral-7B-v0.1 上，针对事实和符号推理任务进行评估，FRIT 将 Mistral 在 GSM8K 上的忠实推理提高了 $3.4$ 个百分点，同时将准确率提高了 $7.6$ 个百分点。我们的方法提供了第一个可扩展的、无监督的方法来训练语言模型以产生更可靠和可解释的推理，从而弥合了推理性能和可信度之间的关键差距。我们在 \href{https://github.com/Anut-py/frit} 上发布了我们的代码。
|
|**2025-09-14**|[FuseCodec: Semantic-Contextual Fusion and Supervision for Neural Codecs](http://arxiv.org/abs/2509.11425)|**[link](https://github.com/mubtasimahasan/FuseCodec)**|语音标记化实现了离散表示，并促进了语音语言建模。然而，现有的神经编解码器捕获的是低层次的声学特征，忽略了人类语音中固有的语义和上下文线索。尽管最近的研究尝试从自监督语音模型中引入语义表示，或结合来自预训练语言模型的上下文表示，但在对齐和统一语义和上下文表示方面仍然存在挑战。我们引入了FuseCodec，它通过强大的跨模态对齐和全局信息监督，统一了声学、语义和上下文表示。我们提出了三种互补技术：（i）潜在表示融合，将语义和上下文特征直接整合到编码器潜在空间中，以实现鲁棒和统一的表示学习；（ii）全局语义-上下文监督，利用全局池化和广播的表示来监督离散标记，从而增强时间一致性和跨模态对齐；（iii）时间对齐的上下文监督，通过在局部窗口内动态匹配上下文和语音标记来加强对齐，以实现细粒度的标记级监督。我们进一步介绍了FuseCodec-TTS，展示了我们的方法论在零样本语音合成中的适用性。在实验上，FuseCodec在LibriSpeech上实现了最先进的性能，在转录准确率、感知质量、可懂度和说话人相似度方面超过了EnCodec、SpeechTokenizer和DAC。结果突出了上下文和语义引导的标记化对于语音标记化和下游任务的有效性。代码和预训练模型可在https://github.com/mubtasimahasan/FuseCodec获取。
|
|**2025-09-14**|[RanAT4BIE: Random Adversarial Training for Biomedical Information Extraction](http://arxiv.org/abs/2509.11191)|null|我们介绍随机对抗训练（RAT），这是一种已成功应用于生物医学信息抽取（BioIE）任务的新颖框架。我们的研究以PubMedBERT作为基础架构，首先验证了传统对抗训练在增强预训练语言模型在BioIE任务上的性能方面的有效性。虽然对抗训练在各种性能指标上产生了显著的改进，但它也带来了相当大的计算开销。为了解决这个限制，我们提出了RAT作为生物医学信息抽取的效率解决方案。该框架巧妙地将随机抽样机制与对抗训练原则相结合，实现了双重目标：增强模型泛化能力和鲁棒性，同时显著降低计算成本。通过全面的评估，RAT在BioIE任务中表现出优于基线模型的性能。结果突显了RAT作为生物医学自然语言处理的变革性框架的潜力，为模型性能和计算效率提供了平衡的解决方案。
|
|**2025-09-11**|[Probing Pre-trained Language Models on Code Changes: Insights from ReDef, a High-Confidence Just-in-Time Defect Prediction Dataset](http://arxiv.org/abs/2509.09192)|null|即时软件缺陷预测（JIT-SDP）在代码审查和持续集成过程中，对于优先处理有风险的代码变更起着关键作用。然而，现有的数据集通常存在标签噪声和识别引入错误的提交的精度较低的问题。为了解决这个问题，我们提出了ReDef（基于回退的缺陷数据集），这是一个高置信度的函数级别修改基准，从22个大型C/C++项目中整理而来。缺陷案例以回退提交为锚定，而干净案例则通过事后历史检查进行验证。模糊实例通过GPT辅助的分类过程进行保守过滤，该过程涉及多次投票和审计。该流程产生了3,164个缺陷修改和10,268个干净修改，提供了比以往现有资源更可靠的标签。除了数据集构建之外，我们还首次系统地评估了预训练语言模型（PLM）如何推理代码修改——特别是，哪种输入编码最有效地暴露了变更信息，以及模型是否真正捕获了编辑语义。我们使用五种编码策略对CodeBERT、CodeT5+和UniXcoder进行了微调，并通过交换添加/删除块、反转diff极性或注入虚假标记的反事实扰动来进一步探测它们的敏感性。我们的结果表明，紧凑的diff风格编码在所有PLM中始终优于整个函数格式，统计测试证实了大型的、模型独立的影响。然而，在反事实测试下，性能几乎没有下降或根本没有下降——表明表面上的鲁棒性实际上反映了对表面线索的依赖，而不是真正的语义理解。这些发现表明，与基于快照的任务不同，当前的PLM在真正理解代码修改的能力方面仍然有限。
|
|**2025-09-08**|[Neurocognitive Modeling for Text Generation: Deep Learning Architecture for EEG Data](http://arxiv.org/abs/2509.07202)|null|随着大型语言模型（LLMs）的引入，文本生成能力经历了巨大的转变。然而，基于脑电图（EEG）的文本生成仍然具有挑战性，因为它需要大量的数据和处理能力。本文介绍了一种新方法，该方法结合了Gemma 2B LLM与分类器-LLM架构的使用，以整合循环神经网络（RNN）编码器。我们的方法显著降低了所需的数据量和计算能力，同时实现了接近最先进方法的性能。值得注意的是，与当前的方法相比，我们的方法提供了10%的整体性能提升。所提出的架构展示了脑电图文本生成有效迁移学习的可能性，即使在数据限制的情况下也能保持强大和功能性。这项工作强调了将LLM与脑电图解码相结合以改进辅助技术，并提高严重运动障碍患者的独立性和沟通能力的潜力。我们的方法通过有效地利用预训练语言模型的优势，突破了当前能力的限制，并为脑机接口的研究和应用开辟了新的途径。这使得基于脑电图的文本生成更易于访问和高效。
|
|**2025-09-08**|[TableMind: An Autonomous Programmatic Agent for Tool-Augmented Table Reasoning](http://arxiv.org/abs/2509.06278)|null|表格推理对于在金融、医疗保健和科学研究等领域利用结构化数据至关重要。虽然大型语言模型（LLM）在多步骤推理中显示出前景，但纯粹基于文本的方法通常难以应对此任务中固有的复杂数值计算和细粒度操作。工具集成推理通过显式代码执行来提高计算准确性，但现有系统经常依赖于僵化的模式、监督模仿，并且缺乏真正的自主适应性。在本文中，我们提出 TableMind，这是一种由 LLM 驱动的表格推理代理，它 (i) 自主执行多轮工具调用，(ii) 在安全沙箱环境中编写和执行数据分析代码，以进行数据分析和精确的数值推理，以及 (iii) 表现出诸如计划和自我反思等高级能力以适应策略。为了实现这些能力，我们采用了一种建立在强大的预训练语言模型之上的两阶段微调范式：首先，在高质量推理轨迹上进行监督微调，以建立有效的工具使用模式；然后，进行强化微调以优化多目标策略。特别地，我们提出了排名感知策略优化（RAPO），当高质量轨迹的输出概率低于低质量轨迹时，该方法会增加高质量轨迹的更新权重，从而更一致地引导模型朝着更好、更准确的答案发展。在几个主流基准上的大量实验表明，与具有竞争力的基线相比，TableMind 实现了卓越的性能，从而在推理准确性和计算精度方面都获得了显着提高。
|
|**2025-09-06**|[New Insights into Optimal Alignment of Acoustic and Linguistic Representations for Knowledge Transfer in ASR](http://arxiv.org/abs/2509.05609)|null|对齐声学和语言表示是弥合自动语音识别（ASR）中知识迁移的预训练模型的中心挑战。这种对齐本质上是结构化的和非对称的：虽然多个连续的声学帧通常对应于单个语言标记（多对一），但某些声学转换区域可能与多个相邻标记相关（一对多）。此外，声学序列通常包括没有语言对应部分的帧，例如背景噪声或静音可能导致不平衡的匹配条件。在这项工作中，我们采取了一种新的视角，将对齐和匹配视为一个检测问题，其目标是以高精度和召回率识别有意义的对应关系，确保语言标记的完全覆盖，同时灵活地处理冗余或嘈杂的声学帧，以便在ASR中迁移语言知识。基于这种新的视角，我们提出了一种基于不平衡最优传输的对齐模型，该模型通过声学和语言模态之间的软匹配和部分匹配，显式地处理分布不匹配和结构不对称性。我们的方法确保每个语言标记都至少以一个声学观察为基础，同时允许从声学单元到语言单元的灵活的概率映射。我们通过在基于CTC的ASR系统上使用预训练语言模型进行知识迁移的实验来评估我们提出的模型。实验结果表明了我们的方法在灵活控制匹配程度从而提高ASR性能方面的有效性。
|
|**2025-08-31**|[Speaker-Conditioned Phrase Break Prediction for Text-to-Speech with Phoneme-Level Pre-trained Language Model](http://arxiv.org/abs/2509.00675)|null|本文旨在提升多说话人文本转语音（TTS）系统中短语停顿预测（也称为断句）的性能。我们通过利用说话人嵌入来整合说话人特定的特征，从而增强断句模型的效果。我们进一步证明，这些说话人嵌入可以仅从断句任务中捕获与说话人相关的特征。此外，我们通过少样本自适应方法探索了预训练说话人嵌入对未见说话人的潜力。更重要的是，我们率先将音素级别的预训练语言模型应用于此TTS前端任务，从而显著提高了断句模型的准确性。我们的方法通过客观和主观评估进行了严格的评估，证明了其有效性。
|
|**2025-08-31**|[SEAL: Structure and Element Aware Learning to Improve Long Structured Document Retrieval](http://arxiv.org/abs/2508.20778)|null|在长结构化文档检索中，现有方法通常使用对比学习在缺乏显式结构信息的数据集上微调预训练语言模型（PLM）。这种做法存在两个关键问题：1）当前方法未能有效利用结构特征和元素级语义；2）缺乏包含结构元数据的数据集。为了弥合这些差距，我们提出了\our，一种新颖的对比学习框架。它利用结构感知学习来保留语义层次结构，并利用掩码元素对齐来实现细粒度的语义区分。此外，我们发布了\dataset，一个具有丰富结构注释的长结构化文档检索数据集。在已发布和工业数据集上对各种现代PLM进行的大量实验，以及在线A/B测试，表明性能持续提升，在BGE-M3上将NDCG@10从73.96\%提高到77.84\%。相关资源可在https://github.com/xinhaoH/SEAL获取。
|
|**2025-08-28**|[Adaptive Federated Distillation for Multi-Domain Non-IID Textual Data](http://arxiv.org/abs/2508.20557)|**[link](https://github.com/jiahaoxiao1228/AdaFD)**|预训练语言模型的广泛成功建立了一种新的训练范式，即使用来自本地客户端的特定任务数据对全局PLM进行微调。本地数据彼此高度不同，无法捕捉现实世界中整个数据的全局分布。为了解决真实环境中非独立同分布（non-IID）数据的挑战，已经提出了保护隐私的联邦蒸馏并对其进行了深入研究。然而，以往的实验性非独立同分布场景主要通过标签（输出）多样性来识别，而没有考虑在自然语言处理中至关重要的语言领域（输入）的多样性。在本文中，我们引入了一套全面的多领域非独立同分布场景，并提出了一个包含多样化数据的统一基准测试框架。该基准可用于评估真实环境中的联邦学习框架。为此，我们提出了一个自适应联邦蒸馏（AdaFD）框架，旨在解决同构和异构设置中的多领域非独立同分布挑战。实验结果表明，我们的模型能够捕捉本地客户端的多样性，并取得比现有工作更好的性能。本文的代码可在以下网址获取：https://github.com/jiahaoxiao1228/AdaFD。
|

<p align=right>(<a href="#updated-on-20250918">back to top</a>)</p>

## Transformer

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-09-17**|[An Attention-Based Stochastic Simulator for Multisite Extremes to Evaluate Nonstationary, Cascading Flood Risk](http://arxiv.org/abs/2509.14162)|null|时空聚集的极端事件造成的复合洪水风险对传统风险模型和保险组合提出了挑战，这些模型通常忽略了区域间的相关风险。时空聚集的洪水表现出肥尾行为，受到低频水文气候变率和大规模水汽输送的调节。非平稳随机模拟器和区域复合事件模型旨在捕捉这种尾部风险，但尚未将空间和时间极端事件在低频水文气候变率下统一起来。我们引入了一种新颖的基于注意力机制的框架，用于多站点洪水生成，该框架以多元水文气候信号为条件，并可解释地归因于全球次年代际到多年代际气候变率。我们的模拟器结合了小波信号处理、基于Transformer的多元时间序列预测和改进的Neyman-Scott联合聚类，以模拟气候驱动的具有空间复合性和时间级联性的洪水。应用于密西西比河流域的案例研究表明，该模型生成了在空间和时间上合理聚集的分布式洪水风险组合，为模拟洪水引起的损失所特有的时空相关损失提供了基础。
|
|**2025-09-17**|[SV-Mixer: Replacing the Transformer Encoder with Lightweight MLPs for Self-Supervised Model Compression in Speaker Verification](http://arxiv.org/abs/2509.14136)|null|自监督学习（SSL）已将说话人验证的准确率提升到接近最先进水平，但大多数SSL编码器中使用的Transformer主干网络阻碍了设备端和实时部署。先前的压缩工作削减了层深度或宽度，但仍然继承了自注意力的二次方成本。我们提出了SV-Mixer，这是第一个用于SSL知识蒸馏的完全基于MLP的学生编码器。SV-Mixer用三个轻量级模块替换了Transformer：用于多分辨率时间特征的多尺度混合、用于帧到语句上下文的局部-全局混合，以及用于频谱子空间的分组通道混合。从WavLM蒸馏而来，SV-Mixer的性能优于Transformer学生14.6%，同时将参数和GMAC减少了一半以上，并且在75%的压缩率下，它与教师模型的性能非常接近。我们的结果表明，无注意力机制的SSL学生可以在硬件友好的占用空间内提供教师级别的准确率，从而为强大的设备端说话人验证打开了大门。
|
|**2025-09-16**|[B-TGAT: A Bi-directional Temporal Graph Attention Transformer for Clustering Multivariate Spatiotemporal Data](http://arxiv.org/abs/2509.13202)|null|对高维多元时空气候数据进行聚类具有挑战性，因为其时间依赖关系复杂、空间交互作用不断演变以及动力学过程具有非平稳性。包括循环模型和卷积模型在内的传统聚类方法，通常难以在保留空间背景的同时，捕捉局部和全局的时间关系。我们提出了一种时间分布式的混合U-Net自编码器，该编码器集成了一个双向时间图注意力Transformer (B-TGAT)，以指导多维时空气候数据集的有效时间聚类。编码器和解码器配备了ConvLSTM2D模块，通过对局部动态和随时间变化的空间相关性进行建模来提取联合时空特征，并且跳跃连接在特征压缩和重构期间保留了多尺度空间细节。在瓶颈处，B-TGAT将基于图的空间建模与注意力驱动的时间编码相结合，从而能够自适应地对时间邻居进行加权，并捕获跨区域的短期和长期依赖关系。这种架构产生了判别性潜在嵌入，这些嵌入针对聚类进行了优化。在三个不同的时空气候数据集上的实验表明，与最先进的基线相比，该方法具有卓越的聚类可分离性、时间稳定性和与已知气候转变的对齐性。ConvLSTM2D、U-Net跳跃连接和B-TGAT的集成增强了时间聚类性能，同时为复杂时空变异性提供了可解释的见解，从而推动了方法论发展和气候科学应用。
|
|**2025-09-16**|[Runge-Kutta Approximation and Decoupled Attention for Rectified Flow Inversion and Semantic Editing](http://arxiv.org/abs/2509.12888)|null|整流流（RF）模型最近表现出比基于DDIM的扩散模型更优越的生成性能。然而，在实际应用中，它们面临两个主要挑战：（1）反演精度低，这妨碍了与源图像的一致性，以及（2）扩散Transformer中纠缠的多模态注意力，这妨碍了精确的注意力控制。为了解决第一个挑战，我们提出了一种基于微分方程Runge-Kutta求解器的整流流模型的高效高阶反演方法。为了解决第二个挑战，我们引入了解耦扩散Transformer注意力（DDTA），这是一种新颖的机制，可在多模态扩散Transformer内部解耦文本和图像注意力，从而实现更精确的语义控制。在图像重建和文本引导编辑任务上的大量实验表明，我们的方法在保真度和可编辑性方面均达到了最先进的性能。代码可在https://github.com/wmchen/RKSovler_DDTA上获取。
|
|**2025-09-16**|[SAGA: Selective Adaptive Gating for Efficient and Expressive Linear Attention](http://arxiv.org/abs/2509.12817)|null|虽然Transformer架构在建模远程依赖关系方面表现出色，并因此被广泛应用于视觉任务，但基于softmax的注意力机制的二次复杂度构成了一个主要的瓶颈，特别是在处理高分辨率图像时。线性注意力通过将注意力计算从 $(QK)V$重新 формулировка为$Q(KV)$，从而将复杂度从$\mathcal{O}(N^2)$降低到$\mathcal{O}(N)$，同时保留全局感受野，这提供了一个有希望的替代方案。然而，大多数现有方法均匀地压缩历史键值(KV)信息，这可能导致特征冗余和与查询(Q)的方向对齐的丢失。这种均匀压缩导致低秩$KV$特征图，导致与softmax注意力相比存在性能差距。为了缓解这个限制，我们提出了用于高效和富有表现力的线性注意力的\textbf{S}选择性\textbf{A}自适应\textbf{GA}门控(SAGA)，它引入了输入自适应可学习门来选择性地调节信息聚合到$KV$特征图中。这些门增强了语义多样性，并缓解了传统线性注意力中固有的低秩约束。此外，我们提出了一种用于门计算的有效Hadamard积分解方法，该方法不引入额外的内存开销。实验表明，在$1280 \times 1280$ 的分辨率下，与PVT-T相比，SAGA的吞吐量提高了1.76倍，峰值GPU内存减少了2.69倍。此外，它在ImageNet数据集上将top-1准确率提高了高达4.4％，证明了计算效率和模型有效性。
|
|**2025-09-16**|[BATR-FST: Bi-Level Adaptive Token Refinement for Few-Shot Transformers](http://arxiv.org/abs/2509.12768)|null|Vision Transformer (ViT) 在计算机视觉应用中展现出巨大的潜力。然而，它们在少样本学习中的性能受到一些挑战的限制，包括难以优化令牌级别的交互、难以处理有限的训练数据，以及难以发展出强大的归纳偏置。现有方法通常依赖于不灵活的令牌匹配或基本的相似性度量，这限制了全局上下文的有效整合和局部特征的优化。为了应对这些挑战，我们提出了一种用于少样本Transformer的双层自适应令牌优化方法 (BATR-FST)，这是一种两阶段方法，可以逐步改进令牌表示，并为少样本分类保持强大的归纳偏置。在预训练阶段，掩码图像建模 (MIM) 通过重建掩码图像区域，为 Vision Transformer (ViT) 提供可迁移的patch级别表示，为后续的自适应提供稳健的基础。在元微调阶段，BATR-FST 结合了一个双层自适应令牌优化模块，该模块利用令牌聚类来捕获局部交互，利用不确定性感知令牌加权来优先考虑可靠的特征，并利用双层注意力机制来平衡簇内和簇间的关系，从而促进彻底的令牌优化。此外，图令牌传播确保了支持实例和查询实例之间的语义一致性，而类别分离惩罚则保留了不同的类别边界，从而增强了判别能力。在三个基准少样本数据集上的大量实验表明，BATR-FST 在 1-shot 和 5-shot 场景中均取得了优异的成果，并通过 Transformer 改进了少样本分类。
|
|**2025-09-16**|[NEFT: A Unified Transformer Framework for Efficient Near-Field CSI Feedback in XL-MIMO Systems](http://arxiv.org/abs/2509.12748)|null|超大规模多输入多输出 (XL-MIMO) 系统由于其庞大的天线阵列而在近场区域运行，是下一代无线通信的关键推动者，但在信道状态信息 (CSI) 反馈方面面临重大挑战。深度学习已成为一种强大的工具，通过学习紧凑的 CSI 表示来进行反馈。然而，现有方法难以捕捉近场 CSI 的复杂结构，同时在实际移动设备上产生过高的计算开销。为了克服这些限制，我们提出了近场高效反馈 Transformer (NEFT) 系列，用于在各种硬件平台上进行准确高效的近场 CSI 反馈。NEFT 构建在分层 Vision Transformer 主干网络之上，并通过轻量级变体进行扩展，以满足各种部署约束：NEFT-Compact 应用多级知识蒸馏 (KD) 来降低复杂性，同时保持准确性，而 NEFT-Hybrid 和 NEFT-Edge 通过无注意力编码和 KD 来解决编码器和边缘受限的场景。大量仿真表明，NEFT 在归一化均方误差 (NMSE) 方面比最先进的方法提高了 15-21 分贝，而 NEFT-Compact 和 NEFT-Edge 在总 FLOPs 方面降低了 25-36%，且精度损失可忽略不计。此外，NEFT-Hybrid 将编码器侧的复杂性降低了高达 64%，从而可以在高度不对称的设备场景中进行部署。这些结果表明，NEFT 是 XL-MIMO 系统中近场 CSI 反馈的一种实用且可扩展的解决方案。
|
|**2025-09-17**|[Soft Graph Transformer for MIMO Detection](http://arxiv.org/abs/2509.12694)|null|我们提出了软图Transformer (SGT)，这是一种专为MIMO检测设计的软输入-软输出神经架构。虽然最大似然(ML)检测能实现最佳精度，但其指数级的复杂度使其在大型系统中不可行，并且传统的消息传递算法依赖于在有限维度中经常失效的渐近假设。最近的基于Transformer的检测器表现出强大的性能，但通常忽略MIMO因子图结构，并且无法利用先验软信息。SGT通过结合自注意力来解决这些限制，自注意力编码符号和约束子图中的上下文依赖关系，以及图感知的交叉注意力，其在子图之间执行结构化的消息传递。它的软输入接口允许集成辅助先验，产生有效的软输出，同时保持计算效率。实验表明，SGT实现了接近ML的性能，并为利用软先验的接收器系统提供了一个灵活且可解释的框架。
|
|**2025-09-15**|[LazyDrag: Enabling Stable Drag-Based Editing on Multi-Modal Diffusion Transformers via Explicit Correspondence](http://arxiv.org/abs/2509.12203)|null|依赖于通过注意力机制实现的隐式点匹配已成为基于拖拽编辑的核心瓶颈，导致在反演强度减弱和代价高昂的测试时优化（TTO）方面做出根本性妥协。这种妥协严重限制了扩散模型的生成能力，抑制了高保真图像修复和文本引导的创作。在本文中，我们介绍了LazyDrag，这是第一个用于多模态扩散Transformer的基于拖拽的图像编辑方法，它直接消除了对隐式点匹配的依赖。具体来说，我们的方法从用户拖拽输入中生成显式对应图，作为增强注意力控制的可靠参考。这种可靠的参考为稳定的全强度反演过程开辟了潜力，这在基于拖拽的编辑任务中尚属首次。它避免了对TTO的需求，并释放了模型的生成能力。因此，LazyDrag自然地将精确的几何控制与文本引导相结合，从而实现了以前无法实现的复杂编辑：张开狗的嘴并修复其内部，生成像“网球”这样的新对象，或者对于模糊的拖拽，进行上下文感知的更改，例如将手移入口袋。此外，LazyDrag支持具有同步移动和缩放操作的多轮工作流程。在DragBench上进行评估，我们的方法在拖拽准确性和感知质量方面均优于基线方法，这已通过VIEScore和人工评估得到验证。LazyDrag不仅建立了新的最先进性能，而且为编辑范式开辟了一条新途径。
|
|**2025-09-15**|[Dynamic Relational Priming Improves Transformer in Multivariate Time Series](http://arxiv.org/abs/2509.12196)|null|Transformer中的标准注意力机制采用静态的token表征，这些表征在每一层的所有成对计算中保持不变。这限制了它们与每个token对交互中可能存在的不同关系动态的表征对齐。虽然它们在关系相对同质的领域表现出色，但标准注意力的静态关系学习难以捕捉多元时间序列（MTS）数据的多样化、异构的通道间依赖关系——在多元时间序列数据中，单个系统内的不同通道对交互可能受完全不同的物理定律或时间动态支配。为了更好地使注意力机制与这种领域现象对齐，我们提出了具有动态关系启动的注意力（prime attention）。与标准注意力中每个token在所有成对交互中呈现相同表征不同，prime attention通过可学习的调制动态地（或每次交互）调整每个token，以最好地捕捉每个token对的独特关系动态，从而针对该特定关系优化每个成对交互。Prime attention的这种表征可塑性使得能够有效提取MTS中特定于关系的信息，同时保持与标准注意力相同的渐近计算复杂度。我们的结果表明，prime attention在各项基准测试中始终优于标准注意力，在预测准确率方面提高了高达6.5%。此外，我们发现与标准注意力相比，prime attention在使用减少高达40%的序列长度时，实现了相当或更优越的性能，进一步证明了其卓越的关系建模能力。
|

<p align=right>(<a href="#updated-on-20250918">back to top</a>)</p>

## 多模态大模型

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-09-17**|[AssoCiAm: A Benchmark for Evaluating Association Thinking while Circumventing Ambiguity](http://arxiv.org/abs/2509.14171)|null|多模态大型语言模型（MLLM）的最新进展受到了广泛关注，为实现通用人工智能（AGI）提供了一条有希望的途径。在AGI所需的关键能力中，创造力已成为MLLM的一项重要特征，而联想是其基础。联想反映了模型进行创造性思考的能力，因此对其进行评估和理解至关重要。虽然已经提出了几种评估联想能力的框架，但它们通常忽略了联想任务中固有的模糊性，这种模糊性源于联想的发散性，并削弱了评估的可靠性。为了解决这个问题，我们将模糊性分解为两种类型——内部模糊性和外部模糊性——并引入AssoCiAm，这是一个旨在评估联想能力同时通过混合计算方法规避模糊性的基准。然后，我们对MLLM进行了广泛的实验，揭示了认知和联想之间存在很强的正相关关系。此外，我们观察到评估过程中模糊性的存在导致MLLM的行为变得更加随机。最后，我们验证了我们的方法在确保更准确和可靠的评估方面的有效性。有关数据和代码，请参见项目页面。
|
|**2025-09-17**|[MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation](http://arxiv.org/abs/2509.13773)|null|生成式人工智能技术的快速发展正在推动各种人工智能驱动的服务集成到智能手机中，从而改变用户与设备交互的方式。为了简化对预定义人工智能服务的访问，本文介绍了一种开创性的任务指令推荐框架MIRA，它能够在智能手机上实现直观的一键式人工智能任务处理。借助MIRA，用户可以长按图像或文本对象，以接收上下文相关的指令推荐，从而执行人工智能任务。我们的工作引入了三个关键创新：1）基于多模态大型语言模型（MLLM）的推荐流程，该流程具有结构化推理能力，可以提取关键实体、推断用户意图并生成精确的指令；2）一种模板增强的推理机制，该机制集成了高级推理模板，从而提高了任务推断的准确性；3）一种基于前缀树的约束解码策略，该策略将输出限制为预定义的指令候选项，从而确保建议的一致性和意图对齐。通过使用真实世界的带注释数据集和用户研究进行评估，MIRA已证明在指令推荐的准确性方面有显著提高。令人鼓舞的结果突显了MIRA在彻底改变用户与智能手机上的人工智能服务交互方式方面的潜力，从而提供更无缝和高效的体验。
|
|**2025-09-17**|[Re-purposing SAM into Efficient Visual Projectors for MLLM-Based Referring Image Segmentation](http://arxiv.org/abs/2509.13676)|null|近年来，将多模态大型语言模型（MLLM）与万物分割模型（SAM）相结合的指称图像分割（RIS）框架取得了令人瞩目的成果。然而，由于视觉标记的冗余，使MLLM适应分割在计算上是密集型的。我们观察到，传统的基于图像块的视觉投影器难以在减少视觉标记数量和保持语义清晰度之间取得平衡，通常会保留过长的标记序列，以避免性能下降。受文本标记器的启发，我们提出了一种新颖的语义视觉投影器，该投影器利用SAM生成的语义超像素来识别图像中的“视觉词”。通过压缩和投影语义超像素作为视觉标记，我们的方法根据场景的复杂性自适应地缩短标记序列，同时最大限度地减少压缩过程中的语义损失。为了减轻信息损失，我们提出了一种语义超像素位置嵌入，以增强MLLM对超像素几何形状和位置的感知，以及一个语义超像素聚合器，以保留超像素内部的细粒度细节和外部的全局上下文。实验表明，我们的方法在不影响性能的前提下，将视觉标记减少了93%，显著加快了MLLM的训练和推理速度，并在RIS上优于现有的压缩视觉投影器。
|
|**2025-09-17**|[LLM-I: LLMs are Naturally Interleaved Multimodal Creators](http://arxiv.org/abs/2509.13642)|null|我们提出了LLM交错模型（LLM-I），这是一个灵活且动态的框架，它将交错的图文生成重构为一个工具使用问题。LLM-I旨在克服当前统一模型的“单工具”瓶颈，这些模型仅限于合成图像，并且难以处理需要事实依据或程序精确性的任务。我们的框架使中央LLM或MLLM代理能够智能地协调各种专业视觉工具，包括在线图像搜索、基于扩散的生成、代码执行和图像编辑。该代理经过训练，可以通过强化学习（RL）框架熟练地选择和应用这些工具，该框架具有混合奖励系统，该系统结合了基于规则的逻辑以及来自LLM和MLLM评估器的判断。LLM-I使用四种不同的模型骨干在各种新数据集上进行训练， демонстрирует展现了最先进的性能，在四个基准测试中大幅优于现有方法。我们还介绍了一种新颖的测试时缩放策略，可提供进一步的性能提升。项目页面：https://github.com/ByteDance-BandAI/LLM-I。
|
|**2025-09-16**|[Simulating Clinical AI Assistance using Multimodal LLMs: A Case Study in Diabetic Retinopathy](http://arxiv.org/abs/2509.13234)|null|糖尿病视网膜病变(DR)是全球范围内导致失明的主要原因之一，而人工智能系统可以扩大眼底照相筛查的范围。目前获得FDA批准的系统主要提供二元转诊结果，这种最简单的输出可能会限制临床信任和实用性。然而，确定提高临床医生-AI性能的最有效输出格式是一项经验性挑战，难以大规模评估。我们评估了多模态大型语言模型(MLLM)在DR检测中的应用，以及它们在不同输出类型中模拟临床AI辅助的能力。在IDRiD和Messidor-2数据集上测试了两个模型：GPT-4o（一种通用MLLM）和MedGemma（一种开源医疗模型）。实验包括：(1)基线评估，(2)使用合成预测模拟AI辅助，以及(3)实际的AI-AI协作，其中GPT-4o整合了MedGemma的输出。MedGemma在基线测试中优于GPT-4o，实现了更高的灵敏度和AUROC，而GPT-4o表现出接近完美的特异性，但灵敏度较低。两种模型都根据模拟的AI输入调整了预测，但GPT-4o的性能在出现不正确的输入时会崩溃，而MedGemma则保持更稳定。在实际协作中，GPT-4o在MedGemma的描述性输出指导下取得了良好的效果，即使没有直接的图像访问（AUROC高达0.96）。这些发现表明，MLLM可以改进DR筛查流程，并作为可扩展的模拟器，用于研究不同输出配置下的临床AI辅助。像MedGemma这样开放、轻量级的模型在资源匮乏的环境中可能特别有价值，而描述性输出可以增强临床工作流程中的可解释性和临床医生信任。
|
|**2025-09-16**|[MEJO: MLLM-Engaged Surgical Triplet Recognition via Inter- and Intra-Task Joint Optimization](http://arxiv.org/abs/2509.12893)|null|手术三元组识别，包括识别工具、动作、目标及其组合，是一个复杂的手术场景理解挑战，受到长尾数据分布的影响。受益于跨任务协同提升的主流多任务学习范式在识别三元组方面表现出 promising 的性能，但仍存在两个关键挑战：1) 纠缠任务通用和任务特定表示所导致的任务间优化冲突；2) 由于类不平衡训练数据而导致的任务内优化冲突。为了克服这些困难，我们提出了 MLLM 参与的联合优化 (MEJO) 框架，该框架增强了手术三元组识别的任务间和任务内优化。对于任务间优化，我们引入了共享-特定-解耦 (S $^2$ D) 学习方案，该方案将表示分解为任务共享和任务特定的组成部分。为了增强任务共享表示，我们构建了一个多模态大型语言模型 (MLLM) 驱动的概率提示池，以使用专家级语义线索动态增强视觉特征。此外，通过涵盖时空维度的不同任务提示来建模全面的任务特定线索，有效缓解了任务间歧义。为了解决任务内优化冲突，我们开发了一种协调梯度学习 (CGL) 策略，该策略剖析并重新平衡源自头部和尾部类别的正负梯度，以实现更协调的学习行为。在 CholecT45 和 CholecT50 数据集上的大量实验证明了我们提出的框架的优越性，验证了其在处理优化冲突方面的有效性。
|
|**2025-09-16**|[Lego-Edit: A General Image Editing Framework with Model-Level Bricks and MLLM Builder](http://arxiv.org/abs/2509.12883)|null|基于指令的图像编辑因其与用户的直接交互而备受关注。然而，现实世界中的用户指令极其多样化，现有方法通常无法有效地泛化到其训练领域之外的指令，从而限制了它们的实际应用。为了解决这个问题，我们提出了Lego-Edit，它利用多模态大型语言模型（MLLM）的泛化能力来组织一套模型级别的编辑工具，以应对这一挑战。Lego-Edit包含两个关键设计：（1）一个模型级别的工具包，包含在有限数据上有效训练的各种模型和多种图像处理功能，从而使MLLM能够对编辑动作进行细粒度的组合；（2）一种三阶段渐进式强化学习方法，该方法使用对未标注的开放领域指令的反馈来训练MLLM，使其具备处理现实世界指令的通用推理能力。实验表明，Lego-Edit在GEdit-Bench和ImgBench上实现了最先进的性能。它对开放领域指令表现出强大的推理能力，并且无需额外的微调即可使用新引入的编辑工具。代码可在以下网址获取：https://github.com/xiaomi-research/lego-edit。
|
|**2025-09-16**|[ActiveVLN: Towards Active Exploration via Multi-Turn RL in Vision-and-Language Navigation](http://arxiv.org/abs/2509.12618)|null|视觉语言导航（VLN）任务要求智能体遵循自然语言指令，并在复杂环境中导航。现有的基于MLLM的VLN方法主要依赖于模仿学习（IL），并且通常使用DAgger进行后训练以减轻协变量偏移。虽然这些方法有效，但会产生大量的数据收集和训练成本。强化学习（RL）提供了一种有希望的替代方案。然而，先前的VLN强化学习方法缺乏与环境的动态交互，并且依赖于专家轨迹进行奖励塑造，而不是进行开放式的主动探索。这限制了智能体发现多样化和合理的导航路线的能力。为了解决这些限制，我们提出了ActiveVLN，这是一个通过多轮强化学习显式地实现主动探索的VLN框架。在第一阶段，使用一小部分专家轨迹进行模仿学习，以引导智能体。在第二阶段，智能体迭代地预测和执行动作，自动收集多样化的轨迹，并通过GRPO目标优化多个rollout。为了进一步提高强化学习的效率，我们引入了一种动态提前停止策略，以修剪长尾或可能失败的轨迹，以及额外的工程优化。实验表明，与基于DAgger和先前的基于强化学习的后训练方法相比，ActiveVLN实现了相对于模仿学习基线的最大性能提升，并且尽管使用了较小的模型，但仍达到了与最先进方法相媲美的性能。代码和数据即将发布。
|
|**2025-09-15**|[Small Models, Big Results: Achieving Superior Intent Extraction through Decomposition](http://arxiv.org/abs/2509.12423)|null|从用户界面交互轨迹理解用户意图仍然是智能体开发中一个具有挑战性但至关重要的前沿领域。虽然大规模的、基于数据中心的、多模态大型语言模型（MLLM）具有更强的能力来处理此类序列的复杂性，但可以在设备上运行以提供保护隐私、低成本和低延迟用户体验的小型模型，在准确的意图推断方面存在困难。我们通过引入一种新颖的分解方法来解决这些限制：首先，我们执行结构化的交互总结，捕获来自每个用户操作的关键信息。其次，我们使用在聚合摘要上运行的微调模型执行意图提取。这种方法提高了资源受限模型中的意图理解能力，甚至超过了大型MLLM的基本性能。
|
|**2025-09-15**|[EfficientUICoder: Efficient MLLM-based UI Code Generation via Input and Output Token Compression](http://arxiv.org/abs/2509.12159)|null|多模态大型语言模型在UI2Code任务中表现出卓越的性能，显著提高了网站开发效率。然而，由于需要大量的输入图像tokens和广泛的输出代码tokens，这些任务比传统的代码生成产生更高的计算开销。我们全面的研究发现，图像和代码tokens中存在显著的冗余，这加剧了计算复杂性，并阻碍了对关键UI元素的关注，导致生成过长且通常无效的HTML文件。我们提出了EfficientUICoder，一个用于高效UI代码生成的压缩框架，包含三个关键组件。首先，元素和布局感知的Token压缩通过检测元素区域和构建UI元素树来保留必要的UI信息。其次，区域感知的Token优化利用注意力分数从选定区域中丢弃低注意力tokens，同时整合来自未选定区域的高注意力tokens。第三，自适应重复Token抑制通过跟踪HTML/CSS结构频率并应用指数惩罚来动态减少重复生成。大量实验表明，EfficientUICoder在不影响网页质量的情况下实现了55%-60%的压缩率，并提供了卓越的效率改进：在340亿参数的MLLM上，计算成本降低了44.9%，生成的tokens减少了41.4%，预填充时间减少了46.6%，推理时间减少了48.8%。代码可在https://github.com/WebPAI/EfficientUICoder获取。
|

<p align=right>(<a href="#updated-on-20250918">back to top</a>)</p>

## 大模型PEFT

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-09-17**|[Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications](http://arxiv.org/abs/2509.13775)|null|本文探讨了我们在阿拉伯语方言识别（ADI）中对不同数据高效和参数高效方法的探索。特别地，我们研究了各种软提示策略，包括前缀调优（prefix-tuning）、提示调优（prompt-tuning）、P-tuning和P-tuning V2，以及LoRA重参数化。对于数据高效策略，我们分析了零样本和少样本推断的硬提示，以分析大型语言模型（LLM）的方言识别能力。对于参数高效的PEFT方法，我们使用阿拉伯语专用编码器模型在几个主要数据集上进行了实验。我们还分析了在开源解码器模型、通用多语言模型（Phi-3.5）和阿拉伯语专用模型（SILMA）上的n-shot推断。我们观察到，大型语言模型通常难以区分少样本或零样本设置中的方言细微差别。软提示编码器变体的表现更好，而基于LoRA的微调模型表现最佳，甚至超过了完全微调。
|
|**2025-09-16**|[DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform](http://arxiv.org/abs/2509.13506)|null|扩散模型凭借其成熟的图像合成能力，能够实现高质量的虚拟试穿（VTO）。尽管当前的VTO方法涉及对大型预训练模型进行广泛的端到端训练，但实际应用通常优先考虑有限的训练和推理、服务及部署预算。为了解决这一障碍，我们应用Doob的h变换高效微调（DEFT），以调整大型预训练的无条件模型，使其具备下游图像条件的VTO能力。DEFT冻结了预训练模型的参数，并训练一个小的h变换网络来学习条件h变换。与传统的高效参数微调（PEFT）中5.52%的基线相比，h变换网络仅允许训练冻结参数的1.42%。为了进一步提高DEFT的性能并减少现有模型的推理时间，我们还提出了一种自适应一致性损失。一致性训练通过强制执行推理路径上的一致性，将缓慢但高性能的扩散模型提炼成快速模型，同时保持性能。受约束优化的启发，我们以数据自适应的方式将一致性损失和去噪评分匹配损失相结合，而不是蒸馏，从而以低成本微调现有的VTO模型。实验结果表明，所提出的DEFT-VTON方法在VTO任务上实现了最先进的性能，只需15个去噪步骤，同时保持了竞争性的结果。
|
|**2025-09-16**|[LLMs for energy and macronutrients estimation using only text data from 24-hour dietary recalls: a parameter-efficient fine-tuning experiment using a 10-shot prompt](http://arxiv.org/abs/2509.13268)|null|背景：大多数用于评估营养成分的人工智能工具依赖于图像输入。然而，仅凭食物消耗的文本描述，大型语言模型（LLM）是否能准确预测营养价值仍然未知。如果有效，这种方法无需照片即可实现更简单的饮食监测。方法：我们使用了来自美国国家健康和营养检查调查（NHANES）中12-19岁青少年的24小时膳食回顾。使用一个开源量化LLM，采用10次示例的思维链方法，仅根据列出食物及其数量的文本字符串来估计能量和五种常量营养素。然后，我们应用参数高效微调（PEFT）来评估预测准确性是否有所提高。NHANES计算的值作为能量、蛋白质、碳水化合物、总糖、膳食纤维和总脂肪的真实值。结果：在一个包含11,281名青少年（49.9%为男性，平均年龄15.4岁）的汇总数据集中，原始LLM的预测效果较差。能量的平均绝对误差（MAE）为652.08，且所有终点的Lin's CCC均<0.46。相比之下，经过微调的模型表现明显更好，能量MAE在不同子集中从171.34到190.90不等，并且所有结果的Lin's CCC均超过0.89。结论：当使用思维链方法提示并使用PEFT进行微调时，仅暴露于文本输入的开源LLM可以准确预测24小时膳食回顾中的能量和常量营养素值。这种方法为低负担、基于文本的饮食监测工具带来了希望。
|
|**2025-09-16**|[Don't Forget the Nonlinearity: Unlocking Activation Functions in Efficient Fine-Tuning](http://arxiv.org/abs/2509.13240)|null|现有的参数高效微调（PEFT）方法主要调整权重矩阵，同时保持激活函数不变。我们引入了\textbf{NoRA}，这是第一个直接调整预训练的基于Transformer的模型中的非线性激活函数的PEFT框架。NoRA用可学习的有理函数替换固定的激活函数，并将结构化的低秩更新应用于分子和分母系数，采用分组设计，以最小的成本实现局部自适应并提高稳定性。在CIFAR-10和CIFAR-100上训练的视觉Transformer上，NoRA在仅更新0.4%的参数（0.02M）的情况下，匹配或超过了完全微调，实现了+0.17%和+0.27%的准确率提升。当与LoRA结合使用时（\textbf{NoRA++}），它在匹配的训练预算下，通过添加更少的可训练参数，优于LoRA和DoRA。在LLaMA3-8B指令调优中，NoRA++持续提高生成质量，平均MMLU增益为+0.3%--0.8%，包括STEM（Alpaca）上的+1.6%和OpenOrca上的+1.3%。我们进一步表明，NoRA将自适应限制在低维函数子空间中，隐式地正则化更新幅度和方向。这些结果表明，激活空间调整是基于权重的PEFT的一种补充且高度参数高效的替代方案，将激活函数定位为模型自适应的一流对象。
|
|**2025-09-17**|[HAM: Hierarchical Adapter Merging for Scalable Continual Learning](http://arxiv.org/abs/2509.13211)|null|持续学习是人类认知的一项基本能力，但它对当前的深度学习模型提出了严峻的挑战。主要问题是，新的知识会干扰先前学习的信息，导致模型忘记早期知识而偏向于新知识，这种现象被称为灾难性遗忘。虽然大型预训练模型可以通过利用其现有知识和过度参数化来部分缓解遗忘，但当面对新的数据分布时，它们通常会遇到困难。参数高效微调（PEFT）方法，如LoRA，能够有效地适应新的知识。然而，它们在扩展到动态学习场景和长序列任务时仍然面临挑战，因为为每个任务维护一个适配器会引入复杂性并增加干扰的可能性。在本文中，我们介绍了一种新颖的框架，即分层适配器合并（HAM），它在训练期间动态地组合来自不同任务的适配器。这种方法使HAM能够有效地扩展，从而使其能够比具有更高效率的竞争基线管理更多的任务。为了实现这一目标，HAM维护一组固定的组，这些组以分层方式整合新的适配器。对于每个任务，HAM训练一个低秩适配器以及一个重要性标量，然后根据适配器的相似性动态地对任务进行分组。在每个组内，适配器被剪枝、缩放和合并，从而促进相关任务之间的迁移学习。在三个视觉基准上的大量实验表明，HAM显著优于最先进的方法，特别是随着任务数量的增加。
|
|**2025-09-16**|[A Systematic Evaluation of Parameter-Efficient Fine-Tuning Methods for the Security of Code LLMs](http://arxiv.org/abs/2509.12649)|null|代码生成大型语言模型（LLM）显著加速了软件开发。然而，它们频繁生成不安全代码带来了严重风险。我们对七种参数高效微调（PEFT）技术进行了全面评估，证明在不影响功能的情况下，显著提高了安全代码生成能力。我们的研究表明，提示调优是最有效的PEFT方法，在CodeGen2 16B上实现了80.86%的总体安全率，比67.28%的基线提高了13.5个百分点。通过采样温度优化解码策略，进一步将安全性提升至87.65%。这相当于每生成一百万个代码片段，减少了约203,700个易受攻击的代码片段。此外，在我们的TrojanPuzzle评估中，提示和前缀调优提高了针对投毒攻击的鲁棒性，并针对CWE-79和CWE-502攻击向量表现出强大的性能。我们的研究结果推广到Python和Java，证实了提示调优的一致有效性。这项研究为使用LLM构建更具弹性的软件系统提供了重要的见解和实践指导。
|
|**2025-09-15**|[PeruMedQA: Benchmarking Large Language Models (LLMs) on Peruvian Medical Exams -- Dataset Construction and Evaluation](http://arxiv.org/abs/2509.11517)|null|背景：医学大型语言模型（LLM）在回答医学考试问题方面表现出了卓越的性能。然而，这种高性能在多大程度上可以转移到西班牙语的医学问题以及拉丁美洲国家的问题上，仍有待探索。由于基于LLM的医学应用在拉丁美洲越来越受欢迎，因此这些知识至关重要。目的：构建一个由秘鲁医生参加专科培训的医学考试问题组成的数据集；在此数据集上对LLM进行微调；评估和比较原始LLM与微调LLM在准确性方面的性能。方法：我们整理了PeruMedQA，这是一个多项选择问答（MCQA）数据集，包含8,380个问题，涵盖12个医学领域（2018-2025年）。我们选择了八个医学LLM，包括medgemma-4b-it和medgemma-27b-text-it，并开发了零样本特定任务提示，以适当地回答问题。我们采用参数高效微调（PEFT）和低秩适应（LoRA）来微调medgemma-4b-it，利用除2025年（测试集）以外的所有问题。结果：medgemma-27b-text-it的表现优于所有其他模型，在多个实例中，正确答案的比例超过90%。参数小于100亿的LLM表现出低于60%的正确答案，而一些考试的结果低于50%。微调后的medgemma-4b-it再次胜过所有参数小于100亿的LLM，并在各种考试中与一个拥有700亿参数的LLM相媲美。结论：对于需要来自西班牙语国家知识库以及与秘鲁具有相似流行病学特征的医学AI应用和研究，感兴趣的各方应使用medgemma-27b-text-it或微调版本的medgemma-4b-it。
|
|**2025-09-11**|[HEFT: A Coarse-to-Fine Hierarchy for Enhancing the Efficiency and Accuracy of Language Model Reasoning](http://arxiv.org/abs/2509.09801)|null|将大型语言模型（LLM）适配到专门的推理任务从根本上受到计算资源的限制。参数高效微调（PEFT）方法已成为一种强大的解决方案，但这些技术的格局多种多样，不同的方法在模型的权重空间或其表示空间中运行。本文研究了这样一种假设，即这些范式的协同组合可以释放卓越的性能和效率。我们介绍了一种新的分层适配策略HEFT（分层高效微调），该策略以粗到精的方式组合了两种不同的PEFT方法：首先，使用低秩适配（LoRA）在权重空间中进行广泛的基础适配，然后使用表示微调（ReFT）对内部激活进行精确的手术式优化。我们通过在BoolQ基准测试上微调Llama-2-7B模型来评估这种方法，BoolQ是一个具有挑战性的推理数据集。我们的结果揭示了深刻的协同效应。仅使用我们的HEFT策略微调三个epoch的模型达到了85.17%的准确率，超过了仅使用LoRA（85.05%）或仅使用ReFT（83.36%）方法训练20个epoch的模型的性能。这项工作表明，PEFT方法的周到组合是一种有效的算法创新，为提高语言模型的推理能力提供了一条更高效的途径。通过以一小部分的计算预算获得卓越的结果，我们的发现提出了一种原则性的方法来克服将大规模模型用于复杂认知任务时固有的障碍。
|
|**2025-09-11**|[PeftCD: Leveraging Vision Foundation Models with Parameter-Efficient Fine-Tuning for Remote Sensing Change Detection](http://arxiv.org/abs/2509.09572)|null|为了解决多时相和多源遥感影像中伪变化普遍、标记样本稀缺以及跨域泛化困难等问题，我们提出了一种基于视觉基础模型（VFMs）和参数高效微调（PEFT）的变化检测框架PeftCD。PeftCD的核心是采用一个由VFM衍生的权重共享孪生编码器，并将LoRA和Adapter模块无缝集成到其中。这种设计通过仅训练最少数量的附加参数来实现高效的任务适应。为了充分释放VFM的潜力，我们研究了两个领先的骨干网络：以其强大的分割先验而闻名的Segment Anything Model v2（SAM2）和最先进的自监督表征学习器DINOv3。该框架由一个精心设计的轻量级解码器进行补充，确保重点仍然是来自骨干网络的强大特征表示。广泛的实验表明，PeftCD在多个公共数据集上实现了最先进的性能，包括SYSU-CD（IoU 73.81%）、WHUCD（92.05%）、MSRSCD（64.07%）、MLCD（76.89%）、CDD（97.01%）、S2Looking（52.25%）和LEVIR-CD（85.62%），并且具有显著精确的边界划分和对伪变化的强大抑制。总而言之，PeftCD在准确性、效率和泛化性之间实现了最佳平衡。它为将大规模VFM应用于现实世界的遥感变化检测应用提供了一个强大且可扩展的范例。代码和预训练模型将在https://github.com/dyzy41/PeftCD上发布。
|
|**2025-09-11**|[Sensitivity-LoRA: Low-Load Sensitivity-Based Fine-Tuning for Large Language Models](http://arxiv.org/abs/2509.09119)|null|大型语言模型（LLM）已经改变了日常生活和科学研究。然而，将LLM从通用模型调整到专门任务仍然具有挑战性，特别是在资源受限的环境中。低秩适应（LoRA）是参数高效微调（PEFT）中的一种突出方法，通过使用低秩分解来近似模型权重更新，已成为一种很有前途的LLM方法。然而，LoRA受到其对每个增量矩阵的统一秩（r）分配的限制，并且旨在解决此问题的现有秩分配技术仍然计算效率低下、复杂且不稳定，从而阻碍了实际应用。为了解决这些限制，我们提出了一种敏感性LoRA，这是一种高效的微调方法，可以根据权重矩阵的全局和局部敏感性动态地为权重矩阵分配秩。它利用损失函数的二阶导数（Hessian矩阵）来有效地捕获权重敏感性，从而以最小的计算开销实现最佳的秩分配。我们的实验结果证明了Sensitivity-LoRA在各种任务和基准测试中具有强大的有效性、效率和稳定性。
|

<p align=right>(<a href="#updated-on-20250918">back to top</a>)</p>

## 大模型强化学习

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-08-26**|[History Rhymes: Accelerating LLM Reinforcement Learning with RhymeRL](http://arxiv.org/abs/2508.18588)|null|随着大型语言模型（LLM）的快速发展，强化学习（RL）已成为增强LLM推理能力的关键方法。与传统的预训练方法不同，RL包含多个阶段：rollout、reward和训练，这需要各种worker类型之间的协作。然而，由于两个主要因素，当前的RL系统仍然面临着严重的GPU利用率不足的问题：（1）由于测试时扩展，rollout阶段在整个RL过程中占主导地位；（2）rollout长度（在同一批次内）的不平衡会导致GPU气泡。虽然像异步执行和截断等先前的解决方案提供了一定的缓解，但它们可能会牺牲训练准确性以换取效率。我们的关键见解源于一个先前被忽视的观察结果：rollout响应在相邻的训练epoch中表现出显著的相似性。基于这一见解，我们推出了RhymeRL，一个旨在加速RL训练的LLM RL系统，它具有两项关键创新。首先，为了提高rollout生成，我们提出了HistoSpec，一种推测性解码推理引擎，它利用历史rollout token序列的相似性来获得准确的草案。其次，为了解决rollout气泡问题，我们引入了HistoPipe，一种两层调度策略，它利用历史rollout分布的相似性来平衡rollout workers之间的工作负载。我们已经在真实的生产环境中评估了RhymeRL，证明了其从几十个到数千个GPU的可扩展性。实验结果表明，RhymeRL在不影响准确性或修改RL范式的情况下，实现了比现有方法高2.6倍的性能提升。
|
|**2025-07-10**|[RLEP: Reinforcement Learning with Experience Replay for LLM Reasoning](http://arxiv.org/abs/2507.07451)|null|用于大型语言模型的强化学习（RL）是一项能源密集型工作：训练可能不稳定，并且策略可能会逐渐偏离其预训练权重。我们提出 \emph{RLEP}\, -- \,具有经验回放的强化学习\, -- \,一个两阶段框架，首先收集经过验证的轨迹，然后在后续训练期间重放它们。在每个更新步骤中，策略都会在小批量数据上进行优化，这些小批量数据将新生成的 rollout 与这些重放的成功案例混合在一起。通过重放高质量的示例，RLEP 可以引导模型远离无效的探索，将学习重点放在有希望的推理路径上，并提供更快的收敛速度和更强的最终性能。在 Qwen2.5-Math-7B 基础模型上，RLEP 以更少的更新次数达到基线峰值精度，并最终超越它，从而提高了 AIME-2024 的准确率，从 38.2% 提高到 39.9%，AIME-2025 的准确率从 19.8% 提高到 22.3%，AMC-2023 的准确率从 77.0% 提高到 82.2%。我们的代码、数据集和检查点可在 https://github.com/Kwai-Klear/RLEP 公开获取，以方便重现和进一步研究。
|
|**2025-08-27**|[Can Large Language Models Develop Strategic Reasoning? Post-training Insights from Learning Chess](http://arxiv.org/abs/2507.00726)|null|尽管用于大型语言模型（LLM）的强化学习（RL）在数学推理方面展现了潜力，但使用RL进行LLM的战略推理在很大程度上仍未被探索。我们研究了LLM是否可以通过RL在国际象棋中发展战略推理能力。为此，我们利用一个经过国际象棋预训练的行动价值网络，以提供关于LLM输出的棋步质量的密集奖励，这可以被视为一种知识蒸馏的形式。我们的实验表明，我们基于蒸馏的密集奖励通常优于稀疏二元奖励。然而，令人惊讶的是，所有模型都远低于专家水平。我们提供了关于国际象棋推理训练的SFT和RL消融实验，并发现证据表明这种局限性源于预训练模型对国际象棋的内在理解的不足——而仅靠RL可能无法完全克服这种不足。代码可在https://github.com/krafton-ai/Chess-R1获取。
|
|**2025-06-06**|[CodeContests+: High-Quality Test Case Generation for Competitive Programming](http://arxiv.org/abs/2506.05817)|null|由于其高推理难度和精确的正确性反馈，竞争性编程已成为训练和评估大型语言模型（LLM）推理能力的关键任务。然而，虽然存在大量的公共问题数据，例如问题陈述和解决方案，但这些问题的测试用例通常难以获得。因此，测试用例生成是构建大规模数据集的必要任务，并且测试用例的质量直接决定了评估的准确性。在本文中，我们介绍了一种基于LLM的智能体系统，该系统为竞争性编程问题创建高质量的测试用例。我们将此系统应用于CodeContests数据集，并提出了一个具有改进测试用例的新版本，名为CodeContests+。我们评估了CodeContests+中测试用例的质量。首先，我们使用172万个带有通过/失败标签的提交来检查这些测试用例在评估中的准确性。结果表明，CodeContests+实现了比CodeContests显著更高的准确性，特别是具有明显更高的真正率（TPR）。随后，我们在LLM强化学习（RL）中的实验进一步证实，测试用例质量的提高为RL带来了相当大的优势。
|
|**2025-07-09**|[EMORL: Ensemble Multi-Objective Reinforcement Learning for Efficient and Flexible LLM Fine-Tuning](http://arxiv.org/abs/2505.02579)|**[link](https://github.com/engineerkong/EMORL)**|用于大型语言模型（LLM）微调的强化学习（RL）的最新进展在解决多目标任务方面显示出前景，但仍然面临重大挑战，包括竞争性目标平衡、训练效率低、可扩展性差和可解释性有限。利用集成学习原则，我们引入了一种集成多目标RL（EMORL）框架，该框架使用单独的目标来微调多个模型，同时在微调后优化它们的聚合，以提高效率和灵活性。我们的方法是第一个聚合各个模型的隐藏状态的方法，整合了来自多个目标的情境信息。这种方法得到了分层网格搜索算法的支持，该算法可识别最佳加权组合。我们评估了EMORL在咨询师反思生成任务中的应用，使用文本分类模型对生成结果进行评分，并在RL微调期间提供奖励。通过在PAIR和Psych8k数据集上进行全面实验，我们证明了EMORL相对于现有基线的优势：显著更低且更稳定的训练消耗（ $17,529\pm 1,650$个数据点和$6,573\pm 147.43$ 秒），改进的可扩展性和可解释性，以及在多个目标上具有可比的性能。
|
|**2025-04-29**|[Q-Fusion: Diffusing Quantum Circuits](http://arxiv.org/abs/2504.20794)|null|量子计算在解决具有社会意义和计算复杂性问题方面具有巨大潜力。此外，量子机器学习（QML）有望迅速提高我们当前的机器学习能力。然而，目前的含噪声中等规模量子（NISQ）设备受到量子比特数量和门数量的限制，这阻碍了它们的全部能力。此外，量子算法的设计仍然是一项费力的任务，需要大量的领域专业知识和时间。量子架构搜索（QAS）旨在通过自动生成新的量子电路来简化这一过程，从而减少手动干预的需求。在本文中，我们提出了一种基于扩散的算法，利用LayerDAG框架来生成新的量子电路。这种方法与其他使用大型语言模型（LLM）、强化学习（RL）、变分自编码器（VAE）和类似技术的方案形成对比。我们的结果表明，所提出的模型始终生成100%有效的量子电路输出。
|
|**2025-03-04**|[Learning from Failures in Multi-Attempt Reinforcement Learning](http://arxiv.org/abs/2503.04808)|null|以DeepSeek R1为代表的大语言模型（LLM）强化学习（RL）方面的最新进展表明，即使是一个简单的问答任务也能显著提高LLM的推理能力。在这项工作中，我们通过将任务修改为多次尝试设置来扩展这种方法。模型不是为每个问题生成单个响应，而是被赋予多次尝试的机会，并在不正确的响应后提供反馈。多次尝试任务鼓励模型改进其先前的尝试并提高搜索效率。实验结果表明，即使在多次尝试任务上训练的小型LLM，在用更多次尝试进行评估时，也能获得显著更高的准确率，在数学基准测试中，从1次尝试的45.6%提高到2次尝试的52.5%。相比之下，在标准单轮任务上训练的同一LLM仅表现出边际改进，在评估期间给予更多次尝试时，从42.3%提高到43.2%。结果表明，与标准单轮任务相比，在多次尝试任务上训练的LLM在数学基准测试中获得了稍好的性能，同时也学会了根据用户反馈更有效地改进其响应。完整代码可在https://github.com/DualityRL/multi-attempt获取。
|
|**2025-01-25**|[Training Dialogue Systems by AI Feedback for Improving Overall Dialogue Impression](http://arxiv.org/abs/2501.12698)|null|为了提高用户在与对话系统对话时的参与度，我们必须改善个别对话回复以及诸如一致性、个性以及同理心等贯穿整个对话的对话印象。虽然借助大型语言模型（LLM），此类对话系统一直在迅速发展，但从人工智能反馈中进行强化学习（RLAIF）已引起人们的关注，以使基于LLM的对话模型与此类对话印象对齐。在RLAIF中，基于另一个LLM的奖励模型用于通过零样本/少样本提示技术为基于LLM的对话模型创建训练信号。然而，仅通过提示LLM来评估整个对话是具有挑战性的。在这项研究中，我们对LLM进行了监督微调（SFT），从而准备了与整个对话的印象相关的12个指标相对应的奖励模型，以用于评估对话回复。我们使用奖励模型信号作为反馈来调整我们的对话模型，以改善系统的印象。自动和人工评估的结果表明，使用与对话印象相对应的奖励模型来调整对话模型，可以改善对各个指标的评估以及对话回复的自然性。
|
|**2025-08-07**|[Enhancing Code LLMs with Reinforcement Learning in Code Generation: A Survey](http://arxiv.org/abs/2412.20367)|null|随着大型语言模型（LLM）的快速发展，强化学习（RL）已成为代码生成和优化在各个领域中的关键技术。本文对强化学习在代码优化和生成中的应用进行了系统性综述，重点介绍了其在增强编译器优化、资源分配以及框架和工具开发中的作用。后续章节首先深入研究编译器优化的复杂过程，其中强化学习算法被用于提高效率和资源利用率。然后，讨论进展到强化学习在资源分配中的作用，重点介绍寄存器分配和系统优化。我们还将探讨框架和工具在代码生成中日益重要的作用，研究如何整合强化学习以增强其能力。本综述旨在为有兴趣利用强化学习的力量来推进代码生成和优化技术的研究人员和从业人员提供全面的资源。
|
|**2025-06-13**|[Entropy Controllable Direct Preference Optimization](http://arxiv.org/abs/2411.07595)|null|在大语言模型（LLM）的后训练中，从人类反馈中进行强化学习（RLHF）是实现与人类偏好对齐的有效方法。直接偏好优化（DPO）允许使用简单的二元交叉熵损失进行策略训练，而无需奖励模型。DPO的目标受到反向KL散度的正则化，从而鼓励对参考策略进行模式寻求拟合。然而，我们指出，最小化反向KL散度可能无法捕捉到参考分布的模式，这可能会损害策略的性能。基于这一观察，我们提出了对DPO的一个简单修改，即H-DPO，它可以控制结果策略的熵，从而增强分布的清晰度，并更有效地实现模式寻求拟合。在我们的实验中，我们表明H-DPO在各种任务中优于DPO，并在数学任务的pass@ $k$ 评估中展示了卓越的结果。此外，H-DPO易于实现，只需要对DPO的损失计算进行少量修改，这使其具有高度的实用性，并有望在大语言模型的训练中得到广泛应用。
|

<p align=right>(<a href="#updated-on-20250918">back to top</a>)</p>

