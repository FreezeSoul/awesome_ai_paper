## Updated on 2024.06.18
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#多模态>多模态</a></li>
    <li><a href=#6dof-object-pose>6DOF Object Pose</a></li>
    <li><a href=#nerf>nerf</a></li>
    <li><a href=#分类/检测/识别/分割>分类/检测/识别/分割</a></li>
    <li><a href=#模型压缩/优化>模型压缩/优化</a></li>
    <li><a href=#ocr>OCR</a></li>
    <li><a href=#生成模型>生成模型</a></li>
    <li><a href=#llm>LLM</a></li>
    <li><a href=#transformer>Transformer</a></li>
    <li><a href=#3dgs>3DGS</a></li>
    <li><a href=#3d/cg>3D/CG</a></li>
    <li><a href=#各类学习方式>各类学习方式</a></li>
  </ol>
</details>

## 多模态

|Publish Date|Title|PDF|Code|Abstract|
|---|---|---|---|--------------------------------------------------|
|**2024-06-14**|**VEGA: Learning Interleaved Image-Text Comprehension in Vision-Language Large Models**|[2406.10228](http://arxiv.org/abs/2406.10228)|null|**多模态大型模型 (MLLM) 的快速发展展现出其在处理视觉和语言混合任务方面的惊人能力。然而，目前大多数模型和基准测试都局限于视觉和文本上下文范围较窄的场景。当面对复杂的理解任务时，这些模型往往表现不佳，因为这些任务需要在文本和图像形式的大量无关信息和潜在误导性信息中进行导航。为了弥合这一差距，我们引入了一项新的、更具挑战性的任务，称为交错图文理解 (IITC)。这项任务要求模型辨别并忽略图像和文本中的多余元素，以准确回答问题，并遵循复杂的指令来精确定位相关图像。为了支持这项任务，我们进一步构建了一个新的 VEGA 数据集，该数据集专为科学内容的 IITC 任务而设计，并设计了一个子任务，即图文关联 (ITA)，以完善图文关联能力。我们对四个领先的闭源模型以及使用 VEGA 的各种开源模型进行了评估，结果突出了 IITC 的严格性。即使是最先进的模型，如 Gemini-1.5-pro 和 GPT4V，也只取得了有限的成功。通过采用多任务、多尺度微调策略，我们为 IITC 任务上的 MLLM  设定了一个稳健的基线，在图像关联方面达到了 85.8% 的准确率，Rouge 得分达到 0.508。这些结果验证了我们的数据集在提高 MLLM  细粒度图文理解能力方面的有效性。 
**|
|**2024-06-14**|**VideoGUI: A Benchmark for GUI Automation from Instructional Videos**|[2406.10227](http://arxiv.org/abs/2406.10227)|null|**图形用户界面（GUI）自动化在通过协助完成计算机任务来提高人类生产力方面具有巨大潜力。现有的任务制定主要集中在可以通过单个、仅使用语言的指令指定的简单任务上，例如“插入新幻灯片”。在这项工作中，我们介绍了 VideoGUI，这是一个新颖的多模态基准测试，旨在评估 GUI 助手在以视觉为中心的 GUI 任务上的表现。我们的基准测试源自高质量的网络教学视频，侧重于涉及专业和新颖软件（例如 Adobe Photoshop 或 Stable Diffusion WebUI）以及复杂活动（例如视频编辑）的任务。VideoGUI 通过分层过程评估 GUI 助手，从而可以识别它们可能失败的特定级别：（i）高级规划：在没有语言描述的情况下，根据视觉条件重建程序性子任务；（ii）中级规划：根据视觉状态（即屏幕截图）和目标生成精确动作叙述的序列；（iii）原子动作执行：执行特定动作，例如准确单击指定元素。对于每个级别，我们设计了跨各个维度的评估指标，以提供清晰的信号，例如在原子动作执行中单击、拖动、键入和滚动的个体性能。我们对 VideoGUI 的评估表明，即使是 SoTA 大型多模态模型 GPT4o 在以视觉为中心的 GUI 任务上也表现不佳，尤其是在高级规划方面。 
**|
|**2024-06-14**|**Short Film Dataset (SFD): A Benchmark for Story-Level Video Understanding**|[2406.10221](http://arxiv.org/abs/2406.10221)|null|**近年来，视觉语言模型的进步极大地推动了视频理解的发展。然而，现有的数据集和任务存在显著的局限性。大多数数据集仅限于事件有限、叙述范围狭窄的短视频。例如，包含教学和以自我为中心的视频的数据集通常记录一个人在单个场景中的活动。尽管一些电影数据集提供了更丰富的内容，但它们通常仅限于短期任务，缺乏公开可用的视频，并且由于在大型语言模型训练中使用电影论坛和其他资源，经常遇到数据泄露问题。为了解决上述限制，我们提出了包含 1,078 部公开可用的业余电影的短片数据集（SFD），该数据集涵盖了各种类型，并将数据泄露问题降至最低。SFD 以多项选择和开放式问答的形式提供长期故事导向的视频任务。我们广泛的实验强调了解决 SFD 任务需要长期推理能力。值得注意的是，我们发现电影脚本中存在强烈的信号，导致人类和大型语言模型的性能相当。我们还发现，与仅使用视觉数据相比，当前模型的性能明显低于人类。 
**|
|**2024-06-14**|**DevBench: A multimodal developmental benchmark for language learning**|[2406.10215](http://arxiv.org/abs/2406.10215)|null|**视觉语言模型和儿童的学习轨迹有多么相似（或不同）？最近的建模工作试图通过构建在较少数据（尤其是多模态自然数据）上训练的模型来理解模型和人类数据效率之间的差距。然而，此类模型通常在成人水平的基准上进行评估，测试的语言能力范围有限，并且没有与行为数据进行直接比较。我们介绍DevBench，这是一个多模态基准测试，包含七个语言评估任务，涵盖词汇、句法和语义能力领域，以及来自儿童和成人的行为数据。我们针对这些任务评估了一组视觉语言模型，不仅比较了模型和人类的准确性，还比较了他们的反应模式。在各项任务中，模型在接近人类反应模式方面表现出差异，并且在任务中表现更好的模型也更接近人类的行为反应。我们还检查了 OpenCLIP 在训练过程中的发展轨迹，发现更多的训练会使模型更接近成人的反应模式。因此，DevBench 提供了一个用于比较模型与人类语言发展的基准。这些比较突出了模型和人类语言学习过程的不同之处，为了解改进语言模型的切入点提供了见解。 
**|
|**2024-06-14**|**Detecting and Evaluating Medical Hallucinations in Large Vision Language Models**|[2406.10185](http://arxiv.org/abs/2406.10185)|null|**大型视觉语言模型 (LVLM) 在医疗应用中越来越不可或缺，包括医学视觉问答和影像报告生成。虽然这些模型继承了基础大型语言模型 (LLM) 的强大功能，但它们也继承了产生幻觉的可能性，这在容错率极低的医疗环境中是一个重大问题。然而，目前还没有专门针对医学领域幻觉检测和评估的方法或基准。为了弥合这一差距，我们推出了 Med-HallMark，这是第一个专门为医学多模态领域内的幻觉检测和评估而设计的基准。该基准提供多任务幻觉支持、多方面幻觉数据和分层幻觉分类。此外，我们提出了 MediHall Score，这是一种新的医学评估指标，旨在通过考虑幻觉的严重程度和类型的分层评分系统来评估 LVLM 的幻觉，从而能够对潜在的临床影响进行精细评估。我们还介绍了 MediHallDetector，这是一种为精确检测幻觉而设计的新型医学 LVLM，它采用多任务训练来进行幻觉检测。通过广泛的实验评估，我们使用我们的基准为流行的 LVLM 建立了基线。研究结果表明，与传统指标相比，MediHall Score 可以更细致地理解幻觉的影响，并证明了 MediHallDetector 性能的提升。我们希望这项工作能够显著提高 LVLM 在医疗应用中的可靠性。这项工作的所有资源将很快发布。 
**|
|**2024-06-14**|**CarLLaVA: Vision language models for camera-only closed-loop driving**|[2406.10165](http://arxiv.org/abs/2406.10165)|null|**在这篇技术报告中，我们介绍了 CarLLaVA，这是一个用于自动驾驶的视觉语言模型 (VLM)，专为 CARLA 自动驾驶挑战赛 2.0 而开发。CarLLaVA 使用 LLaVA VLM 的视觉编码器和 LLaMA 架构作为骨干，仅使用摄像头输入即可实现最先进的闭环驾驶性能，并且无需复杂或昂贵的标签。此外，我们还展示了预测驾驶输出的同时预测语言评论的初步结果。CarLLaVA 使用路径预测和航路点的半解耦输出表示，利用路径实现更好的横向控制，并利用航路点实现更好的纵向控制。我们提出了一种高效的训练方案，可以在大型驾驶数据集上进行训练，而不会在简单、琐碎的数据上浪费计算资源。CarLLaVA 在 CARLA 自动驾驶挑战赛 2.0 的传感器赛道上排名第一，比之前的最佳成绩高出 458%，比同期最佳提交成绩高出 32.6%。 
**|
|**2024-06-14**|**RoboGolf: Mastering Real-World Minigolf with a Reflective Multi-Modality Vision-Language Model**|[2406.10157](http://arxiv.org/abs/2406.10157)|null|**迷你高尔夫球，一个拥有无数球场布局和复杂球运动的游戏，构成了一个引人注目的现实世界测试平台，用于研究 embodied intelligence。因为它不仅挑战空间和运动推理能力，还需要反思和纠正能力来解决错误设计的球场。我们介绍 RoboGolf，这是一个利用嵌套 VLM 支持的闭环控制和反思平衡回路来感知双目视觉输入的框架。大量实验表明 RoboGolf 在具有挑战性的迷你高尔夫球场上（包括那些无法完成的球场）的有效性。 
**|
|**2024-06-14**|**SkySenseGPT: A Fine-Grained Instruction Tuning Dataset and Model for Remote Sensing Vision-Language Understanding**|[2406.10100](http://arxiv.org/abs/2406.10100)|**[link](https://github.com/luo-z13/skysensegpt)**|遥感大型多模态模型 (RSLMM) 正在迅速发展，并在遥感影像 (RSI) 理解方面展现出显著的能力。然而，由于现有数据集的限制，RSLMM 在理解复杂遥感场景中物体之间丰富的语义关系方面存在不足。为了释放 RSLMM 的复杂理解能力，我们提出了一个包含 1,800,851 个指令样本的大规模指令微调数据集 FIT-RS。FIT-RS 涵盖了常见的解释任务，并创新性地引入了一些难度逐渐递增的复杂理解任务，从关系推理到图像级场景图生成。基于 FIT-RS，我们构建了 FIT-RSFG 基准测试。此外，我们还建立了一个名为 FIT-RSRC 的新基准测试，用于评估 LMM 的细粒度关系理解能力。基于组合指令数据，我们提出了 SkySenseGPT，它在公共数据集和 FIT-RSFG 上都取得了优异的性能，超过了现有的 RSLMM。我们希望 FIT-RS 数据集能够增强 RSLMM 的关系理解能力，并为遥感社区提供大规模的细粒度数据源。该数据集将在 https://github.com/Luo-Z13/SkySenseGPT 上提供。 
|
|**2024-06-14**|**First Multi-Dimensional Evaluation of Flowchart Comprehension for Multimodal Large Language Models**|[2406.10057](http://arxiv.org/abs/2406.10057)|null|**随着多模态大语言模型（MLLM）技术的进步，其综合能力日益强大。为了评估MLLM的各种能力，涌现出 numerous 评估系统。但目前仍缺乏一种全面的方法来评估MLLM在与流程图相关的任务上的表现，而流程图在日常生活和工作中非常重要。我们提出了第一个综合方法FlowCE，用于从多个维度评估MLLM在与流程图相关的任务上的能力。它涵盖了评估MLLM在流程图上的推理、定位识别、信息提取、逻辑验证和总结等方面的能力。然而，我们发现即使是GPT4o模型也只取得了56.63的分数。在开源模型中，Phi-3-Vision获得了最高的49.97分。我们希望FlowCE能够为未来基于流程图的多模态大语言模型（MLLM）研究做出贡献。我们将开源这个项目：\url{https://github.com/360AILAB-NLP/FlowCE} 
**|
|**2024-06-14**|**Details Make a Difference: Object State-Sensitive Neurorobotic Task Planning**|[2406.09988](http://arxiv.org/abs/2406.09988)|**[link](https://github.com/xiao-wen-sun/ossa)**|物体状态反映了物体当前的状态或情况，这对机器人的任务规划和操作非常重要。然而，检测物体状态并为机器人生成状态敏感的计划具有挑战性。最近，预训练的大型语言模型 (LLM) 和视觉语言模型 (VLM) 在生成计划方面表现出令人印象深刻的能力。然而，据我们所知，几乎没有研究调查 LLM 或 VLM 是否也能生成物体状态敏感的计划。为了研究这个问题，我们介绍了一种物体状态敏感代理 (OSSA)，这是一种由预训练神经网络赋能的任务规划代理。我们为 OSSA 提出了两种方法：(i) 由预训练视觉处理模块（密集字幕模型，DCM）和自然语言处理模型 (LLM) 组成的模块化模型，以及 (ii) 仅由 VLM 组成的单片模型。为了定量评估这两种方法的性能，我们使用了桌面场景，其中任务是清理桌面。我们提供了一个考虑物体状态的多模态基准数据集。我们的结果表明，这两种方法都可以用于物体状态敏感的任务，但单片方法优于模块化方法。OSSA 的代码可在 \url{https://github.com/Xiao-wen-Sun/OSSA} 获取。 
|

<p align=right>(<a href=#updated-on-20240618>back to top</a>)</p>

## 6DOF Object Pose

|Publish Date|Title|PDF|Code|Abstract|
|---|---|---|---|--------------------------------------------------|
|**2024-06-06**|**Omni6DPose: A Benchmark and Model for Universal 6D Object Pose Estimation and Tracking**|[2406.04316](http://arxiv.org/abs/2406.04316)|null|**6D物体姿态估计是计算机视觉中一项至关重要但极具挑战性的任务，其面临的主要问题是大规模数据集的严重缺乏。这种稀缺性阻碍了对模型性能的全面评估，限制了研究进展。此外，可用实例或类别的数量有限也限制了其应用。为了解决这些问题，本文提出了Omni6DPose，这是一个以对象类别多样性、规模大和对象材质多样性为特征的大型数据集。Omni6DPose主要由三个部分组成：ROPE（真实6D物体姿态估计数据集），包含332K张图像，对149个类别中的581个实例进行了超过150万次标注；SOPE（模拟6D物体姿态估计数据集），由在混合现实环境中创建的475K张图像组成，使用深度模拟，对149个类别中的4162个实例进行了超过500万次标注；以及在ROPE和SOPE中使用的、手动对齐的真实扫描物体。由于存在大量的变化和歧义，Omni6DPose本身就具有挑战性。为了应对这一挑战，我们引入了GenPose++，这是对SOTA类别级姿态估计框架的增强版本，它包含两个关键改进：语义感知特征提取和基于聚类的聚合。此外，我们还提供了一个全面的基准分析，以评估先前方法在这个大规模数据集上在6D物体姿态估计和姿态跟踪方面的性能。 
**|
|**2024-06-05**|**Sparse Color-Code Net: Real-Time RGB-Based 6D Object Pose Estimation on Edge Devices**|[2406.02977](http://arxiv.org/abs/2406.02977)|null|**随着机器人和增强现实应用越来越依赖于精确高效的6D物体姿态估计，边缘设备上的实时性能对于实现更具交互性和响应能力的系统至关重要。我们提出的稀疏颜色代码网络（SCCN）体现了一种清晰简洁的流程设计，可以有效地满足这一需求。SCCN利用基本物体几何特征的稀疏性来加速透视n点（PnP）计算过程，对RGB图像中的目标物体进行像素级预测。此外，它引入了一种新颖的基于像素级几何的物体对称表示，该表示与初始姿态预测无缝集成，有效地解决了对称物体的歧义问题。SCCN在英伟达Jetson AGX Xavier上分别实现了在基准LINEMOD数据集和遮挡LINEMOD数据集上每秒19帧（FPS）和6帧的估计速率，同时在这些速率下始终保持较高的估计精度。 
**|
|**2024-05-19**|**Advancing 6-DoF Instrument Pose Estimation in Variable X-Ray Imaging Geometries**|[2405.11677](http://arxiv.org/abs/2405.11677)|**[link](https://github.com/cviviers/YOLOv5-6D-Pose)**|在微创手术中准确估计手术器械的 6 自由度 (6-DoF) 位姿可以显著改善治疗策略并最终改善手术结果。现有的深度学习方法已经取得了准确的结果，但它们需要针对每个对象定制方法，并且需要费力的设置和训练环境（通常扩展到广泛的模拟），同时缺乏实时计算能力。我们提出了一种用于 X 射线系统中 6-DoF 位姿估计任务的通用数据采集方法、一种新颖且通用的 YOLOv5-6D 位姿架构，用于准确快速地进行目标位姿估计，以及一种在考虑单目锥束 X 射线图像采集几何形状的情况下进行手术螺钉位姿估计的完整方法。所提出的 YOLOv5-6D 位姿模型在公共基准测试中取得了具有竞争力的结果，同时在 GPU 上的速度 considerably 更快，达到 42 FPS。此外，该方法可以泛化到不同的 X 射线采集几何形状和语义图像复杂度，从而能够在不同领域实现准确的位姿估计。最后，所提出的方法在脊柱手术期间对骨螺钉位姿估计进行了测试，以用于计算机辅助引导。该模型通过 0.1 ADD-S 指标实现了 92.41% 的准确率，证明了其在提高手术精度和患者治疗效果方面的巨大潜力。YOLOv5-6D 的代码可在 https://github.com/cviviers/YOLOv5-6D-Pose 公开获取。 
|
|**2024-05-18**|**PS6D: Point Cloud Based Symmetry-Aware 6D Object Pose Estimation in Robot Bin-Picking**|[2405.11257](http://arxiv.org/abs/2405.11257)|null|**6D物体姿态估计在各个领域都起着至关重要的作用，特别是在工业工件的抓取方面。针对锈蚀、高反射率和缺乏纹理等挑战，本文介绍了一种基于点云的姿态估计框架（PS6D）。PS6D专注于细长和多对称物体。它通过注意力引导的特征提取模块提取多尺度特征，设计了对称感知旋转损失和中心距离敏感平移损失来回归每个点到实例质心的姿态，然后使用两阶段聚类方法完成实例分割和姿态估计。来自Sil'eane和IPA数据集的对象以及来自工业实践的典型工件被用于生成数据和评估算法。与最先进的方法相比，PS6D在F $_{1_{inst}}$ 方面提高了11.5%，在召回率方面提高了14.8%。PS6D的主要部分已经部署到Mech-Mind的软件中，并在分拣实验中达到了91.7%的成功率，标志着其在工业姿态估计任务中的应用。 
**|
|**2024-05-31**|**Deep Learning-Based Object Pose Estimation: A Comprehensive Survey**|[2405.07801](http://arxiv.org/abs/2405.07801)|**[link](https://github.com/cnjianliu/awesome-object-pose-estimation)**|物体姿态估计是计算机视觉中的一个基本问题，在增强现实和机器人技术中有着广泛的应用。在过去的十年中，深度学习模型由于其卓越的准确性和鲁棒性，已经逐渐取代了依赖于工程点对特征的传统算法。然而，当代方法仍然存在若干挑战，包括它们对标记训练数据的依赖性、模型紧凑性、在挑战性条件下的鲁棒性以及对新颖的未见过物体的泛化能力。目前缺少一篇综述来讨论该领域的进展、面临的挑战和未来有希望的方向。为了填补这一空白，我们讨论了基于深度学习的物体姿态估计的最新进展，涵盖了该问题的三种形式，即实例级、类别级和未见过物体姿态估计。我们的综述还涵盖了多种输入数据模态、输出姿态的自由度、物体属性和下游任务，为读者提供了对该领域的全面理解。此外，它还讨论了不同领域的训练范式、推理模式、应用领域、评估指标和基准数据集，并报告了当前最先进方法在这些基准上的性能，从而方便读者根据自己的应用选择最合适的方法。最后，该综述指出了关键挑战，回顾了当前的趋势及其优缺点，并为未来的研究指明了有希望的方向。我们还将持续跟踪https://github.com/CNJianLiu/Awesome-Object-Pose-Estimation 上的最新工作。 
|
|**2024-05-02**|**IntervenGen: Interventional Data Generation for Robust and Data-Efficient Robot Imitation Learning**|[2405.01472](http://arxiv.org/abs/2405.01472)|null|**模仿学习是训练机器人控制策略的一种很有前景的范式，但这些策略可能会受到分布偏移的影响，即评估时的条件与训练数据中的条件不同。一种提高策略对分布偏移鲁棒性的流行方法是交互式模仿学习（即DAgger及其变体），其中人类操作员在策略执行期间提供纠正性干预。然而，收集足够数量的干预以覆盖策略错误的分布对于人类操作员来说可能是一项繁重的任务。我们提出了IntervenGen (I-Gen)，这是一种新颖的数据生成系统，它可以从少量的人工干预中自主生成大量覆盖状态空间的纠正性干预。我们将I-Gen应用于4个模拟环境和1个具有物体姿态估计误差的物理环境，结果表明，它只需10次人工干预即可将策略鲁棒性提高高达39倍。视频和更多结果可在https://sites.google.com/view/intervengen2024上找到。 
**|
|**2024-04-17**|**GeoReF: Geometric Alignment Across Shape Variation for Category-level Object Pose Refinement**|[2404.11139](http://arxiv.org/abs/2404.11139)|null|**物体姿态细化对于稳健的物体姿态估计至关重要。先前的工作在实例级物体姿态细化方面取得了重大进展。然而，由于类别内存在较大的形状变化以及目标物体与形状先验之间的差异，类别级姿态细化是一个更具挑战性的问题。为了应对这些挑战，我们介绍了一种用于类别级物体姿态细化的全新架构。我们的方法集成了 HS 层和可学习的仿射变换，旨在增强几何信息的提取和对齐。此外，我们引入了一种跨点云变换机制，可以有效地融合不同的数据源。最后，我们通过结合形状先验信息进行平移和尺寸误差预测，来突破模型的极限。我们进行了大量的实验来证明所提出框架的有效性。通过广泛的定量实验，我们证明了在所有指标上，相较于基线方法都有显著的改进。 
**|
|**2024-04-08**|**Learning a Category-level Object Pose Estimator without Pose Annotations**|[2404.05626](http://arxiv.org/abs/2404.05626)|null|**三维物体姿态估计是一项具有挑战性的任务。以往的工作总是需要数千张带有标注姿态的物体图像来学习三维姿态对应关系，这对于标注来说既费力又耗时。在本文中，我们提出了一种无需姿态标注即可学习类别级三维物体姿态估计器的方法。我们没有使用手动标注的图像，而是利用扩散模型（例如 Zero-1-to-3）生成一组在受控姿态差异下的图像，并建议使用这些图像来学习我们的物体姿态估计器。直接使用原始的扩散模型会导致图像出现姿态噪声和伪影。为了解决这个问题，首先，我们利用从专门设计的对比姿态学习中学习到的图像编码器来过滤不合理的细节并提取图像特征图。此外，我们提出了一种新的学习策略，允许模型从那些生成的图像集中学习物体姿态，而无需知道其规范姿态的对齐方式。实验结果表明，我们的方法能够从单次拍摄设置（作为姿态定义）中进行类别级物体姿态估计，同时在少样本类别级物体姿态估计基准测试中明显优于其他最先进的方法。 
**|
|**2024-03-28**|**Instance-Adaptive and Geometric-Aware Keypoint Learning for Category-Level 6D Object Pose Estimation**|[2403.19527](http://arxiv.org/abs/2403.19527)|**[link](https://github.com/leeiieeo/ag-pose)**|类别级 6D 物体姿态估计旨在估计特定类别中未见过实例的旋转、平移和尺寸。在这一领域，基于密集对应的方法已经取得了领先的性能。然而，它们没有明确考虑不同实例的局部和全局几何信息，导致对具有显著形状变化的未见过实例的泛化能力较差。为了解决这个问题，我们提出了一种新的实例自适应和几何感知关键点学习方法，用于类别级 6D 物体姿态估计（AG-Pose），它包括两个关键设计：（1）第一个设计是实例自适应关键点检测模块，它可以自适应地检测一组稀疏关键点，用于表示各种实例的几何结构。(2) 第二个设计是几何感知特征聚合模块，它可以有效地将局部和全局几何信息整合到关键点特征中。这两个模块可以协同工作，为未见过的实例建立鲁棒的关键点级对应关系，从而增强模型的泛化能力。在 CAMERA25 和 REAL275 数据集上的实验结果表明，所提出的 AG-Pose 在没有类别特定形状先验的情况下，大幅度优于现有技术方法。 
|
|**2024-06-01**|**Object Pose Estimation via the Aggregation of Diffusion Features**|[2403.18791](http://arxiv.org/abs/2403.18791)|**[link](https://github.com/tianfu18/diff-feats-pose)**|从图像中估计物体姿态是3D场景理解的关键任务，最近的方法在非常大的基准数据集上显示出良好的结果。然而，这些方法在处理未见过物体时性能会显著下降。我们认为这是由于图像特征的泛化能力有限造成的。为了解决这个问题，我们深入分析了扩散模型（如Stable Diffusion）的特征，这些特征在对未见过物体进行建模方面具有巨大潜力。基于这一分析，我们创新性地将这些扩散特征引入到物体姿态估计中。为此，我们提出了三种不同的架构，可以有效地捕捉和聚合不同粒度的扩散特征，大大提高了物体姿态估计的泛化能力。我们的方法在三个流行的基准数据集LM、O-LM和T-LESS上，以相当大的优势超过了现有技术水平。特别是，我们的方法在未见过物体上的准确率高于之前的最佳结果：在Unseen LM上为98.2% vs. 93.5%，在Unseen O-LM上为85.9% vs. 76.3%，显示了我们方法强大的泛化能力。我们的代码发布在https://github.com/Tianfu18/diff-feats-pose。 
|

<p align=right>(<a href=#updated-on-20240618>back to top</a>)</p>

## nerf

|Publish Date|Title|PDF|Code|Abstract|
|---|---|---|---|--------------------------------------------------|
|**2024-06-14**|**GaussianSR: 3D Gaussian Super-Resolution with 2D Diffusion Priors**|[2406.10111](http://arxiv.org/abs/2406.10111)|null|**从低分辨率输入视图实现高分辨率新视角合成 (HRNVS) 是一项具有挑战性的任务，因为缺乏高分辨率数据。以前的方法从低分辨率输入视图优化高分辨率神经辐射场 (NeRF)，但渲染速度缓慢。在这项工作中，我们基于 3D 高斯样条 (3DGS) 开发了我们的方法，因为它能够以更快的渲染速度生成高质量的图像。为了缓解高分辨率合成的数据短缺问题，我们建议利用现成的 2D 扩散先验，通过分数蒸馏采样 (SDS) 将 2D 知识提取到 3D。然而，由于生成先验带来的随机性，将 SDS 直接应用于基于高斯的 3D 超分辨率会导致不希望的和冗余的 3D 高斯基元。为了缓解这个问题，我们引入了两种简单而有效的技术来减少 SDS 引入的随机扰动。具体来说，我们 1) 使用退火策略缩小 SDS 中扩散时间步长的范围；2) 在密集化过程中随机丢弃冗余的高斯基元。大量实验表明，我们提出的 GaussainSR 仅使用合成和真实世界数据集上的低分辨率输入，就可以获得 HRNVS 的高质量结果。项目页面：https://chchnii.github.io/GaussianSR/ 
**|
|**2024-06-14**|**RaNeuS: Ray-adaptive Neural Surface Reconstruction**|[2406.09801](http://arxiv.org/abs/2406.09801)|**[link](https://github.com/wangyida/ra-neus)**|我们的目标是利用可微分辐射场（例如 NeRF）来重建详细的 3D 表面，以及生成标准的新颖视图渲染。 已经有一些相关方法可以执行此类任务，通常是通过利用带符号距离场 (SDF) 来实现的。 然而，最先进的方法仍然无法正确重建小规模细节，例如树叶、绳索和纺织品表面。 考虑到不同的方法使用全局常数 Eikonal 正则化来制定和优化从 SDF 到辐射场的投影，我们通过逐射线加权因子进行改进，以优先考虑在建立完美 SDF 的基础上进行渲染和零交叉表面拟合。 我们建议自适应地调整带符号距离场上的正则化，以便不令人满意的渲染光线不会强制执行无效的强 Eikonal 正则化，并允许来自具有良好学习辐射的区域的梯度有效地反向传播到 SDF。 因此，平衡这两个目标以生成准确和详细的表面。 此外，关于 SDF 中的零交叉表面和辐射场中的渲染点之间是否存在几何偏差，投影也可以根据优化期间不同的 3D 位置进行调整。 我们提出的 RaNeuS 在合成数据集和真实数据集上都进行了广泛的评估，在新颖视图合成和几何重建方面均取得了最先进的结果。|
|**2024-06-13**|**Neural NeRF Compression**|[2406.08943](http://arxiv.org/abs/2406.08943)|null|**神经辐射场 (NeRF) 已成为通过连续体积表示捕获详细 3D 场景的强大工具。最近的 NeRF 利用特征网格来提高渲染质量和速度；然而，这些表示引入了巨大的存储开销。本文提出了一种有效压缩基于网格的 NeRF 模型的新方法，解决了存储开销问题。我们的方法基于非线性变换编码范式，采用神经压缩来压缩模型的特征网格。由于缺乏涉及许多独立同分布场景的训练数据，我们为单个场景设计了一种无编码器、端到端优化的轻量级解码器方法。为了利用潜在特征网格的空间不均匀性，我们引入了重要性加权的速率失真目标函数和采用掩蔽机制的稀疏熵模型。我们的实验结果表明，我们提出的方法在基于网格的 NeRF 压缩效率和重建质量方面优于现有工作。 
**|
|**2024-06-13**|**OpenMaterial: A Comprehensive Dataset of Complex Materials for 3D Reconstruction**|[2406.08894](http://arxiv.org/abs/2406.08894)|null|**近年来，神经辐射场和隐式神经表示等深度学习技术的进步极大地推动了三维重建领域的发展。然而，由于金属和玻璃等具有独特镜面反射和透光特性的复杂光学特性，因此对其进行精确重建仍然是一项艰巨的挑战。为了促进针对这些挑战的解决方案的开发，我们引入了 OpenMaterial 数据集，该数据集包含 1001 个由 295 种不同材料（包括导体、电介质、塑料及其粗糙变体）制成的物体，并在 723 种不同的光照条件下捕获。为此，我们利用基于物理的渲染技术，结合实验室测量的折射率 (IOR)，生成了高度逼真的多视图图像，这些图像能够逼真地复制现实世界中的物体。OpenMaterial 提供了全面的注释，包括三维形状、材料类型、相机姿态、深度和物体遮罩。它是第一个能够对具有多种复杂材料的物体进行现有算法定量评估的大规模数据集，从而为开发能够处理复杂材料特性的三维重建算法铺平了道路。**|
|**2024-06-13**|**Gaussian-Forest: Hierarchical-Hybrid 3D Gaussian Splatting for Compressed Scene Modeling**|[2406.08759](http://arxiv.org/abs/2406.08759)|null|**近年来，新视角合成领域见证了三维高斯 splatting 的兴起，它以基于点的方式表示场景并通过光栅化进行渲染。与依赖于光线追踪的辐射场相比，这种方法展现出更优的渲染质量和速度。然而，三维高斯的显式和非结构化性质带来了巨大的存储挑战，阻碍了其更广泛的应用。为了应对这一挑战，我们引入了高斯森林建模框架，该框架将场景分层表示为混合三维高斯森林。每个混合高斯保留其独特的显式属性，同时与其兄弟高斯共享隐式属性，从而以更少的变量优化参数化。此外，我们还设计了自适应增长和修剪策略，确保在复杂区域进行详细表示，并显著减少所需高斯的数量。大量实验表明，高斯森林不仅保持了相当的速度和质量，而且实现了超过 10 倍的压缩率，标志着高效场景建模的重大进步。代码可在 https://github.com/Xian-Bei/GaussianForest 获取。 
**|
|**2024-06-12**|**OpenObj: Open-Vocabulary Object-Level Neural Radiance Fields with Fine-Grained Understanding**|[2406.08009](http://arxiv.org/abs/2406.08009)|**[link](https://github.com/BIT-DYN/OpenObj)**|近年来，利用视觉语言模型 (VLM) 进行开放词汇表三维场景重建引起了人们的广泛兴趣，这些模型在开放集检索方面表现出非凡的能力。然而，现有方法存在一些局限性：它们要么侧重于学习点态特征，导致语义理解模糊，要么只处理对象级重建，从而忽略了对象内部的复杂细节。为了应对这些挑战，我们引入了 OpenObj，这是一种利用细粒度理解构建开放词汇表对象级神经辐射场 (NeRF) 的创新方法。本质上，OpenObj 建立了一个强大的框架，用于在对象级别进行高效且无缝的场景建模和理解。此外，我们将零件级特征纳入神经场，从而能够对对象内部进行细致入微的表示。这种方法可以捕获对象级实例，同时保持细粒度的理解。在多个数据集上的结果表明，OpenObj 在零样本语义分割和检索任务中取得了优异的性能。此外，OpenObj 支持多尺度的现实世界机器人任务，包括全局运动和局部操作。 
|
|**2024-06-12**|**Spatial Annealing Smoothing for Efficient Few-shot Neural Rendering**|[2406.07828](http://arxiv.org/abs/2406.07828)|**[link](https://github.com/pulangk97/SANeRF)**|基于混合表示的神经辐射场 (NeRF) 在视图合成场景重建方面已展现出令人印象深刻的能力，并具有很高的效率。然而，由于过拟合问题，当视图输入稀疏时，它们的性能会显著下降。虽然已经设计了各种正则化策略来应对这些挑战，但它们通常依赖于低效的假设或与混合模型不兼容。显然，需要一种在混合框架内保持效率并提高对稀疏视图的适应性的方法。在本文中，我们介绍了一种名为空间退火平滑正则化 NeRF (SANeRF) 的精确且高效的少样本神经渲染方法，该方法专为预过滤驱动的混合表示架构而设计。我们实施了从初始大值开始的样本空间大小的指数减少。这种方法对于稳定训练阶段的早期阶段至关重要，并且对增强后续的细节细化过程有很大贡献。我们广泛的实验表明，通过仅添加一行代码，与当前的少样本 NeRF 方法相比，SANeRF 可提供卓越的渲染质量和更快的重建速度。值得注意的是，在 Blender 数据集上，SANeRF 的 PSNR 比 FreeNeRF 高 0.3 dB，同时实现了 700 倍的重建速度。 
|
|**2024-06-11**|**Neural Gaffer: Relighting Any Object via Diffusion**|[2406.07520](http://arxiv.org/abs/2406.07520)|null|**单图像重打光是一项具有挑战性的任务，涉及对几何、材质和光照之间复杂相互作用的推理。许多先前的方法要么只支持特定类别的图像（如肖像），要么需要特殊的拍摄条件（如使用手电筒）。或者，一些方法将场景明确分解为内在成分，例如法线和BRDF，但这可能不准确或表达不足。在这项工作中，我们提出了一种新颖的端到端二维重打光扩散模型，称为Neural Gaffer，它可以拍摄任何物体的单个图像，并可以在任何新的环境光照条件下合成准确、高质量的重打光图像，只需将图像生成器设置为以目标环境图为条件，而无需进行显式的场景分解。我们的方法建立在预先训练的扩散模型的基础上，并在合成的重打光数据集上对其进行微调，揭示并利用了扩散模型中存在的对光照的内在理解。我们在合成图像和来自互联网的真实图像上对我们的模型进行了评估，并展示了其在泛化性和准确性方面的优势。此外，通过与其他生成方法相结合，我们的模型可以实现许多下游二维任务，例如基于文本的重打光和物体插入。我们的模型还可以作为三维任务（例如为辐射场重新照明）的强大重打光先验。**|
|**2024-06-11**|**Active Scout: Multi-Target Tracking Using Neural Radiance Fields in Dense Urban Environments**|[2406.07431](http://arxiv.org/abs/2406.07431)|null|**我们研究了在高度遮挡的城市环境（例如，城市中的高层建筑）中进行的追逃游戏，其中侦察机（四旋翼机）跟踪地面上的多个动态目标。我们证明了可以使用来自不同有利位置的 RGB 和深度图像——在线——构建城市的神经辐射场 (NeRF) 表示。这种表示用于计算信息增益，以探索城市未知部分并跟踪目标——从而为主动跟踪动态目标提供了一种完全基于第一性原理的方法。我们使用基于费城和纽约市开放街道地图数据的定制模拟器证明，我们可以在 300 步内探索和定位 20 个静态目标。这比不使用主动感知的贪婪基线要慢。但是对于主动隐藏在遮挡物后面的动态目标，我们表明我们的方法最多可以保持 200 米的跟踪误差；贪婪基线的跟踪误差可高达 600 米。我们观察到侦察机策略中的一些有趣特性，例如，它会定期切换注意力以跟踪不同的目标，因为随着时间的推移，NeRF 表示的质量会提高，侦察机在目标跟踪方面也会变得更好。 
**|
|**2024-06-11**|**Cinematic Gaussians: Real-Time HDR Radiance Fields with Depth of Field**|[2406.07329](http://arxiv.org/abs/2406.07329)|null|**辐射场方法代表了从多视图照片重建复杂场景的最新技术。然而，这些重建通常存在以下一个或两个限制：首先，它们通常以低动态范围 (LDR) 表示场景，这限制了它们在光照均匀的环境中的使用，并阻碍了沉浸式观看体验。其次，它们依赖于针孔相机模型，假设所有场景元素在输入图像中都是对焦的，这带来了实际挑战，并使新视图合成过程中的重新对焦变得复杂。为了解决这些限制，我们提出了一种基于 3D 高斯 splatting 的轻量级方法，该方法利用场景的多视图 LDR 图像（具有不同的曝光时间、光圈和焦距）作为输入来重建高动态范围 (HDR) 辐射场。通过结合基于薄透镜相机模型的高斯分析卷积以及色调映射模块，我们的重建能够渲染具有灵活重聚焦功能的 HDR 内容。我们证明了我们对 HDR 和景深的组合处理促进了实时电影渲染，其性能优于现有技术水平。 
**|

<p align=right>(<a href=#updated-on-20240618>back to top</a>)</p>

## 分类/检测/识别/分割

|Publish Date|Title|PDF|Code|Abstract|
|---|---|---|---|--------------------------------------------------|
|**2024-06-14**|**SatDiffMoE: A Mixture of Estimation Method for Satellite Image Super-resolution with Latent Diffusion Models**|[2406.10225](http://arxiv.org/abs/2406.10225)|null|**在获取卫星图像时，由于卫星成像系统机载传感器的限制，通常需要在空间分辨率和时间分辨率（采集频率）之间进行权衡。高分辨率卫星图像对于土地作物监测、城市规划、野火管理和各种应用非常重要。实现高时空分辨率卫星成像是一项重要且具有挑战性的任务。随着扩散模型的出现，我们现在可以学习强大的生成先验来生成具有高分辨率的真实卫星图像，这也可以用于促进超分辨率任务。在这项工作中，我们提出了一种新的基于扩散的融合算法，称为SatDiffMoE，它可以将同一位置的任意数量的连续低分辨率卫星图像作为输入，并通过利用和融合来自不同时间点的补充信息，将它们融合成一个更精细的高分辨率重建图像。我们的算法具有高度的灵活性，允许对任意数量的低分辨率图像进行训练和推理。实验结果表明，我们提出的SatDiffMoE方法不仅在各种数据集上的卫星图像超分辨率任务中取得了优异的性能，而且与以前的方法相比，在减少模型参数的情况下提高了计算效率。 
**|
|**2024-06-14**|**EFM3D: A Benchmark for Measuring Progress Towards 3D Egocentric Foundation Models**|[2406.10224](http://arxiv.org/abs/2406.10224)|null|**可穿戴计算机的出现为人工智能提供了一种新的语境来源，这种语境嵌入以自我为中心的传感器数据中。这种新的以自我为中心的数据配备了精细的三维位置信息，因此为植根于三维空间的新型空间基础模型提供了机会。为了衡量我们称之为以自我为中心的基础模型 (EFM) 的进展，我们建立了 EFM3D，这是一个包含两个核心三维以自我为中心感知任务的基准测试。EFM3D 是第一个基于 Project Aria 高质量标注的以自我为中心的数据进行三维目标检测和表面回归的基准测试。我们提出了以自我为中心的体素提升 (EVL)，它是三维 EFM 的基线。EVL 利用所有可用的以自我为中心的模态，并继承了二维基础模型的基本功能。这个在大型模拟数据集上训练的模型在 EFM3D 基准测试中优于现有方法。 
**|
|**2024-06-14**|**YOLOv1 to YOLOv10: A comprehensive review of YOLO variants and their application in the agricultural domain**|[2406.10139](http://arxiv.org/abs/2406.10139)|null|**本综述调查了从 YOLOv1 到最先进的 YOLOv10 等各种 YOLO 变体在农业发展中的变革潜力。主要目标是阐明这些尖端的物体检测模型如何能够重振和优化农业的各个方面，从作物监测到牲畜管理。它旨在实现关键目标，包括确定农业中的当代挑战、详细评估 YOLO 的增量进步，以及探索其在农业中的具体应用。这是首批将最新的 YOLOv10 包含在内的调查之一，为其对人工智能和自动化时代精准农业和可持续农业实践的影响提供了新的视角。此外，该综述对 YOLO 的性能进行了批判性分析，综合了现有研究，并预测了未来趋势。通过仔细研究 YOLO 变体中包含的独特功能及其现实应用，本综述为 YOLO 变体与农业之间不断发展的关系提供了宝贵的见解。这些发现有助于深入理解精准农业和可持续农业实践的潜力，标志着在农业领域整合先进物体检测技术方面迈出了重要一步。 
**|
|**2024-06-14**|**GaussianSR: 3D Gaussian Super-Resolution with 2D Diffusion Priors**|[2406.10111](http://arxiv.org/abs/2406.10111)|null|**从低分辨率输入视图实现高分辨率新视角合成（HRNVS）是一项具有挑战性的任务，因为缺乏高分辨率数据。以前的方法从低分辨率输入视图优化高分辨率神经辐射场（NeRF），但渲染速度缓慢。在这项工作中，我们基于三维高斯散射（3DGS）开发了我们的方法，因为它能够以更快的渲染速度生成高质量的图像。为了缓解高分辨率合成的数据短缺问题，我们建议利用现成的二维扩散先验，通过分数蒸馏采样（SDS）将二维知识提取到三维。然而，由于生成先验带来的随机性，将SDS直接应用于基于高斯的3D超分辨率会导致不希望出现的冗余3D高斯基元。为了缓解这个问题，我们引入了两种简单而有效的技术来减少SDS引入的随机扰动。具体来说，我们1）使用退火策略缩小SDS中扩散时间步长的范围；2）在密集化过程中随机丢弃冗余的高斯基元。大量实验表明，我们提出的GaussainSR方法只需低分辨率输入，就可以在合成数据集和真实世界数据集上获得高质量的HRNVS结果。项目页面：https://chchnii.github.io/GaussianSR/ 
**|
|**2024-06-14**|**Forgetting Order of Continual Learning: Examples That are Learned First are Forgotten Last**|[2406.09935](http://arxiv.org/abs/2406.09935)|null|**灾难性遗忘是持续学习中的一个重大挑战，模型在学习新数据时经常会忘记之前的任务。我们的实证分析表明，灾难性遗忘与样本学习速度之间存在强相关性：先学习的样本很少被遗忘，而后学习的样本更容易被遗忘。我们证明了基于回放的持续学习方法可以通过关注中等学习速度的样本进行复习来利用这一现象。我们引入了“金发姑娘”（Goldilocks），这是一种新颖的回放缓冲区采样方法，它过滤掉学习太快或太慢的样本，保留那些以中等速度学习的样本。Goldilocks改进了现有的持续学习算法，在多个图像分类任务中实现了最先进的性能。 
**|
|**2024-06-14**|**Exact Sparse Representation Recovery in Signal Demixing and Group BLASSO**|[2406.09922](http://arxiv.org/abs/2406.09922)|null|**本文简要介绍了(Carioni 和 Del Grande, arXiv:2311.08072, 2023) 中提出的凸正则化优化问题中稀疏表示恢复的理论。我们关注未知量属于巴拿赫空间且在希尔伯特空间中进行测量的场景，探索这种情况下优化问题最小值点的性质。具体来说，我们分析了一个Tikhonov 正则化的凸优化问题，其中 $y_0$ 是测量数据，$w$ 表示噪声，$\lambda$ 是正则化参数。通过引入度量非退化源条件 (MNDSC) 并考虑足够小的 $\lambda$ 和 $w$ ，我们为问题建立了精确稀疏表示恢复 (ESRR)，这意味着最小值点是唯一的，并且可以精确地恢复原始数据的稀疏表示。然后，我们通过两个新的应用：信号分离和基于组稀疏凸优化（Group BLASSO）的超分辨率，强调了这一理论结果的实际意义。这些应用强调了我们结果的广泛适用性和重要性，展示了其在不同领域的潜力。 
**|
|**2024-06-14**|**Robust compressive tracking via online weighted multiple instance learning**|[2406.09914](http://arxiv.org/abs/2406.09914)|null|**由于遮挡、运动模糊、快速运动、光照变化、旋转、背景杂波、低分辨率和帧间变形等因素，开发强大的目标跟踪器是一项具有挑战性的任务。在文献中，已经提出了许多基于稀疏表示的优秀方法来解决上述问题。然而，大多数算法并不关注稀疏表示的学习。它们只考虑目标外观的建模，因此会因为训练样本不精确而偏离目标。考虑到上述所有因素，我们提出了一种视觉目标跟踪算法，该算法集成了基于稀疏表示的由粗到精搜索策略和加权多示例学习（WMIL）算法。与其他跟踪器相比，由于采用了由粗到精的搜索方法，我们的方法以较低的复杂度获得了更多原始信号的信息，并且对重要样本进行了加权。因此，它可以很容易地将背景特征与前景特征区分开来。此外，我们还从未遮挡的子区域中选择样本，以有效地开发强分类器。因此，我们实现了一个稳定而强大的目标跟踪器来解决所有上述问题。在具有挑战性的基准数据集上进行的定量和定性分析实验结果表明了我们方法的准确性和效率。 
**|
|**2024-06-14**|**Bayesian Conditioned Diffusion Models for Inverse Problems**|[2406.09768](http://arxiv.org/abs/2406.09768)|null|**扩散模型最近在许多涉及基于正向测量算子的逆问题的图像重建任务中表现出色。一个常见的框架是使用与任务无关的无条件模型，这些模型稍后会进行后验条件化以进行重建，但这种方法通常会导致任务性能欠佳。虽然也有人提出了特定于任务的条件模型，但当前的方法是启发式地将测量数据作为朴素输入通道注入，从而导致采样不准确。在这里，我们解决了扩散模型的最优条件化问题，以解决图像重建过程中出现的具有挑战性的逆问题。具体来说，我们提出了一种新的基于分数函数的扩散模型贝叶斯条件化技术BCDM，该技术与给定测量数据的期望图像的条件分布相关联。我们严格推导了表达和训练条件分数函数的理论。最后，我们展示了所提出的技术在图像去锯齿、去模糊、超分辨率和修复方面的最新性能。 
**|
|**2024-06-14**|**Automated GIS-Based Framework for Detecting Crosswalk Changes from Bi-Temporal High-Resolution Aerial Images**|[2406.09731](http://arxiv.org/abs/2406.09731)|null|**识别路面标记的变化对于基础设施监测、维护、开发、交通管理和安全至关重要。鉴于高分辨率图像的日益普及以及计算机视觉和目标检测技术的进步，道路几何形状的自动提取对此至关重要。具体而言，由于在不同时间实例捕获了大量的卫星和高分辨率航空图像，变化检测已成为一种可行的解决方案。本研究开发了一个自动化框架，利用从不同时间间隔获得的高分辨率图像中提取的数据，检测佛罗里达州奥兰治县、奥西奥拉县和塞米诺尔县人行横道的变化。具体而言，对于奥兰治县，手动提取、核实和分类了 2019 年至 2021 年期间人行横道的变化，分为新增人行横道或改造人行横道。对于塞米诺尔县，使用开发的模型自动提取了 2018 年至 2021 年期间人行横道的变化，而对于奥西奥拉县，则提取了 2019 年至 2020 年期间的变化。调查结果表明，奥兰治县大约发生了 2,094 处人行横道变化，其中 312 处发生在州级公路上。另一方面，在塞米诺尔县和奥西奥拉县，分别在地方和州级公路上观察到 1,040 处和 1,402 处人行横道变化。其中，在塞米诺尔县和奥西奥拉县的州级公路上分别发现了 340 处和 344 处变化。观察到的人行横道时空变化可用于定期更新现有的人行横道清单，这对从事交通和安全研究的机构至关重要。从这些人行横道变化中提取的数据可以与交通和事故数据相结合，为决策者提供宝贵的见解。 
**|
|**2024-06-14**|**An alternate approach for estimating grain-growth kinetics**|[2406.09653](http://arxiv.org/abs/2406.09653)|null|**晶粒生长速率有助于实现多晶材料的理想性能，通常通过测量晶粒尺寸并跟踪其在反映时间演变的显微照片中的变化来估计。采用这种传统方法的技术需要绝对区分晶粒和分隔它们的界面，才能得出准确的结果。边缘检测、分割和其他深度学习算法越来越多地被用于精确地揭示边界网络和相关的晶粒。本文提出了一种测量晶粒生长动力学的替代方法，该方法减少了对高级图像处理的需求。当前技术中的晶粒生长速率是通过“计数”三叉结（和四叉结）的数量并监测其在微观结构演变过程中的变化来确定的。这种基于结点的处理方法将重点转移，最大限度地减少了定义明确的晶界网络的重要性，从而减少了揭示它们的复杂技术的参与。扩展了一种基于回归的目标检测算法，以实现对多晶微结构中结点数量的识别和计数。通过检查结点数量随时间的变化，随后确定生长速率。通过目前的基于结点的方法估计的生长动力学，在各种多相多晶微结构中，与传统处理的结果非常吻合。除了提供一种新的晶粒生长测量技术外，当前工作附带的分析还揭示了与拓扑事件兼容的三叉结点计数的渐进演变趋势。本方法通过其底层算法，为在原位研究中监测晶粒生长提供了一种很有前景的选择。 
**|

<p align=right>(<a href=#updated-on-20240618>back to top</a>)</p>

## 模型压缩/优化

|Publish Date|Title|PDF|Code|Abstract|
|---|---|---|---|--------------------------------------------------|
|**2024-06-14**|**Self-Knowledge Distillation for Learning Ambiguity**|[2406.09719](http://arxiv.org/abs/2406.09719)|null|**最近的语言模型在自然语言理解 (NLU) 任务中表现出了惊人的性能。然而，当面对可以以多种方式解释的模糊样本时，它们往往不是最优的，它们会过于自信地预测单个标签，而没有考虑其正确性。为了解决这个问题，我们提出了一种新颖的自我知识蒸馏方法，该方法使模型能够通过利用从其较低层蒸馏的知识来更准确地学习标签分布。这种方法还包括一个学习阶段，可以根据蒸馏的分布知识重新校准被判断为极其模糊的训练样本的不必要增强的置信度。我们在不同的 NLU 基准数据集上验证了我们的方法，实验结果证明了其在生成更好的标签分布方面的有效性。特别是，通过重新校准高度模糊样本的置信度的过程，在很大程度上缓解了对未见样本的预测与其真实标签不匹配时的过度自信问题。这已被证明有助于生成比现有最先进方法更好的分布。此外，与现有方法相比，我们的方法在训练模型方面更有效率，因为它不需要额外的训练过程来细化标签分布。 
**|
|**2024-06-14**|**Frequency-mix Knowledge Distillation for Fake Speech Detection**|[2406.09664](http://arxiv.org/abs/2406.09664)|null|**在电话场景中，打击语音欺骗攻击的虚假语音检测 (FSD) 任务极具挑战性。数据增强 (DA) 方法被认为是解决电话场景中 FSD 任务的有效手段，通常分为时域和频域两个阶段。虽然每种方法都有其优点，但都可能导致信息丢失。为了解决这个问题，我们提出了一种新颖的 DA 方法，即频率混合 (Freqmix)，并引入了 Freqmix 知识蒸馏 (FKD) 来增强模型的信息提取和泛化能力。具体来说，我们使用 Freqmix 增强的数据作为教师模型的输入，而学生模型的输入则经过时域 DA 方法处理。我们使用多级特征蒸馏方法来恢复信息并提高模型的泛化能力。我们的方法在 ASVspoof 2021 LA 数据集上取得了最先进的结果，比基线提高了 31%，并且在 ASVspoof 2021 DF 数据集上表现出色。 
**|
|**2024-06-13**|**RobustSAM: Segment Anything Robustly on Degraded Images**|[2406.09627](http://arxiv.org/abs/2406.09627)|null|**Segment Anything Model (SAM) 作为一种变革性的图像分割方法已经出现，它以其强大的零样本分割能力和灵活的提示系统而备受赞誉。然而，它的性能在处理低质量图像时会受到挑战。为了解决这一局限性，我们提出了 Robust Segment Anything Model (RobustSAM)，它在保留 SAM 的提示能力和零样本泛化能力的同时，增强了其在低质量图像上的性能。我们的方法利用预训练的 SAM 模型，仅增加了少量参数和计算需求。RobustSAM 的额外参数可以在 8 个 GPU 上用 30 小时内完成优化，这证明了其对于典型研究实验室的可行性和实用性。我们还介绍了 Robust-Seg 数据集，这是一个包含 688K 个图像-掩码对的集合，这些图像对具有不同的退化程度，旨在优化我们模型的训练和评估。跨多个分割任务和数据集的大量实验都证实了 RobustSAM 的优越性能，尤其是在零样本条件下，突显了其在广泛现实应用中的潜力。此外，我们的方法已被证明可以有效提升基于 SAM 的下游任务（如单图像去雾和去模糊）的性能。 
**|
|**2024-06-13**|**Contextual Distillation Model for Diversified Recommendation**|[2406.09021](http://arxiv.org/abs/2406.09021)|null|**推荐结果的多样性与准确性在提升用户体验方面同样至关重要。现有研究，例如行列式点过程（DPP）和最大边缘相关性（MMR），采用贪婪算法迭代地选择同时优化准确性和多样性的项目。然而，先前的方法通常表现出平方复杂度，将其应用限制在重排序阶段，并且不适用于候选项目池更大的其他推荐阶段，例如预排序和排序阶段。在本文中，我们提出了上下文蒸馏模型（CDM），这是一种有效的解决多样化问题的推荐模型，适用于部署在工业推荐流程的所有阶段。具体而言，CDM利用同一用户请求中的候选项目作为上下文来增强结果的多样性。我们提出了一个对比上下文编码器，它采用注意力机制来对正面和负面上下文进行建模。对于CDM的训练，我们将每个目标项目与其上下文嵌入进行比较，并利用知识蒸馏框架来学习每个目标项目在MMR算法下的获胜概率，其中教师来自MMR输出。在推理过程中，通过推荐模型得分和学生模型得分的线性组合进行排名，确保了多样性和效率。我们对两个工业数据集进行了离线评估，并在短视频平台快手对CDM进行了在线A/B测试。指标显示，推荐质量和多样性方面观察到的显着提升，有力地证明了CDM的有效性。 
**|
|**2024-06-12**|**Unveiling Incomplete Modality Brain Tumor Segmentation: Leveraging Masked Predicted Auto-Encoder and Divergence Learning**|[2406.08634](http://arxiv.org/abs/2406.08634)|null|**脑肿瘤分割仍然是一个重大挑战，特别是在多模态磁共振成像 (MRI) 的情况下，临床环境中经常出现模态图像缺失，导致分割精度降低。为了解决这个问题，我们提出了一种新的策略，称为掩码预测预训练，能够从不完整的模态数据中学习鲁棒的特征。此外，在微调阶段，我们利用知识蒸馏技术来对齐完整和缺失模态数据之间的特征，同时增强模型鲁棒性。值得注意的是，我们利用 Holder 伪散度而不是 KLD 进行蒸馏损失计算，提供了更好的数学可解释性和特性。在 BRATS2018 和 BRATS2020 数据集上的大量实验表明，与现有的最先进方法相比，该方法显著提高了性能。 
**|
|**2024-06-14**|**Adaptive Teaching with Shared Classifier for Knowledge Distillation**|[2406.08528](http://arxiv.org/abs/2406.08528)|**[link](https://github.com/random2314235/atsc)**|知识蒸馏 (KD) 是一种用于将知识从过参数化的教师网络转移到参数较少的学生网络的技术，从而最大程度地减少性能损失。KD 方法可以分为离线和在线两种方法。离线 KD 利用强大的预训练教师网络，而在线 KD 允许动态调整教师网络以提高学生网络的学习效率。最近，人们发现共享教师网络的分类器可以显著提高学生网络的性能，而网络参数只增加了很少。基于这些见解，我们提出了具有共享分类器的自适应教学 (ATSC)。在 ATSC 中，预训练的教师网络会根据学生网络的能力进行自我调整，以更好地适应其学习需求，并且学生网络受益于共享分类器，从而提高其性能。此外，我们将 ATSC 扩展到具有多个教师的环境。我们进行了广泛的实验，证明了所提出的 KD 方法的有效性。我们的方法在单教师和多教师场景下，在 CIFAR-100 和 ImageNet 数据集上均取得了最先进的结果，而所需的模型参数仅略有增加。源代码可在 https://github.com/random2314235/ATSC 公开获取。 
|
|**2024-06-12**|**DistilDoc: Knowledge Distillation for Visually-Rich Document Applications**|[2406.08226](http://arxiv.org/abs/2406.08226)|null|**这项工作探索了知识蒸馏（KD）在富视觉文档（VRD）应用中的应用，例如文档布局分析（DLA）和文档图像分类（DIC）。虽然VRD研究依赖于日益复杂和笨重的模型，但该领域忽略了通过模型压缩来提高效率的研究。在这里，我们设计了一种KD实验方法，用于在更大任务管道中不可或缺的文档理解（DU）任务上获得更精简、更高效的模型。我们精心挑选了KD策略（基于响应、基于特征），用于在具有不同架构（ResNet、ViT、DiT）和容量（基础、小型、微型）的骨干网络之间提取知识。我们研究了影响师生知识差距的因素，发现一些方法（调整后的普通KD、MSE、带有合适投影器的SimKD）始终优于监督学生训练。此外，我们设计了下游任务设置，以评估协变量偏移和蒸馏DLA模型在零样本布局感知文档视觉问答（DocVQA）上的鲁棒性。DLA-KD实验导致了较大的mAP知识差距，这不可预测地转化为下游鲁棒性，突出了进一步探索如何有效地获得更多语义文档布局感知的需求。 
**|
|**2024-06-12**|**Low-Complexity Acoustic Scene Classification Using Parallel Attention-Convolution Network**|[2406.08119](http://arxiv.org/abs/2406.08119)|null|**这项工作是我们提交给 DCASE2023 挑战赛任务 1 的改进系统。我们提出了一种通过并行注意力-卷积网络进行低复杂度声音场景分类的方法，该网络由四个模块组成，包括预处理、融合、全局和局部上下文信息提取。所提出的网络在从每个音频片段中捕获全局和局部上下文信息方面计算效率很高。此外，我们将其他技术集成到我们的方法中，例如知识蒸馏、数据增强和自适应残差归一化。在 DCASE2023 挑战赛的官方数据集上进行评估时，我们的方法获得了 56.10% 的最高准确率，参数量为 5.21 千，乘积累加运算次数为 144 万次。它在准确性和复杂度方面超过了 DCASE2023 挑战赛的前两名系统，并获得了最先进的结果。代码位于：https://github.com/Jessytan/Low-complexity-ASC。 
**|
|**2024-06-12**|**Guiding Frame-Level CTC Alignments Using Self-knowledge Distillation**|[2406.07909](http://arxiv.org/abs/2406.07909)|null|**基于连接主义时间分类（CTC）框架的Transformer编码器被广泛应用于自动语音识别（ASR）。然而，用于ASR的知识蒸馏（KD）存在师生模型在帧级对齐上的分歧问题，最终阻碍了其提升学生模型性能。为了解决这个问题，本文提出了一种自知识蒸馏（SKD）方法，在训练阶段指导帧级对齐。与使用独立的教师和学生模型的传统方法相比，本研究引入了一种简单有效的方法，共享编码器层并将子模型作为学生模型。总的来说，我们的方法在提高资源效率和性能方面是有效的。我们还对尖峰时间进行了实验分析，以说明该方法通过减少对齐分歧来提高性能。 
**|
|**2024-06-12**|**Small Scale Data-Free Knowledge Distillation**|[2406.07876](http://arxiv.org/abs/2406.07876)|**[link](https://github.com/osvai/ssd-kd)**|无数据知识蒸馏能够利用大型教师网络学习到的知识来增强小型学生网络的训练，而无需访问原始训练数据，从而避免了实际应用中的隐私、安全和专有风险。在这一研究方向上，现有方法通常遵循一种反演和蒸馏范式，其中使用在预训练教师网络的指导下动态训练的生成对抗网络来合成用于知识蒸馏的大规模样本集。在本文中，我们重新审视了这种常见的无数据知识蒸馏范式，并通过“用于知识蒸馏的小规模反演数据”的视角，表明在整体训练效率方面还有相当大的改进空间。根据三个经验证据表明，在数据反演和蒸馏过程中，如何在合成样本多样性和难度方面平衡类别分布非常重要，我们提出了小规模无数据知识蒸馏SSD-KD。在公式中，SSD-KD引入了一个调制函数来平衡合成样本，并引入了一个优先采样函数来选择合适的样本，并通过动态重放缓冲区和强化学习策略来促进。因此，SSD-KD可以在极小规模的合成样本（例如，比原始训练数据规模小10倍）的条件下执行蒸馏训练，使其整体训练效率比许多主流方法快一到两个数量级，同时保持优越或具有竞争力的模型性能，如在流行的图像分类和语义分割基准测试中所证明的那样。代码可在https://github.com/OSVAI/SSD-KD获取。 
|

<p align=right>(<a href=#updated-on-20240618>back to top</a>)</p>

## OCR

|Publish Date|Title|PDF|Code|Abstract|
|---|---|---|---|--------------------------------------------------|
|**2024-06-14**|**Enhancing Question Answering on Charts Through Effective Pre-training Tasks**|[2406.10085](http://arxiv.org/abs/2406.10085)|null|**为了完全理解一份文档，仅仅使用文本信息是不够的。理解视觉线索，例如布局和图表，也是必要的。虽然目前最先进的文档理解方法（基于 OCR 和非基于 OCR 的方法）运作良好，但尚未对其能力和局限性进行全面分析。因此，在这项工作中，我们解决了当前视觉问答模型在应用于图表时存在的局限性。为了调查最先进模型的缺陷，我们以 ChartQA 为例进行了全面的行为分析。我们的研究结果表明，现有模型在回答与图表的结构和视觉上下文以及数值信息相关的问题时表现不佳。为了解决这些问题，我们提出了三个简单的预训练任务，这些任务从结构-视觉知识及其对数值问题的理解两方面增强了现有模型。我们在三个图表数据集（包括提取性和抽象性问题数据集）上评估了我们预训练的模型（称为 MatCha-v2），并观察到它比基线模型平均提高了 1.7%。 
**|
|**2024-06-14**|**OSPC: Detecting Harmful Memes with Large Language Model as a Catalyst**|[2406.09779](http://arxiv.org/abs/2406.09779)|null|**作为一种能够在互联网上快速传播个人观点和立场的媒介，迷因也给社会偏见和歧视的传播带来了重大挑战。本研究提出了一种新颖的方法来检测有害迷因，特别是在新加坡的多元文化和多语言环境下。我们的方法结合了图像描述、光学字符识别 (OCR) 和大型语言模型 (LLM) 分析，以全面理解和分类有害迷因。该系统利用 BLIP 模型进行图像描述，使用 PP-OCR 和 TrOCR 进行多种语言的文本识别，并使用 Qwen LLM 进行细致入微的语言理解，能够识别以英语、中文、马来语和泰米尔语创建的迷因中的有害内容。为了提高系统的性能，我们利用 GPT-4V 标记的额外数据对我们的方法进行了微调，旨在将 GPT-4V 对有害迷因的理解能力提炼到我们的系统中。我们的框架在新加坡人工智能举办的网络安全奖挑战赛的公开排行榜上名列前茅，AUROC 为 0.7749，准确率为 0.7087，远远领先于其他团队。值得注意的是，我们的方法优于以前的基准，FLAVA 的 AUROC 为 0.5695，VisualBERT 的 AUROC 为 0.5561。**|
|**2024-06-12**|**M3T: A New Benchmark Dataset for Multi-Modal Document-Level Machine Translation**|[2406.08255](http://arxiv.org/abs/2406.08255)|**[link](https://github.com/amazon-science/m3t-multi-modal-translation-bench)**|文档翻译对神经机器翻译 (NMT) 系统提出了挑战。大多数文档级 NMT 系统依赖于精心整理的句子级平行数据，假设可以完美地从文档中提取文本及其精确的阅读顺序。这些系统也倾向于忽略额外的视觉线索，例如文档布局，认为它们无关紧要。然而，现实世界的文档通常具有复杂的文本布局，这与这些假设相矛盾。从光学字符识别 (OCR) 或启发式规则中提取信息可能会导致错误，并且布局（例如，段落、标题）可能会传达文本不同部分之间的关系。这种复杂性在广泛使用的 PDF 文档中尤为明显，这些文档以视觉方式呈现信息。本文通过引入 M3T 来解决这一差距，M3T 是一个新颖的基准数据集，专为评估 NMT 系统在翻译半结构化文档的综合任务上的性能而设计。该数据集旨在弥合文档级 NMT 系统中的评估差距，承认现实应用程序中丰富的文本布局带来的挑战。 
|
|**2024-06-10**|**VCR: Visual Caption Restoration**|[2406.06462](http://arxiv.org/abs/2406.06462)|**[link](https://github.com/tianyu-z/vcr)**|我们引入了视觉字幕修复 (VCR)，这是一项新颖的视觉语言任务，它挑战模型利用图像中的像素级提示准确地恢复部分遮挡的文本。这项任务源于以下观察：嵌入图像中的文本与常见视觉元素和自然语言有着本质区别，因为它需要对视觉、文本和嵌入图像中的文本进行模态对齐。虽然大量工作已将嵌入图像中的文本整合到视觉问答任务中，但这些任务的方法通常依赖于光学字符识别或掩码语言建模，从而将任务简化为主要基于文本的处理。然而，在 VCR 中，基于文本的处理变得无效，因为准确的文本恢复依赖于来自所提供图像、上下文以及来自掩码文本微小暴露区域的细微线索的组合信息。我们开发了一个管道，使用图像-字幕对生成 VCR 任务的合成图像，并可调节字幕可见性以控制任务难度。利用此管道，我们使用来自维基百科的带字幕图像构建了一个名为 VCR-Wiki 的 VCR 数据集，其中包含 211 万个英文实体和 34.6 万个中文实体，分为简单和困难两种变体。我们的结果表明，当前的视觉语言模型在 VCR 任务中的表现明显落后于人类，仅仅在我们数据集上微调模型并不会带来显著的改进。我们发布了 VCR-Wiki 和数据构建代码，以促进未来的研究。 
|
|**2024-06-07**|**Scaling Automatic Extraction of Pseudocode**|[2406.04635](http://arxiv.org/abs/2406.04635)|null|**在学术论文中，伪代码提供了一种表达算法的简洁方法。伪代码也可以被认为是一种中间表示形式，有助于弥合编程语言和自然语言之间的差距。访问大量的伪代码可以带来各种好处，从增强算法理解、促进进一步的算法设计，到支持基于 NLP 或计算机视觉的模型，用于自动代码生成和光学字符识别 (OCR) 等任务。我们通过从 arXiv 论文中提取近 320,000 个伪代码示例，创建了一个大型伪代码集合。该过程涉及扫描超过 220 万篇学术论文，其中 1,000 篇经过人工检查和标记。我们的方法包括一个为优化覆盖范围而定制的提取机制，以及一个基于随机抽样的验证机制，以检查其准确性和可靠性，同时考虑到集合固有的异质性。此外，我们还提供了对常见伪代码结构的见解，并通过聚类和统计分析加以支持。值得注意的是，这些分析表明伪代码的使用呈指数级增长，突出了它们日益增长的重要性。 
**|
|**2024-06-06**|**CORU: Comprehensive Post-OCR Parsing and Receipt Understanding Dataset**|[2406.04493](http://arxiv.org/abs/2406.04493)|**[link](https://github.com/update-for-integrated-business-ai/coru)**|在光学字符识别 (OCR) 和自然语言处理 (NLP) 领域，集成多语言功能仍然是一项重大挑战，尤其是在考虑阿拉伯语等具有复杂书写系统的语言时。本文介绍了综合性 OCR 后解析和收据理解数据集 (CORU)，这是一个专门设计用于增强多语言环境（涉及阿拉伯语和英语）中收据的 OCR 和信息提取的新颖数据集。CORU 包含来自不同零售环境（包括超市和服装店）的 20,000 多张带注释的收据，以及 30,000 张用于 OCR 的带注释图像，用于识别每个检测到的行，以及 10,000 个为详细信息提取而注释的项目。这些注释捕获了基本细节，例如商家名称、商品描述、总价、收据编号和日期。它们的结构支持三个主要的计算任务：目标检测、OCR 和信息提取。我们在 CORU 上建立了一系列模型的基线性能，以评估传统方法（如 Tesseract OCR）和更先进的基于神经网络的方法的有效性。这些基线对于处理现实世界收据中常见的复杂且嘈杂的文档布局以及推进自动多语言文档处理的现状至关重要。我们的数据集可公开访问 (https://github.com/Update-For-Integrated-Business-AI/CORU)。 
|
|**2024-06-03**|**Generalized Jersey Number Recognition Using Multi-task Learning With Orientation-guided Weight Refinement**|[2406.01033](http://arxiv.org/abs/2406.01033)|null|**球衣号码识别 (JNR) 一直是体育分析中的一项重要任务。由于图像存在模糊、遮挡、变形和低分辨率等问题，提高识别精度仍然是一个持续的挑战。最近的研究已经使用数字定位和光学字符识别来解决这些问题。一些方法将球员识别方案应用于图像序列，忽略了人体旋转角度对球衣数字识别的影响。通过使用多任务方案来识别每个数字，可以准确预测球衣数字的数量，从而获得更可靠的结果。基于以上考虑，本文提出了一种称为角度数字细化方案 (ADRS) 的多任务学习方法，该方法结合人体方向角度和数字线索来识别运动球衣号码。根据我们的实验结果，我们的方法增加了推理信息，显着提高了预测精度。与只能处理单一类型运动的现有技术方法相比，所提出的方法产生了更加多样化和实用的 JNR 应用。在我们的数据集中纳入了足球、篮球、排球和棒球等多种类型的团队运动，这极大地促进了体育分析中通用的 JNR。我们的方法在 Top-1 上的准确率达到 64.07%，在 Top-2 上的准确率达到 89.97%，相应的 F1 分数分别为 67.46% 和 90.64%。 
**|
|**2024-05-30**|**Scaling up archival text analysis with the blockmodeling of n-gram networks -- A case study of Bulgaria's representation in the Osservatore Romano (January-May 1877)**|[2405.20156](http://arxiv.org/abs/2405.20156)|null|**本文旨在通过应用网络聚类方法分析 1877 年 1 月至 5 月期间出版的 123 期《罗马观察报》中对保加利亚的报道，从而弥合档案文本分析与网络分析之间的差距。本研究利用光学字符识别和广义同质性块模型构建了相关关键词网络。包括“保加利亚”和“俄罗斯”的网络同构性很强，并且与“德国”、“英国”和“战争”的网络有很大程度的重叠。从结构上看，这两个网络的块模型呈现出清晰的核心-半边缘-边缘结构，反映了报纸报道中各概念之间的关系。该报的词汇选择有效地 delegitimized 保加利亚民族复兴，突出了罗马教廷对该报编辑路线的影响。 
**|
|**2024-05-30**|**Towards Unified Multi-granularity Text Detection with Interactive Attention**|[2405.19765](http://arxiv.org/abs/2405.19765)|null|**现有的OCR引擎或文档图像分析系统通常依赖于针对不同场景和粒度的文本检测训练单独的模型，这导致了巨大的计算复杂性和资源需求。在本文中，我们介绍了“检测任何文本”（DAT），这是一种先进的范例，它将场景文本检测、布局分析和文档页面检测无缝地统一到一个 cohesive、端到端的模型中。这种设计使DAT能够有效地管理不同粒度的文本实例，包括*单词*、*行*、*段落*和*页面*。DAT的一项关键创新是跨粒度交互注意力模块，它通过关联不同文本查询之间的结构信息，显著增强了不同粒度文本实例的表示学习。因此，它使模型能够在多个文本粒度上实现互惠互利的检测性能。此外，基于提示的分割模块改进了对任意曲率和复杂布局文本的检测结果，从而提高了DAT的准确性并扩展了其在现实世界中的适用性。实验结果表明，DAT在各种文本相关基准测试中均达到了最先进的性能，包括多方向/任意形状场景文本检测、文档布局分析和页面检测任务。 
**|
|**2024-05-28**|**RealitySummary: On-Demand Mixed Reality Document Enhancement using Large Language Models**|[2405.18620](http://arxiv.org/abs/2405.18620)|null|**我们推出了 RealitySummary，这是一种混合现实阅读助手，可以使用按需文本提取、摘要和增强功能来增强任何打印或数字文档。虽然增强阅读工具承诺通过覆盖数字内容来增强物理阅读体验，但以前的系统通常需要预先处理文档，这限制了它们的通用性和现实世界的用例。在本文中，我们探索了利用大型语言模型进行按需文档增强。为了解不同文档的通用技术，我们首先进行了一项探索性设计研究，确定了五类文档增强功能（摘要、增强、导航、比较和提取）。在此基础上，我们开发了一个概念验证系统，可以使用 Google Cloud OCR 和 GPT-4 自动提取和汇总文本，然后使用 Microsoft Hololens 2 和 Apple Vision Pro 在文档周围嵌入信息。我们演示了六种特定文档增强的实时示例：1）摘要、2）比较表、3）时间线、4）关键词列表、5）摘要突出显示和 6）信息卡。可用性研究 (N=12) 和实地研究 (N=11) 的结果突出了按需 MR 文档增强的潜在好处以及未来研究的机会。 
**|

<p align=right>(<a href=#updated-on-20240618>back to top</a>)</p>

## 生成模型

|Publish Date|Title|PDF|Code|Abstract|
|---|---|---|---|--------------------------------------------------|
|**2024-06-14**|**SatDiffMoE: A Mixture of Estimation Method for Satellite Image Super-resolution with Latent Diffusion Models**|[2406.10225](http://arxiv.org/abs/2406.10225)|null|**在获取卫星图像时，由于卫星成像系统机载传感器的限制，通常需要在空间分辨率和时间分辨率（采集频率）之间进行权衡。高分辨率卫星图像对于土地作物监测、城市规划、野火管理和各种应用非常重要。实现高时空分辨率卫星成像是一项重要且具有挑战性的任务。随着扩散模型的出现，我们现在可以学习强大的生成先验，以生成具有高分辨率的逼真卫星图像，这也可以用于促进超分辨率任务。在这项工作中，我们提出了一种新的基于扩散的融合算法，称为 SatDiffMoE，它可以将同一位置的任意数量的连续低分辨率卫星图像作为输入，并通过利用和融合来自不同时间点的补充信息，将它们融合成一张具有更多精细细节的高分辨率重建图像。我们的算法具有高度的灵活性，允许对任意数量的低分辨率图像进行训练和推理。实验结果表明，我们提出的 SatDiffMoE 方法不仅在各种数据集上的卫星图像超分辨率任务中取得了优异的性能，而且与以前的方法相比，还提高了计算效率并减少了模型参数。 
**|
|**2024-06-14**|**Universal randomised signatures for generative time series modelling**|[2406.10214](http://arxiv.org/abs/2406.10214)|**[link](https://github.com/niklaswalter/randomised-signature-timeseries-generation)**|随机签名已被提出作为一种灵活且易于实现的方案来替代已确立的路径签名。在本文中，我们采用随机签名，本着水库计算的精神，为金融时间序列数据引入了一个生成模型。具体来说，我们提出了一种基于离散时间随机签名的全新 Wasserstein 类型距离。这种概率测度空间上的度量捕捉了（条件）分布之间的距离。我们关于随机签名在以基础路径作为输入的连续函数空间上的新型通用逼近结果证明了其使用的合理性。然后，我们将度量用作基于水库神经随机微分方程的合成时间序列数据的非对抗性生成模型中的损失函数。我们将模型的结果与现有文献中的基准进行了比较。 
|
|**2024-06-14**|**DiffusionBlend: Learning 3D Image Prior through Position-aware Diffusion Score Blending for 3D Computed Tomography Reconstruction**|[2406.10211](http://arxiv.org/abs/2406.10211)|null|**扩散模型在应用于现实世界中大规模医学图像重建（如 3D 计算机断层扫描 (CT)）时面临着重大挑战。由于对内存、时间和数据的要求很高，直接在高维数据的整个体积上训练扩散模型以获得高效的 3D 扩散先验是困难的。现有的利用单一 2D 图像切片上的扩散先验和手工制作的切片间正则化方法会牺牲 z 轴一致性，从而导致沿 z 轴出现严重伪影。在这项工作中，我们提出了一个新颖的框架，该框架可以通过位置感知的 3D 块扩散分数混合来学习 3D 图像先验，以重建大规模 3D 医学图像。据我们所知，我们是第一个利用 3D 块扩散先验进行 3D 医学图像重建的。在稀疏视图和有限角度 CT 重建上的大量实验表明，我们的 DiffusionBlend 方法明显优于以前的方法，并在具有高维 3D 图像（即 $256 \times 256 \times 500$ ）的现实世界 CT 重建问题上实现了最先进的性能。与以前的最先进方法相比，我们的算法还具有更好或相当的计算效率。 
**|
|**2024-06-14**|**Make It Count: Text-to-Image Generation with an Accurate Number of Objects**|[2406.10210](http://arxiv.org/abs/2406.10210)|null|**尽管文本到图像的扩散模型取得了前所未有的成功，但使用文本控制描绘对象的數量仍然非常困难。这对于从技术文档到儿童读物，再到烹饪食谱插图等各种应用程序都很重要。生成正确的对象数量从根本上来说具有挑战性，因为生成模型需要对每个对象实例保持独立的标识感，即使多个对象看起来相同或重叠，然后在生成过程中隐式地执行全局计算。目前尚不清楚这种表示是否存在。为了解决计数正确生成的问题，我们首先确定扩散模型中可以携带对象身份信息的特征。然后，我们使用它们在去噪过程中分离和计数对象实例，并检测过度生成和生成不足的情况。我们通过训练一个模型来修复后者，该模型可以根据现有对象的布局预测缺失对象的形状和位置，并展示如何使用它来指导具有正确对象计数的去噪过程。我们的方法 CountGen 不依赖于外部来源来确定对象布局，而是使用扩散模型本身的先验信息，创建依赖于提示和种子的布局。在两个基准数据集上进行的评估表明，CountGen 的计数准确率明显优于现有的基线模型。 
**|
|**2024-06-14**|**Glyph-ByT5-v2: A Strong Aesthetic Baseline for Accurate Multilingual Visual Text Rendering**|[2406.10208](http://arxiv.org/abs/2406.10208)|null|**近来，Glyph-ByT5 在图形设计图像中实现了高度精确的视觉文本渲染性能。然而，它仍然只专注于英语，并且在视觉吸引力方面的表现相对较差。在这项工作中，我们通过提出 Glyph-ByT5-v2 和 Glyph-SDXL-v2 来解决这两个基本限制，它们不仅支持 10 种不同语言的精确视觉文本渲染，而且还实现了更好的审美质量。为了实现这一目标，我们做出了以下贡献：(i) 创建了一个高质量的多语言字形-文本和图形设计数据集，该数据集包含超过 100 万个字形-文本对和 1000 万个图形设计图像-文本对，涵盖其他九种语言，(ii) 构建了一个包含 1,000 个提示的多语言视觉段落基准，每种语言 100 个，用于评估多语言视觉拼写准确性，以及 (iii) 利用最新的步骤感知偏好学习方法来增强视觉审美质量。通过结合这些技术，我们提供了一个强大的定制多语言文本编码器 Glyph-ByT5-v2 和一个强大的美学图形生成模型 Glyph-SDXL-v2，它们可以支持 10 种不同语言的准确拼写。我们认为我们的工作是一项重大进步，考虑到最新的 DALL-E3 和 Ideogram 1.0 仍然难以完成多语言视觉文本渲染任务。 
**|
|**2024-06-14**|**Crafting Parts for Expressive Object Composition**|[2406.10197](http://arxiv.org/abs/2406.10197)|null|**像Stable Diffusion、DALLE-2等大型生成模型的文生图技术，由于其卓越的质量和广泛的知识库，已成为各种任务的通用基础。由于图像的构成和生成是创造性的过程，艺术家需要控制生成图像的各个部分。我们发现，仅仅在基本文本提示中添加关于部分的细节，要么会导致完全不同的图像（例如，丢失/错误的身份），要么会导致额外的部分细节被忽略。为了缓解这些问题，我们引入了PartCraft，它能够根据为基本文本提示中的对象指定的细粒度部分级细节生成图像。这允许艺术家进行更多控制，并通过组合独特的对象部分实现新颖的对象组合。PartCraft 首先通过对特定扩散过程中的对象区域进行去噪来定位对象部分。这使得每个部分标记都能定位到正确的对象区域。在获得部分掩码后，我们根据细粒度的部分描述在每个部分区域运行局部扩散过程，并将它们组合起来生成最终图像。PartCraft 的所有阶段都基于对预训练扩散模型的重新利用，这使得它能够跨各种领域进行泛化，而无需训练。我们通过视觉示例定性地展示了 PartCraft 提供的部分级控制的有效性，并与当代基线进行了定量比较。 
**|
|**2024-06-14**|**Enhancing Incomplete Multi-modal Brain Tumor Segmentation with Intra-modal Asymmetry and Inter-modal Dependency**|[2406.10175](http://arxiv.org/abs/2406.10175)|null|**近年来，基于深度学习的多模态MRI图像脑肿瘤分割(BTS)模型取得了显著进展。然而，在实践中，由于扫描方案和患者状况的不同，某些模态的不可用是一个普遍问题，这使得从不完整的MRI模态进行分割成为一个具有挑战性的问题。以往的方法试图通过融合可访问的多模态特征、利用注意力机制和使用生成模型合成缺失的模态来解决这个问题。然而，这些方法忽略了医学图像分割的内在问题，例如训练样本有限，特别是对于存在肿瘤的情况。此外，这些方法需要针对每个缺失模态子集训练和部署特定的模型。为了解决这些问题，我们提出了一种从两个角度增强BTS模型的新方法。首先，我们引入了一个预训练阶段，生成一个包含各种不同肿瘤形状和大脑解剖结构组合的多样化预训练数据集。其次，我们提出了一个后训练阶段，使模型能够在只有部分模态可用的情况下重建预测结果中缺失的模态。为了实现预训练阶段，我们从概念上将MRI图像解耦为两部分：“解剖结构”和“肿瘤”。我们使用从不同训练样本的解剖结构和肿瘤部分生成的合成数据对BTS模型进行预训练。……大量实验表明，我们提出的方法相较于基线方法显著提高了性能，并在三个脑肿瘤分割数据集（BRATS2020、BRATS2018和BRATS2015）上取得了新的最先进结果。 
**|
|**2024-06-14**|**Training-free Camera Control for Video Generation**|[2406.10126](http://arxiv.org/abs/2406.10126)|null|**我们提出了一种无需训练且鲁棒的解决方案，为现成的视频扩散模型提供摄像机运动控制。与之前的工作不同，我们的方法不需要在摄像机标注的数据集上进行任何监督微调，也不需要通过数据增强进行自监督训练。相反，它可以与大多数预训练的视频扩散模型即插即用，并以单个图像或文本提示作为输入生成摄像机可控的视频。我们工作的灵感来自于中间潜变量对生成结果的布局先验，因此重新排列其中的噪声像素也会使输出内容重新分配。由于摄像机运动也可以看作是由视角变化引起的像素重新排列，因此如果视频的噪声潜变量发生相应的变化，则可以按照特定的摄像机运动重新组织视频。在此基础上，我们提出了CamTrol方法，该方法为视频扩散模型提供了强大的摄像机控制能力。它通过两阶段过程实现。首先，我们在3D点云空间中通过显式摄像机运动对图像布局重新排列进行建模。其次，我们利用一系列重新排列的图像形成的噪声潜变量的布局先验生成具有摄像机运动的视频。大量实验表明，我们的方法在控制生成视频的摄像机运动方面具有鲁棒性。此外，我们还展示了我们的方法在生成具有动态内容的3D旋转视频方面可以产生令人印象深刻的结果。项目页面：https://lifedecoder.github.io/CamTrol/。 
**|
|**2024-06-14**|**Precipitation Nowcasting Using Physics Informed Discriminator Generative Models**|[2406.10108](http://arxiv.org/abs/2406.10108)|null|**短临预报利用实时大气条件来预测短时间内的天气。包括 PySTEPS 在内的最先进模型在准确预测极端天气事件方面遇到了困难，因为它们的分布模式不可预测。在这项研究中，我们设计了一个基于物理的神经网络，使用荷兰皇家气象研究所 (KNMI) 的降水和气象数据来执行降水短临预报。该模型的灵感来自新型物理信息鉴别器 GAN (PID-GAN) 公式，将基于物理的监督直接集成到对抗学习框架中。所提出的模型采用 GAN 结构，以矢量量化生成对抗网络 (VQ-GAN) 和 Transformer 作为生成器，并以时间鉴别器作为鉴别器。我们的研究结果表明，PID-GAN 模型在降水短临预报的下游指标方面优于数值模型和最先进的深度生成模型。 
**|
|**2024-06-14**|**Group and Shuffle: Efficient Structured Orthogonal Parametrization**|[2406.10019](http://arxiv.org/abs/2406.10019)|null|**神经网络规模的不断增大导致对高效微调方法的需求日益增长。最近，一种正交微调范式被提出，它使用正交矩阵来调整预训练模型的权重。在本文中，我们介绍了一种新的结构化矩阵类别，它统一并概括了先前工作中的结构化类别。我们研究了该类别的性质，并在此基础上构建了结构化的正交参数化。然后，我们使用这种参数化来修改正交微调框架，提高参数和计算效率。我们在不同的领域对我们的方法进行了经验验证，包括文本到图像扩散模型的调整和语言建模中的下游任务微调。此外，我们还针对正交卷积调整了我们的构造，并使用 1-Lipschitz 神经网络进行了实验。 
**|

<p align=right>(<a href=#updated-on-20240618>back to top</a>)</p>

## LLM

|Publish Date|Title|PDF|Code|Abstract|
|---|---|---|---|--------------------------------------------------|
|**2024-06-14**|**The Devil is in the Neurons: Interpreting and Mitigating Social Biases in Pre-trained Language Models**|[2406.10130](http://arxiv.org/abs/2406.10130)|null|**预训练语言模型（PLM）已被公认包含有害信息，例如社会偏见，这可能会造成负面的社会影响，甚至在应用中带来灾难性的后果。以前关于这个问题的工作主要集中于使用黑盒方法（例如探测）通过观察模型输出来检测和量化PLM中的社会偏见。因此，以前的去偏方法主要是在新构建的反刻板印象数据集上微调甚至预训练语言模型，而这些数据集的成本很高。在这项工作中，我们试图通过引入“社会偏见神经元”的概念来揭示语言模型内部社会偏见的神秘面纱。具体来说，我们提出了“集成梯度梯度（IG $^2$）”来准确地确定语言模型中可归因于不良行为（例如社会偏见）的单元（即神经元）。通过将不良行为形式化为语言的分布属性，我们使用带有情感色彩的提示来引发与这种情感相关的敏感词类（人口统计）。因此，我们的IG$^2$将不同人群的不均匀分布归因于特定的社会偏见神经元，这些神经元跟踪PLM单元内部不需要的行为轨迹以实现互操作性。此外，基于我们可解释的技术，进一步提出了“偏见神经元抑制（BNS）”来减轻社会偏见。通过研究BERT、RoBERTa及其与去偏FairBERTa的归因差异，IG$^2$ 使我们能够定位和抑制识别出的神经元，并进一步减轻不希望的行为。根据StereoSet的先前指标测量，我们的模型以较低的成本实现了更高程度的公平性，同时保持了语言建模能力。 
**|
|**2024-06-14**|**Experiments in News Bias Detection with Pre-Trained Neural Transformers**|[2406.09938](http://arxiv.org/abs/2406.09938)|null|**万维网为全球提供了无与伦比的信息获取渠道，包括真实的新闻报道和评论。然而，国家行为者和商业公司越来越多地传播带有偏见的（扭曲的）或虚假的（非事实的）信息来推进他们的议程。我们在句子级新闻偏见检测和子类型分类的任务上比较了几种大型预训练语言模型，并提供了定量和定性的结果。 
**|
|**2024-06-14**|**Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity**|[2406.09790](http://arxiv.org/abs/2406.09790)|null|**语义文本相似度（STS）是计算语言学的一个关键研究方向，是嵌入模型编码能力的关键指标。在预训练语言模型和对比学习技术的推动下，领先的句子表示方法在 SentEval 的 7 个 STS 基准测试中已经可以达到约 86 的平均 Spearman 相关系数得分。然而，进一步的改进变得越来越微不足道，现有的方法在这些任务上的平均得分都没有超过 87。本文深入分析了这一现象，得出结论：使用对比学习的 Spearman 相关系数得分上限为 87.5。为了突破这一上限，我们提出了一种名为 Pcc-tuning 的创新方法，该方法采用 Pearson 相关系数作为损失函数，以优化模型性能，超越对比学习。实验结果表明，Pcc-tuning 明显优于以往最先进的策略，将 Spearman 相关系数得分提高到 90 以上。 
**|
|**2024-06-13**|**Self-Training for Sample-Efficient Active Learning for Text Classification with Pre-Trained Language Models**|[2406.09206](http://arxiv.org/abs/2406.09206)|null|**主动学习是一种迭代标记过程，用于在缺少标记数据的情况下获取小的标记子集，从而能够训练用于文本分类等监督任务的模型。虽然近年来由于预训练语言模型的改进，主动学习取得了相当大的进展，但在通常被忽视的未标记数据部分仍有未开发的潜力，尽管与通常很小的标记数据集相比，未标记数据的数量要大得多。在这里，我们研究了自我训练（一种半监督方法，其中使用模型从未标记数据中获取伪标签）如何用于提高主动学习在文本分类中的效率。我们从对四种先前自我训练方法的广泛复现开始，其中一些方法首次在主动学习或自然语言处理的背景下进行评估，我们设计了 HAST，这是一种新的、有效的自我训练策略，并在四个文本分类基准上进行了评估，结果表明，它优于复现的自我训练方法，并且在四个数据集中，有三个数据集仅使用 25% 的数据就达到了与先前实验相当的分类结果。 
**|
|**2024-06-13**|**Generating Speakers by Prompting Listener Impressions for Pre-trained Multi-Speaker Text-to-Speech Systems**|[2406.08812](http://arxiv.org/abs/2406.08812)|null|**本文提出了一种语音合成系统，允许用户通过描述说话者特征的提示来指定和控制说话者的声音特征。与以往的方法不同，我们的方法利用听者的印象来构建提示，这些提示更容易收集，并且更自然地与日常对说话者特征的描述相一致。我们采用低秩自适应（LoRA）技术，快速地将预训练的语言模型调整到我们的需求，以便从提示文本中提取与说话者相关的特征。此外，与其他提示驱动的文本到语音（TTS）系统不同，我们将提示到说话者模块与多说话者TTS系统分离，增强了系统的灵活性以及与各种预训练的多说话者TTS系统的兼容性。此外，对于提示到说话者特征模块，我们还比较了判别方法和基于流匹配的生成方法，我们发现结合这两种方法可以帮助系统更好地从提示中同时捕获与说话者相关的信息，并生成更高保真度的语音。 
**|
|**2024-06-12**|**Unraveling Code-Mixing Patterns in Migration Discourse: Automated Detection and Analysis of Online Conversations on Reddit**|[2406.08633](http://arxiv.org/abs/2406.08633)|null|**全球移民模式的激增凸显了将移民无缝融入东道社区的必要性，这需要包容和值得信赖的公共服务。尽管北欧国家拥有强大的公共部门基础设施，但近期移民在获得这些服务方面经常遇到障碍，加剧了社会差距并削弱了信任。在这一努力中，解决数字不平等和语言多样性至关重要。本文探讨了代码混合（一种在多语言使用者中普遍存在的交流策略）在 Reddit 等社交媒体平台上与移民相关的讨论中的应用。我们提出了多语言代码混合文本集成学习识别方法 (ELMICT)，这是一种旨在自动检测移民相关讨论中代码混合消息的新方法。ELMICT 利用集成学习技术组合多个分词器的输出和预训练的语言模型，在识别各种语言和上下文中的代码混合方面表现出高性能（F1 值大于 0.95），特别是在跨语言零样本条件下（平均 F1 值大于 0.70）。此外，ELMICT 的使用有助于分析与 Reddit 上其他主题类别相比，移民相关主题中代码混合的普遍程度，揭示了移民社区关注的话题。我们的研究结果揭示了移民在社交媒体平台上采用的交流策略，为开发包容性数字公共服务和对话系统提供了启示。通过解决本研究提出的研究问题，我们有助于理解移民话语中的语言多样性，并为构建多元文化社会信任的更有效工具铺平道路。 
**|
|**2024-06-12**|**Next-Generation Database Interfaces: A Survey of LLM-based Text-to-SQL**|[2406.08426](http://arxiv.org/abs/2406.08426)|null|**根据自然语言问题生成准确的SQL（文本到SQL）是一个长期存在的问题，因为它在用户问题理解、数据库模式理解和SQL生成方面具有挑战性。传统的文本到SQL系统包括人工工程和深度神经网络。随后，预训练语言模型（PLM）被开发并用于文本到SQL任务，取得了可喜的性能。随着现代数据库变得更加复杂，相应的用户问题也更具挑战性，理解能力有限的PLM可能会导致错误的SQL生成。这需要更复杂和定制的优化方法，而这反过来又限制了基于PLM的系统的应用。最近，大型语言模型（LLM）在自然语言理解方面表现出显著的能力，因为模型规模一直在增加。因此，集成基于LLM的实现可以为文本到SQL研究带来独特的机会、挑战和解决方案。在本次调查中，我们对基于LLM的文本到SQL进行了全面回顾。具体来说，我们简要概述了当前的挑战和文本到SQL的演变过程。然后，我们详细介绍了旨在评估文本到SQL系统的数据集和指标。之后，我们系统地分析了基于LLM的文本到SQL的最新进展。最后，我们讨论了该领域 remaining 的挑战，并对未来方向提出了期望。 
**|
|**2024-06-12**|**Leveraging Large Language Models for Web Scraping**|[2406.08246](http://arxiv.org/abs/2406.08246)|null|**大型语言模型 (LLM) 在复制人类任务和提高生产力方面表现出非凡的能力。然而，由于优先考虑流畅性而非事实准确性以及操纵特定信息的有限能力，LLM 直接应用于数据提取存在局限性。为了克服这些局限性，本研究利用预训练 LLM 的知识表示能力和 RAG 模型支持的目标信息访问，研究了一种用于语言生成的 RAG 模型的通用精确数据抓取方案。为了以更模块化和可解释的方式获取知识，我们使用具有潜在知识检索器的预训练语言模型，该模型允许模型从大型语料库中检索文档并对其进行处理。我们利用 RAG 模型架构，并针对三个任务对其功能进行了深入分析：(i) HTML 元素的语义分类，(ii) 为有效理解而对 HTML 文本进行分块，以及 (iii) 比较不同 LLM 和排名算法的结果。虽然之前的工作已经为 HTML 理解和提取开发了专门的架构和训练程序，但我们表明，在标准自然语言上进行预训练并添加有效分块、搜索和排名算法的 LLM 可以证明是有效的从非结构化文本中提取复杂数据的抓取工具。未来的研究方向包括解决所提出的基于 RAG 的数据提取框架内的来源跟踪和动态知识更新的挑战。通过克服这些限制，这种方法有可能彻底改变从大量文本信息库中提取数据的方式。 
**|
|**2024-06-12**|**Guiding In-Context Learning of LLMs through Quality Estimation for Machine Translation**|[2406.07970](http://arxiv.org/abs/2406.07970)|**[link](https://github.com/JoyeBright/ICLviaQE)**|大型语言模型 (LLM) 的输出质量，特别是在机器翻译 (MT) 中，与查询（即待翻译文本）一起提供的上下文示例 (ICE) 的质量密切相关。这些 ICE 的有效性受多种因素的影响，例如源文本的领域、ICE 的呈现顺序、示例数量以及使用的提示模板。自然地，选择最具影响力的 ICE 取决于理解这些因素如何影响最终的翻译质量，而这最终依赖于翻译参考或人工判断。本文提出了一种新的上下文学习 (ICL) 方法，该方法依赖于由特定领域质量估计 (QE) 指导的搜索算法。我们的方法利用 XGLM 模型，无需翻译参考即可估计生成的翻译质量，从而为机器翻译选择有效的 ICE 以最大限度地提高翻译质量。我们的结果表明，与现有的 ICL 方法相比，我们的方法有显著改进，并且与微调预训练语言模型 (PLM)，特别是 mBART-50 相比，具有更高的翻译性能。 
|
|**2024-06-12**|**Label-aware Hard Negative Sampling Strategies with Momentum Contrastive Learning for Implicit Hate Speech Detection**|[2406.07886](http://arxiv.org/abs/2406.07886)|**[link](https://github.com/hanyang-hcc-lab/lahn)**|检测非直接仇恨的隐性仇恨言论仍然是一个挑战。最近的研究尝试通过将对比学习应用于预训练的语言模型（如 BERT 和 RoBERTa）来检测隐性仇恨言论，但所提出的模型与基于交叉熵损失的学习相比仍然没有显著优势。我们发现，基于随机抽样批数据的对比学习并不能鼓励模型学习困难的负样本。在这项工作中，我们提出了标签感知的困难负样本采样策略 (LAHN)，该策略鼓励模型使用动量集成的对比学习，从困难的负样本中学习详细特征，而不是随机批次中的简单负样本。LAHN 在数据集内和跨数据集的隐性仇恨言论检测方面均优于现有模型。代码可在 https://github.com/Hanyang-HCC-Lab/LAHN 获取。 
|

<p align=right>(<a href=#updated-on-20240618>back to top</a>)</p>

## Transformer

|Publish Date|Title|PDF|Code|Abstract|
|---|---|---|---|--------------------------------------------------|
|**2024-06-14**|**Whisper-Flamingo: Integrating Visual Features into Whisper for Audio-Visual Speech Recognition and Translation**|[2406.10082](http://arxiv.org/abs/2406.10082)|**[link](https://github.com/roudimit/whisper-flamingo)**|音频-视觉语音识别 (AVSR) 利用基于嘴唇的视频来提高在噪声环境下的性能。由于视频比音频更难获取，AVSR 模型的视频训练数据通常仅限于几千小时。相比之下，Whisper 等语音模型使用数十万小时的数据进行训练，因此可以学习到更好的语音到文本解码器。巨大的训练数据差异促使我们调整 Whisper 以处理视频输入。受 Flamingo 将视觉特征注入语言模型的启发，我们提出了 Whisper-Flamingo，它通过门控交叉注意力将视觉特征集成到 Whisper 语音识别和翻译模型中。在嘈杂条件下，我们的视听 Whisper-Flamingo 在 6 种语言的英语语音识别和英语-X 翻译方面优于纯音频 Whisper。此外，Whisper-Flamingo 是一种多功能模型，可以使用一组参数执行所有这些任务，而之前的方法是在每种语言上单独训练的。 
|
|**2024-06-14**|**Simul-Whisper: Attention-Guided Streaming Whisper with Truncation Detection**|[2406.10052](http://arxiv.org/abs/2406.10052)|null|**Whisper作为一种强大的大规模多语言语音识别模型，在许多低资源和跨领域场景中都表现出色。然而，其编码器-解码器结构阻碍了其在流式语音识别中的应用。在本文中，我们介绍了Simul-Whisper，它利用Whisper交叉注意力机制中嵌入的时间对齐信息来指导自回归解码，并在无需对预训练模型进行任何微调的情况下实现基于块的流式自动语音识别。此外，我们观察到块边界处截断词对解码结果的负面影响，并提出了一种基于“整合-触发”的截断检测模型来解决这个问题。在多种语言和Whisper架构上的实验表明，Simul-Whisper在1秒的块大小下平均绝对词错误率仅下降了1.46%，明显优于当前最先进的基线模型。 
**|
|**2024-06-14**|**IFA: Interaction Fidelity Attention for Entire Lifelong Behaviour Sequence Modeling**|[2406.09742](http://arxiv.org/abs/2406.09742)|null|**用户的终身行为序列提供了丰富的用户偏好信息，并在推荐任务中获得了显著的改进，但也大大增加了计算量。为了满足在线服务的严格延迟要求，通常根据与目标商品的相似性对短子序列进行采样。然而，不在子序列中的商品将被丢弃，导致严重的信息丢失。在本文中，我们提出了一种新的高效范式来对完整的终身序列进行建模，称为交互保真度注意力（IFA）。在 IFA 中，我们一次性将候选集中的所有目标商品输入模型，并利用线性 Transformer 来降低候选集和序列之间交叉注意力的的时间复杂度，而不会丢失任何交互信息。我们还额外建模了所有目标商品之间的关系以实现最佳集合生成，并设计了损失函数以提高训练和推理的一致性。我们通过快手推荐系统的离线和在线实验验证了模型的有效性和效率。 
**|
|**2024-06-13**|**Multi-Modal Retrieval For Large Language Model Based Speech Recognition**|[2406.09618](http://arxiv.org/abs/2406.09618)|null|**检索是一种广泛采用的利用外部信息改进语言模型的方法。随着该领域向多模态大型语言模型发展，将纯文本方法扩展到检索中以纳入其他模态变得至关重要，这适用于各种机器学习任务和数据类型。在这项工作中，我们提出了两种多模态检索方法：kNN-LM 和交叉注意力技术。我们通过将这些检索方法应用于可访问外部信息的自动语音识别任务，凭经验证明了它们的有效性。在这种情况下，我们证明了基于语音的多模态检索优于基于文本的检索，并且与多模态语言模型基线相比，词错误率降低了高达 50%。此外，我们在 Spoken-Squad 问答数据集上取得了最先进的识别结果。 
**|
|**2024-06-13**|**Cross-Modal Learning for Anomaly Detection in Fused Magnesium Smelting Process: Methodology and Benchmark**|[2406.09016](http://arxiv.org/abs/2406.09016)|null|**熔镁炉 (FMF) 是氧化镁生产中的关键工业设备，异常检测对其高效、稳定和安全运行起着至关重要的作用。现有的异常检测方法主要集中于使用过程变量（如电弧电流）分析主要异常或基于异常视觉特征构建神经网络，而忽略了跨模态信息的内在关联。本文提出了一种跨模态 Transformer（称为 FmFormer），旨在通过探索视觉特征（视频）和过程变量（电流）之间的相关性来促进熔融镁冶炼过程中的异常检测。我们的方法引入了一种新颖的标记化范式，以多尺度方式有效地弥合 3D 视频模态和 1D 电流模态之间的巨大维度差距，从而实现像素级异常检测的分层重建。随后，FmFormer 利用自注意力机制学习每个模态内的内部特征，并利用双向交叉注意力机制捕获模态间的相关性。为了验证所提出方法的有效性，我们还提供了一个开创性的熔融镁冶炼过程跨模态基准，该基准包含超过 220 万个样本的同步采集的视频和电流数据。利用跨模态学习，所提出的 FmFormer 在检测异常方面实现了最先进的性能，特别是在电流波动和浓密水雾造成的视觉遮挡等极端干扰下。所提出的方法和基准可以通过一些修改应用于其他工业应用。该基准将在 https://github.com/GaochangWu/FMF-Benchmark 发布。 
**|
|**2024-06-13**|**Dual Attribute-Spatial Relation Alignment for 3D Visual Grounding**|[2406.08907](http://arxiv.org/abs/2406.08907)|null|**三维视觉指称定位是一项新兴的研究领域，致力于将三维物理世界与自然语言联系起来，这对于实现 embodied intelligence 至关重要。在本文中，我们提出了 DASANet，一种双重属性-空间关系对齐网络，它分别对语言和 3D 视觉模态之间的对象属性和空间关系特征进行建模和对齐。我们将语言和 3D 点云输入分解成两个独立的部分，并设计了一个双分支注意力模块来分别对分解后的输入进行建模，同时通过交叉注意力在属性-空间特征融合中保留全局上下文。我们的 DASANet 在 Nr3D 数据集上实现了最高的 65.1% 的指称定位准确率，比最佳竞争对手高出 1.3%。此外，两个分支的可视化证明了我们的方法是高效且具有高度可解释性的。 
**|
|**2024-06-12**|**Diffusion-Promoted HDR Video Reconstruction**|[2406.08204](http://arxiv.org/abs/2406.08204)|null|**高动态范围 (HDR) 视频重建旨在从以交替曝光拍摄的低动态范围 (LDR) 帧生成 HDR 视频。大多数现有工作仅依赖于基于回归的范式，导致了诸如鬼影伪影和饱和区域细节丢失等不利影响。在本文中，我们提出了一种用于 HDR 视频重建的扩散促进方法，称为 HDR-V-Diff，它结合了扩散模型来捕捉 HDR 分布。因此，HDR-V-Diff 可以重建具有逼真细节的 HDR 视频，同时减少鬼影伪影。然而，直接引入视频扩散模型会带来巨大的计算负担。相反，为了减轻这种负担，我们首先提出了一种 HDR 潜在扩散模型 (HDR-LDM) 来学习单个 HDR 帧的分布先验。具体来说，HDR-LDM 结合了一种色调映射策略将 HDR 帧压缩到潜在空间中，以及一种新颖的曝光嵌入将曝光信息聚合到扩散过程中。然后，我们提出了一个时间一致性对齐模块 (TCAM) 来学习时间信息作为 HDR-LDM 的补充，该模块在视频帧之间以不同的尺度进行从粗到精的特征对齐。最后，我们设计了一种零初始化交叉注意 (ZiCA) 机制，以有效地整合学习到的分布先验和时间信息来生成 HDR 帧。大量实验验证了 HDR-V-Diff 在几个代表性数据集上实现了最先进的结果。 
**|
|**2024-06-12**|**Labeling Comic Mischief Content in Online Videos with a Multimodal Hierarchical-Cross-Attention Model**|[2406.07841](http://arxiv.org/abs/2406.07841)|**[link](https://github.com/RiTUAL-UH/Comic-Mischief-Prediction)**|我们解决了在线媒体中检测可疑内容的挑战，特别是有意搞怪的子类别。这类内容将暴力、成人内容或讽刺与幽默等元素结合在一起，使其难以被检测到。采用多模态方法对于捕捉有意搞怪内容中固有的微妙细节至关重要。为了解决这个问题，我们提出了一种用于有意搞怪检测任务的新型端到端多模态系统。作为这项贡献的一部分，我们发布了一个针对目标任务的新数据集，该数据集包含三种模态：视频、文本（视频字幕和隐藏式字幕）和音频。我们还设计了一种带有字幕的层次交叉注意模型（HICCAP），以捕捉这些模态之间的复杂关系。结果表明，与鲁棒的基线模型和用于有意搞怪检测及其类型分类的最先进模型相比，所提出的方法有了显著的改进。这强调了我们的系统赋能用户、使其能够对他们选择查看的在线内容做出明智决定的潜力。此外，我们在UCF101、HMDB51和XD-Violence数据集上进行了实验，将我们的模型与其他最先进的方法进行了比较，展示了我们提出的模型在各种场景下的出色性能。 
|
|**2024-06-11**|**M-LRM: Multi-view Large Reconstruction Model**|[2406.07648](http://arxiv.org/abs/2406.07648)|null|**尽管大型重建模型（LRM）最近取得了令人瞩目的成果，但当将其输入从单张图像扩展到多张图像时，它表现出效率低下、几何和纹理质量欠佳，以及收敛速度比预期慢等问题。这归因于LRM将3D重建视为一个简单的图像到3D的转换问题，而忽略了输入图像之间强大的3D一致性。在本文中，我们提出了一种多视图大型重建模型（M-LRM），旨在以3D感知的方式从多视图有效地重建高质量的3D形状。具体来说，我们引入了一种多视图一致性交叉注意机制，使M-LRM能够准确地从输入图像中查询信息。此外，我们利用输入多视图图像的3D先验信息来初始化三平面标记。与LRM相比，我们提出的M-LRM可以生成分辨率为128×128的三平面NeRF，并生成高保真度的3D形状。实验研究表明，与LRM相比，我们的模型实现了显著的性能提升和更快的训练收敛速度。项目页面：https://murphylmf.github.io/M-LRM/ 
**|
|**2024-06-11**|**MS-Diffusion: Multi-subject Zero-shot Image Personalization with Layout Guidance**|[2406.07209](http://arxiv.org/abs/2406.07209)|**[link](https://github.com/MS-Diffusion/MS-Diffusion)**|近年来，文本到图像生成模型的进步极大地增强了从文本提示生成逼真图像的能力，这导致人们对个性化文本到图像应用程序的兴趣日益浓厚，特别是在多主题场景中。然而，这些进步受到两个主要挑战的阻碍：首先，需要根据文本描述准确地维护每个参考主题的细节；其次，难以在单个图像中实现多个主题的 cohesive 表示，而不会引入不一致性。为了解决这些问题，我们的研究引入了 MS-Diffusion 框架，用于布局引导的零样本图像个性化与多主题。这种创新方法将 grounding tokens 与特征重采样器相结合，以保持主题之间的细节保真度。借助布局指导，MS-Diffusion 进一步改进了交叉注意力以适应多主题输入，确保每个主题条件作用于特定区域。所提出的多主题交叉注意力协调了和谐的主题间组合，同时保留了对文本的控制。全面的定量和定性实验表明，该方法在图像和文本保真度方面均优于现有模型，促进了个性化文本到图像生成的开发。 
|

<p align=right>(<a href=#updated-on-20240618>back to top</a>)</p>

## 3DGS

|Publish Date|Title|PDF|Code|Abstract|
|---|---|---|---|--------------------------------------------------|
|**2024-06-14**|**PUP 3D-GS: Principled Uncertainty Pruning for 3D Gaussian Splatting**|[2406.10219](http://arxiv.org/abs/2406.10219)|null|**最近，新颖视图合成的进步实现了实时渲染速度和高重建精度。三维高斯 splatting (3D-GS) 是一种基础的基于点的参数化三维场景表示方法，它将场景建模为大量三维高斯函数的集合。复杂的场景可能包含数百万个高斯函数，导致大量的存储和内存需求，这限制了 3D-GS 在资源有限的设备上的可行性。目前，通过修剪高斯函数来压缩这些预训练模型的技术依赖于结合启发式方法来确定要移除哪些高斯函数。在本文中，我们提出了一种基于原理的空间敏感性修剪评分，该评分优于这些方法。它被计算为训练视图上的重建误差相对于每个高斯函数的空间参数的二阶近似。此外，我们提出了一个多轮修剪-精炼流程，该流程可以应用于任何预训练的 3D-GS 模型，而无需更改训练流程。在修剪了 88.44% 的高斯函数后，我们观察到我们的 PUP 3D-GS 流程将 3D-GS 的平均渲染速度提高了 2.65 倍，同时保留了更多显著的前景信息，并在 Mip-NeRF 360、Tanks & Temples 和 Deep Blending 数据集的场景上实现了比以前的修剪技术更高的图像质量指标。**|
|**2024-06-14**|**GaussianSR: 3D Gaussian Super-Resolution with 2D Diffusion Priors**|[2406.10111](http://arxiv.org/abs/2406.10111)|null|**从低分辨率输入视图实现高分辨率新视角合成（HRNVS）是一项具有挑战性的任务，因为缺乏高分辨率数据。先前的方法从低分辨率输入视图优化高分辨率神经辐射场（NeRF），但渲染速度缓慢。在这项工作中，我们基于三维高斯散射（3DGS）来开发我们的方法，因为它能够以更快的渲染速度生成高质量的图像。为了缓解更高分辨率合成的数据短缺问题，我们建议利用现成的二维扩散先验，通过分数蒸馏采样（SDS）将二维知识提取到三维。然而，将 SDS 直接应用于基于高斯的 3D 超分辨率会导致不希望出现且冗余的 3D 高斯基元，这是由于生成先验带来的随机性。为了缓解这个问题，我们引入了两种简单而有效的技术来减少 SDS 引入的随机扰动。具体来说，我们 1）使用退火策略缩小 SDS 中扩散时间步长的范围；2）在密集化过程中随机丢弃冗余的高斯基元。大量实验表明，我们提出的 GaussainSR 仅需低分辨率输入，即可在合成数据集和真实世界数据集上获得高质量的 HRNVS 结果。项目页面：https://chchnii.github.io/GaussianSR/ 
**|
|**2024-06-14**|**GradeADreamer: Enhanced Text-to-3D Generation Using Gaussian Splatting and Multi-View Diffusion**|[2406.09850](http://arxiv.org/abs/2406.09850)|**[link](https://github.com/trapoom555/gradeadreamer)**|文本到3D生成已经展现出可观的结果，但仍然面临着一些常见的挑战，例如多面 Janus 问题以及生成高质量资源所需时间过长的问题。在本文中，我们通过引入一种名为 GradeADreamer 的新型三阶段训练流程来解决这些问题。该流程能够仅使用单个 RTX 3090 GPU 在 30 分钟内生成高质量的资源。我们提出的方法采用多视图扩散模型 MVDream 生成高斯球体作为先验，然后使用 StableDiffusion 优化几何形状和纹理。实验结果表明，与之前最先进的方法相比，我们的方法显著减轻了多面 Janus 问题，并实现了最高的平均用户偏好排名。项目代码可在 https://github.com/trapoom555/GradeADreamer 获取。 
|
|**2024-06-14**|**Unified Gaussian Primitives for Scene Representation and Rendering**|[2406.09733](http://arxiv.org/abs/2406.09733)|null|**在计算机图形学中，寻找一种统一的场景表示方法仍然是一个研究挑战。传统的基于网格的表示方法不适用于密集的模糊元素，并且为过滤和可微渲染引入了额外的复杂性。相反，基于体素的表示方法难以对硬表面进行建模，并且存在内存需求大的问题。我们提出了一种基于三维高斯分布的通用渲染基元，用于统一场景表示，其特点是具有从光滑表面到模糊元素的多种外观，以及基于物理的散射，以实现精确的全局照明。我们基于非指数传输制定了基元的渲染理论，并推导出与蒙特卡洛路径追踪兼容的高效渲染操作。新的表示方法可以从不同的来源转换而来，包括网格和三维高斯 splatting，并且由于其可微性，可以通过透射率优化进一步细化。我们展示了该表示方法在全局照明和外观编辑等各种渲染应用中的通用性，同时自然地支持任意照明条件。此外，我们将我们的表示方法与现有的体积表示方法进行了比较，突出了其在细节再现方面的效率。 
**|
|**2024-06-13**|**Modeling Ambient Scene Dynamics for Free-view Synthesis**|[2406.09395](http://arxiv.org/abs/2406.09395)|null|**我们介绍了一种从单目捕捉中动态合成自由视点环境场景的新方法，为观看体验带来沉浸式的质量。我们的方法建立在最近3D高斯散 splatting  (3DGS) 的进步基础上，可以忠实地重建复杂的静态场景。先前将3DGS扩展到表示动态的尝试仅限于有界场景或需要多摄像机捕捉，并且通常无法泛化到未见过的运动，从而限制了它们的实际应用。我们的方法通过利用环境运动的周期性来学习运动轨迹模型以及仔细的正则化来克服这些限制。我们还提出了一些重要的实用策略，以提高基线3DGS静态重建的视觉质量，并提高对GPU内存密集型学习至关重要的内存效率。我们展示了几个具有复杂纹理和精细结构元素的环境自然场景的高质量逼真新视图合成。 
**|
|**2024-06-13**|**GGHead: Fast and Generalizable 3D Gaussian Heads**|[2406.09377](http://arxiv.org/abs/2406.09377)|null|**从大型二维图像集合中学习三维头部先验信息是实现高质量三维感知人体建模的重要步骤。其核心要求是构建一种能够很好地扩展到大型数据集和高分辨率图像的高效架构。然而，现有的三维 GAN 由于其训练和渲染速度相对较慢，难以扩展到生成高分辨率样本，并且通常不得不依赖二维超分辨率网络，但这会牺牲全局三维一致性。为了解决这些挑战，我们提出了生成式高斯头部 (GGHead) 模型，该模型在三维 GAN 框架内采用了最新的三维高斯散射表示。为了生成三维表示，我们采用了一个强大的二维 CNN 生成器来预测模板头部网格的 UV 空间中的高斯属性。通过这种方式，GGHead 利用了模板 UV 布局的规律性，极大地促进了预测非结构化三维高斯集这一具有挑战性的任务。我们进一步通过一种新颖的渲染 UV 坐标上的总变差损失来提高生成的三维表示的几何保真度。直观地说，这种正则化鼓励相邻渲染像素应该源于模板 UV 空间中的相邻高斯。总而言之，我们构建的流程管道可以有效地生成仅从单视图二维图像观察中训练得到的三维头部。我们提出的框架在 FFHQ 上的质量与现有的三维头部 GAN 相匹配，同时速度明显更快且完全具有三维一致性。因此，我们首次展示了以 $1024^2$ 分辨率实时生成和渲染高质量、三维一致的头部。 
**|
|**2024-06-14**|**AV-GS: Learning Material and Geometry Aware Priors for Novel View Acoustic Synthesis**|[2406.08920](http://arxiv.org/abs/2406.08920)|null|**新视角声学合成 (NVAS) 旨在在给定三维场景中声源发出的单声道音频的情况下，渲染任意目标视点的双耳音频。现有方法提出了基于 NeRF 的隐式模型，以利用视觉线索作为合成双耳音频的条件。然而，除了 NeRF 渲染效率低下之外，这些方法在表征整个场景环境（如房间几何形状、材料属性以及听者和声源之间的空间关系）方面的能力都有限。为了解决这些问题，我们提出了一种新颖的视听高斯散射 (AV-GS) 模型。为了获得用于音频合成的材料感知和几何感知条件，我们学习了一种基于点的显式场景表示，并在局部初始化的高斯点上使用音频引导参数，同时考虑了听者和声源的空间关系。为了使视觉场景模型适应音频，我们提出了一种点密集和修剪策略，以优化高斯点的分布，并考虑每个点在声音传播中的贡献（例如，对于无纹理的墙壁表面需要更多点，因为它们会影响声音路径的偏转）。大量实验验证了我们的 AV-GS 在真实世界 RWAS 和基于模拟的 SoundSpaces 数据集上优于现有替代方案。 
**|
|**2024-06-13**|**Gaussian-Forest: Hierarchical-Hybrid 3D Gaussian Splatting for Compressed Scene Modeling**|[2406.08759](http://arxiv.org/abs/2406.08759)|null|**近年来，新视角合成领域出现了三维高斯 splatting 技术，该技术以基于点的方式表示场景并通过光栅化进行渲染。与依赖于光线追踪的辐射场相比，这种方法展现出更优越的渲染质量和速度。然而，三维高斯的显式和非结构化性质带来了巨大的存储挑战，阻碍了其更广泛的应用。为了应对这一挑战，我们引入了高斯森林建模框架，该框架将场景分层表示为混合三维高斯森林。每个混合高斯保留其独特的显式属性，同时与其兄弟高斯共享隐式属性，从而以更少的变量优化参数化。此外，我们设计了自适应增长和修剪策略，确保在复杂区域的详细表示，并显著减少所需高斯的数量。大量实验表明，高斯森林不仅保持了相当的速度和质量，而且实现了超过10倍的压缩率，标志着高效场景建模的重大进步。代码可在 https://github.com/Xian-Bei/GaussianForest 获取。 
**|
|**2024-06-12**|**ICE-G: Image Conditional Editing of 3D Gaussian Splats**|[2406.08488](http://arxiv.org/abs/2406.08488)|null|**近年来，出现了许多创建高质量3D资产和场景的技术。然而，在编辑这些对象时，现有方法要么速度慢，要么在质量上妥协，要么没有提供足够的自定义选项。我们介绍了一种从单个参考视图快速编辑3D模型的新方法。我们的技术首先分割编辑图像，然后使用DINO特征匹配所选分割数据集视图中语义对应的区域。然后，可以以语义合理的方式将来自编辑图像特定区域的颜色或纹理变化自动应用于其他视图。这些编辑后的视图充当更新后的数据集，以进一步训练和重新样式化3D场景。最终结果是一个经过编辑的3D模型。我们的框架支持各种编辑任务，例如手动局部编辑、基于对应的任意示例图像的风格迁移，以及来自多个示例图像的不同风格的组合。我们使用高斯样条作为我们的主要3D表示，因为它速度快且易于局部编辑，但我们的技术也适用于其他方法，例如NeRFs。我们通过多个示例展示了我们的方法在提供细粒度编辑控制的同时，可以产生更高质量的结果。项目页面：ice-gaussian.github.io 
**|
|**2024-06-12**|**Human 3Diffusion: Realistic Avatar Creation via Explicit 3D Consistent Diffusion Models**|[2406.08475](http://arxiv.org/abs/2406.08475)|null|**从单张RGB图像创建逼真的人物化身是一个吸引人但极具挑战性的问题。由于其不适定性，最近的工作利用了在大数据集上预训练的二维扩散模型的强大先验。尽管二维扩散模型表现出强大的泛化能力，但它们无法提供具有保证三维一致性的多视图形状先验。我们提出了Human 3Diffusion：通过显式三维一致性扩散创建逼真的人物化身。我们的主要见解是，二维多视图扩散和三维重建模型相互提供补充信息，通过将它们紧密耦合，我们可以充分利用两种模型的潜力。我们引入了一种新颖的图像条件生成式三维高斯 splat 重建模型，它利用了二维多视图扩散模型的先验，并提供了显式三维表示，进一步指导二维逆向采样过程以获得更好的三维一致性。实验表明，我们提出的框架优于最先进的方法，并且能够从单张RGB图像创建逼真的人物化身，在几何形状和外观方面均实现了高保真度。大量的消融实验也验证了我们设计的有效性，(1) 生成式三维重建中的多视图二维先验条件和 (2) 通过显式三维表示对采样轨迹进行一致性细化。我们的代码和模型将在https://yuxuan-xue.com/human-3diffusion上发布。 
**|

<p align=right>(<a href=#updated-on-20240618>back to top</a>)</p>

## 3D/CG

|Publish Date|Title|PDF|Code|Abstract|
|---|---|---|---|--------------------------------------------------|
|**2024-06-14**|**A Two-Stage Masked Autoencoder Based Network for Indoor Depth Completion**|[2406.09792](http://arxiv.org/abs/2406.09792)|**[link](https://github.com/kailaisun/indoor-depth-completion)**|深度图像在三维重建、自动驾驶、增强现实、机器人导航和场景理解等领域有着广泛的应用。消费级深度相机难以感知明亮、光滑、透明和远处表面的深度。尽管现有的深度补全方法已经取得了显著进展，但当应用于复杂的室内场景时，它们的性能仍然有限。为了解决这些问题，我们提出了一种基于两阶段Transformer的室内深度补全网络。与现有的深度补全方法不同，我们采用了一种基于掩码自编码器的自监督预训练编码器，以学习缺失深度值的有效潜在表示；然后，我们提出了一个基于标记融合机制的解码器，从联合RGB和不完整深度图像中完成（即重建）完整深度。与现有方法相比，我们提出的网络在Matterport3D数据集上实现了最先进的性能。此外，为了验证深度补全任务的重要性，我们将我们的方法应用于室内三维重建。代码、数据集和演示可在https://github.com/kailaisun/Indoor-Depth-Completion获取。 
|
|**2024-06-14**|**Grounding Image Matching in 3D with MASt3R**|[2406.09756](http://arxiv.org/abs/2406.09756)|null|**图像匹配是所有高性能三维视觉算法和流程中的核心组成部分。然而，尽管匹配本质上是一个与相机位姿和场景几何密切相关的3D问题，但它通常被视为一个2D问题。这看似合理，因为匹配的目标是在2D像素域之间建立对应关系，但也可能是一个危险的选择。在这项工作中，我们采取了不同的立场，并建议将匹配视为一项3D任务，并使用DUSt3R——一个最近出现的强大的基于Transformer的3D重建框架。基于点图回归，该方法在匹配具有极端视角变化的视图时表现出令人印象深刻的鲁棒性，但精度有限。我们的目标是在保持其鲁棒性的同时，提高这种方法的匹配能力。因此，我们建议使用一个新的输出密集局部特征的头部来增强DUSt3R网络，并使用额外的匹配损失进行训练。我们进一步解决了密集匹配的二次复杂度问题，如果处理不当，这将导致下游应用的速度非常慢。我们引入了一种快速的reciprocal匹配方案，它不仅将匹配速度提高了几个数量级，而且还具有理论上的保证，最后还能产生更好的结果。大量实验表明，我们提出的MASt3R方法在多个匹配任务上明显优于现有技术。特别是，在极具挑战性的无地图定位数据集上，它在VCRE AUC指标上比已发表的最佳方法提高了30%（绝对改进）。 
**|
|**2024-06-13**|**ImageNet3D: Towards General-Purpose Object-Level 3D Understanding**|[2406.09613](http://arxiv.org/abs/2406.09613)|**[link](https://github.com/wufeim/imagenet3d)**|一个具有通用目标级3D理解能力的视觉模型应该能够推断自然图像中任意刚性物体的2D（例如，类别名称和边界框）和3D信息（例如，3D位置和3D视角）。这是一项具有挑战性的任务，因为它涉及从2D信号推断3D信息，最重要的是，要泛化到来自未见类别的刚性物体。然而，现有的具有目标级3D标注的数据集往往受到类别数量或标注质量的限制。在这些数据集上开发的模型成为某些类别或领域的专家，并且无法泛化。在这项工作中，我们提出了ImageNet3D，一个用于通用目标级3D理解的大型数据集。ImageNet3D使用2D边界框、3D姿态、3D位置标注以及穿插3D信息的图像描述，增强了ImageNet数据集中200个类别。借助ImageNet3D中可用的新标注，我们可以（i）分析视觉基础模型的目标级3D感知能力，（ii）研究和开发能够推断自然图像中任意刚性物体2D和3D信息的通用模型，以及（iii）将统一的3D模型与大型语言模型集成，进行3D相关推理。除了标准的分类和姿态估计之外，我们还考虑了两个新任务，即目标级3D感知探测和开放词汇姿态估计。在ImageNet3D上的实验结果证明了我们的数据集在构建具有更强通用目标级3D理解能力的视觉模型方面的潜力。 
|
|**2024-06-13**|**Multiagent Multitraversal Multimodal Self-Driving: Open MARS Dataset**|[2406.09383](http://arxiv.org/abs/2406.09383)|null|**大规模数据集推动了基于人工智能的自动驾驶汽车研究的最新进展。然而，这些数据集通常是从一辆汽车对某个地点的一次性通行中收集的，缺乏多智能体交互或对同一地点的重复遍历。这些信息可以改变自动驾驶汽车的感知、预测和规划能力。为了弥合这一差距，我们与自动驾驶公司May Mobility合作，推出了MARS数据集，该数据集统一了支持多智能体、多路线和多模态自动驾驶汽车研究的场景。更具体地说，MARS是通过在特定地理区域内行驶的车队收集的。每辆车都有自己的路线，不同的车辆可能会出现在附近的地点。每辆车都配备了激光雷达和环视RGB摄像头。我们在MARS中策划了两个子集：一个子集通过同时出现在同一地点的多辆车辆促进协作驾驶，另一个子集通过多辆车辆对同一地点的异步遍历实现记忆回溯。我们进行了地点识别和神经重建实验。更重要的是，MARS引入了新的研究机会和挑战，例如多路线三维重建、多智能体感知和无监督目标发现。我们的数据和代码可以在https://ai4ce.github.io/MARS/找到。**|
|**2024-06-13**|**LRM-Zero: Training Large Reconstruction Models with Synthesized Data**|[2406.09371](http://arxiv.org/abs/2406.09371)|null|**我们提出了LRM-Zero，一个完全基于合成三维数据训练的大型重建模型（LRM），实现了高质量的稀疏视图三维重建。LRM-Zero的核心是我们程序化的三维数据集Zeroverse，它是从简单的基本形状自动合成的，具有随机纹理和增强功能（例如，高度场、布尔差和线框）。与之前的三维数据集（例如，Objaverse）通常由人类捕捉或制作以逼近真实三维数据不同，Zeroverse完全忽略了现实的全局语义，但包含了复杂的几何和纹理细节，这些细节在局部上与真实物体相似，甚至比真实物体更复杂。我们证明了，使用完全合成的Zeroverse训练的LRM-Zero可以在真实世界物体的重建中实现高视觉质量，与在Objaverse上训练的模型相比具有竞争力。我们还分析了Zeroverse的几个关键设计选择，这些选择有助于LRM-Zero的能力和训练稳定性。我们的工作表明，三维重建作为三维视觉的核心任务之一，有可能在没有真实世界物体语义的情况下得到解决。Zeroverse的程序化合成代码和交互式可视化可在以下网址获得：https://desaixie.github.io/lrm-zero/。 
**|
|**2024-06-13**|**OpenMaterial: A Comprehensive Dataset of Complex Materials for 3D Reconstruction**|[2406.08894](http://arxiv.org/abs/2406.08894)|null|**近年来，神经辐射场和隐式神经表示等深度学习技术的进步极大地推动了三维重建领域的发展。然而，由于金属和玻璃等具有独特镜面反射和透光特性的复杂光学属性，准确重建此类物体仍然是一项艰巨的挑战。为了促进解决这些挑战的方案的开发，我们引入了OpenMaterial数据集，该数据集包含1001个由295种不同材料（包括导体、电介质、塑料及其粗糙变体）制成的物体，并在723种不同的照明条件下捕获。为此，我们利用基于物理的渲染技术，结合实验室测量的折射率（IOR），生成了高度逼真的多视图图像，逼真地复制了真实世界的物体。OpenMaterial提供了全面的注释，包括三维形状、材料类型、相机姿态、深度和物体掩模。它是第一个能够对具有多种多样且具有挑战性的材料的物体进行现有算法的定量评估的大规模数据集，从而为开发能够处理复杂材料属性的三维重建算法铺平了道路。 
**|
|**2024-06-12**|**Human 3Diffusion: Realistic Avatar Creation via Explicit 3D Consistent Diffusion Models**|[2406.08475](http://arxiv.org/abs/2406.08475)|null|**从单个RGB图像创建逼真的人物化身是一个吸引人但充满挑战性的问题。由于其不适定性，最近的工作利用了在大型数据集上预训练的二维扩散模型的强大先验。尽管二维扩散模型表现出强大的泛化能力，但它们无法提供具有保证三维一致性的多视图形状先验。我们提出了Human 3Diffusion：通过显式三维一致性扩散创建逼真的人物化身。我们的主要见解是，二维多视图扩散和三维重建模型相互提供补充信息，通过将它们紧密耦合，我们可以充分利用两种模型的潜力。我们介绍了一种新颖的图像条件生成式三维高斯样条重建模型，它利用了来自二维多视图扩散模型的先验，并提供了一个显式的三维表示，进一步指导二维反向采样过程以获得更好的三维一致性。实验表明，我们提出的框架优于最先进的方法，并且能够从单个RGB图像创建逼真的人物化身，在几何形状和外观方面都实现了高保真度。广泛的消融实验也验证了我们设计的有效性，(1) 生成式三维重建中的多视图二维先验条件和 (2) 通过显式三维表示对采样轨迹进行一致性细化。我们的代码和模型将在https://yuxuan-xue.com/human-3diffusion上发布。 
**|
|**2024-06-12**|**Category-level Neural Field for Reconstruction of Partially Observed Objects in Indoor Environment**|[2406.08176](http://arxiv.org/abs/2406.08176)|null|**神经隐式表示法在 3D 重建领域取得了诸多成功案例，因此备受关注。为了进一步应用于场景理解或编辑等领域，一些研究已在目标组合重建方面取得进展。尽管它们在已观察区域表现出色，但在重建部分观察到的目标时仍然存在局限性。为了更好地解决这个问题，我们引入了类别级神经场，它可以学习场景中属于同一类别的目标之间有意义的共同 3D 信息。我们的关键思想是根据目标的观察形状对其进行子分类，以便更好地训练类别级模型。然后，我们利用神经场来执行极具挑战性的部分观察目标配准任务，方法是通过基于射线的度量选择代表性目标并与其对齐。在仿真和真实世界数据集上的实验表明，我们的方法改进了多个类别中未观察部分的重建效果。 
**|
|**2024-06-11**|**M-LRM: Multi-view Large Reconstruction Model**|[2406.07648](http://arxiv.org/abs/2406.07648)|null|**尽管大型重建模型（LRM）最近取得了令人瞩目的进展，但当将其输入从单张图像扩展到多张图像时，它表现出效率低下、几何和纹理质量欠佳以及收敛速度低于预期等问题。这归因于LRM将三维重建视为一个简单的图像到三维的转换问题，而忽略了输入图像之间强大的三维一致性。在本文中，我们提出了一个多视图大型重建模型（M-LRM），旨在以一种三维感知的方式从多视图有效地重建高质量的三维形状。具体来说，我们引入了一种多视图一致性交叉注意机制，使M-LRM能够准确地从输入图像中查询信息。此外，我们利用输入多视图图像的三维先验信息来初始化三平面token。与LRM相比，我们提出的M-LRM可以生成分辨率为128×128的三平面NeRF，并生成高保真度的三维形状。实验研究表明，与LRM相比，我们的模型实现了显著的性能提升和更快的训练收敛速度。项目页面：https://murphylmf.github.io/M-LRM/ 
**|
|**2024-06-11**|**NeRSP: Neural 3D Reconstruction for Reflective Objects with Sparse Polarized Images**|[2406.07111](http://arxiv.org/abs/2406.07111)|null|**我们提出了 NeRSP，一种利用稀疏偏振图像对反射表面进行神经三维重建的技术。反射表面的重建极具挑战性，因为镜面反射与视角相关，因此违反了多视点立体的多视点一致性。另一方面，稀疏图像输入作为一种实际的采集设置，由于缺乏对应匹配，通常会导致结果不完整或扭曲。本文利用偏振图像，共同应对稀疏输入和反射表面带来的挑战。我们从偏振图像形成模型和多视点方位角一致性中推导出光度和几何线索，这些线索共同优化了通过隐式神经表示建模的表面几何形状。根据我们对合成数据集和真实数据集的实验，我们仅用 6 个视图作为输入就实现了最先进的表面重建结果。 
**|

<p align=right>(<a href=#updated-on-20240618>back to top</a>)</p>

## 各类学习方式

|Publish Date|Title|PDF|Code|Abstract|
|---|---|---|---|--------------------------------------------------|
|**2024-06-14**|**Shelf-Supervised Multi-Modal Pre-Training for 3D Object Detection**|[2406.10115](http://arxiv.org/abs/2406.10115)|null|**目前最先进的三维物体探测器通常在大型标注数据集上进行训练。然而，标注三维边界框仍然非常昂贵且耗时，特别是对于激光雷达数据。因此，最近的研究表明，使用无标签数据进行自监督预训练可以提高有限标签情况下的检测精度。现有的方法将图像领域的自监督学习最佳实践（例如对比学习）应用于点云。然而，公开可用的三维数据集比用于基于图像的自监督学习的数据集要小得多，多样性也更低，这限制了其有效性。然而，我们注意到此类数据通常以多模态方式收集，通常与图像配对。我们认为，与其仅使用自监督目标进行预训练，不如使用在互联网规模图像数据上训练的基于图像的基础模型来引导点云表示。具体来说，我们提出了一种“货架式监督”方法（例如，使用现成的图像基础模型进行监督），用于从配对的 RGB 和激光雷达数据中生成零样本三维边界框。使用此类伪标签预训练三维探测器比先前的自监督预训练任务产生更好的半监督检测精度。重要的是，我们证明了基于图像的“货架式监督”有助于训练仅使用激光雷达和多模态（RGB + 激光雷达）的探测器。我们在 nuScenes 和 WOD 数据集上证明了我们方法的有效性，在有限的数据设置下显著优于先前的工作。 
**|
|**2024-06-14**|**InstructRL4Pix: Training Diffusion for Image Editing by Reinforcement Learning**|[2406.09973](http://arxiv.org/abs/2406.09973)|null|**基于指令的图像编辑在使用自然人类语言操作图像的视觉内容方面取得了巨大进展。然而，现有模型受到数据集质量的限制，无法准确地定位具有复杂对象关系的图像中的编辑区域。在本文中，我们提出了强化学习引导的图像编辑方法 (InstructRL4Pix)，以训练扩散模型生成由目标对象的注意力图引导的图像。我们的方法通过计算注意力图之间的距离作为奖励函数，并使用近端策略优化 (PPO) 微调扩散模型，从而最大化奖励模型的输出。我们在对象插入、移除、替换和转换方面评估了我们的模型。实验结果表明，InstructRL4Pix 打破了传统数据集的局限性，并使用无监督学习来优化编辑目标，并根据自然人类指令实现准确的图像编辑。 
**|
|**2024-06-14**|**Neural Concept Binder**|[2406.09949](http://arxiv.org/abs/2406.09949)|**[link](https://github.com/ml-research/neuralconceptbinder)**|基于对象的视觉推理的挑战在于生成既具有描述性又独特的概念表示。此外，以无监督的方式进行这一过程需要人类用户理解模型学习到的概念，并可能修正错误的概念。为了应对这一挑战，我们引入了神经概念绑定器，这是一个用于导出离散概念表示的新框架，我们将其称为“概念槽编码”。这些编码利用“软绑定”（通过以对象为中心的块-槽编码）和“硬绑定”（通过基于检索的推理）来实现。神经概念绑定器有助于直接的概念检查和外部知识的直接整合，例如人类输入或其他人工智能模型（如GPT-4）的见解。此外，我们证明了结合硬绑定机制不会影响性能；相反，它能够无缝集成到神经和符号模块中，以完成复杂的推理任务，这一点在我们新推出的CLEVR-Sudoku数据集的评估中得到了证明。 
|
|**2024-06-14**|**Forgetting Order of Continual Learning: Examples That are Learned First are Forgotten Last**|[2406.09935](http://arxiv.org/abs/2406.09935)|null|**灾难性遗忘是持续学习中的一个重大挑战，模型在学习新数据时经常忘记之前的任务。我们的实证分析表明，灾难性遗忘与样本的学习速度密切相关：早期学习的样本很少被遗忘，而后期学习的样本更容易被遗忘。我们证明，基于重放的持续学习方法可以利用这种现象，通过关注中等学习速度的样本进行复习。我们介绍了一种名为“金发姑娘”（Goldilocks）的新型重放缓冲区采样方法，它过滤掉学习速度过快或过慢的样本，保留那些以中等速度学习的样本。金发姑娘改进了现有的持续学习算法，在多个图像分类任务中取得了最先进的性能。 
**|
|**2024-06-17**|**Exploring the Benefits of Vision Foundation Models for Unsupervised Domain Adaptation**|[2406.09896](http://arxiv.org/abs/2406.09896)|**[link](https://github.com/tue-mps/vfm-uda)**|在计算机视觉领域，实现跨不同数据域的稳健泛化仍然是一项重大挑战。这一挑战在安全关键型应用中尤为重要，因为在这些应用中，基于深度神经网络的系统必须在训练期间未见过的各种环境条件下可靠地运行。我们的研究调查了视觉基础模型（VFM）和无监督域适应（UDA）方法在语义分割任务中的泛化能力是否互补。结果表明，将VFM与UDA相结合有两个主要好处：（a）它可以在保持VFM的分布外性能的同时，实现更好的UDA性能，以及（b）它使某些耗时的UDA组件变得多余，从而显著提高推理速度。具体来说，在模型大小相同的情况下，生成的VFM-UDA方法比之前的非VFM最先进方法实现了8.4倍的速度提升，同时在UDA设置中的性能提高了+1.2 mIoU，在分布外泛化方面提高了+6.1 mIoU。此外，当我们使用参数多3.6倍的VFM时，VFM-UDA方法保持了3.3倍的速度提升，同时将UDA性能提高了+3.1 mIoU，将分布外性能提高了+10.3 mIoU。这些结果强调了将VFM与UDA相结合的显著优势，为语义分割中的无监督域适应设定了新的标准和基线。 
|
|**2024-06-14**|**Federated Learning driven Large Language Models for Swarm Intelligence: A Survey**|[2406.09831](http://arxiv.org/abs/2406.09831)|null|**联邦学习 (FL) 为训练大型语言模型 (LLM) 提供了一个引人注目的框架，同时解决了数据隐私和去中心化挑战。本文综述了大型语言模型联邦学习的最新进展，特别关注机器遗忘，这是遵守“被遗忘权”等隐私法规的关键方面。在联邦 LLM 的背景下，机器遗忘涉及系统地、安全地从学习模型中删除个人数据贡献，而无需从头开始重新训练。我们探索了实现有效遗忘的各种策略，例如扰动技术、模型分解和增量学习，强调了它们对维护模型性能和数据隐私的影响。此外，我们还考察了近期文献中的案例研究和实验结果，以评估这些方法在现实场景中的有效性和效率。我们的调查显示，人们对开发更强大、更具可扩展性的联邦遗忘方法越来越感兴趣，这表明人工智能伦理与分布式机器学习技术交叉领域是未来研究的重要方向。 
**|
|**2024-06-14**|**GeoSEE: Regional Socio-Economic Estimation With a Large Language Model**|[2406.09799](http://arxiv.org/abs/2406.09799)|null|**超越传统的调查方式，将异构数据源与人工智能驱动的推理模型相结合，为衡量大范围地理区域的社会经济状况（如贫困和人口）带来了新的机遇。目前的研究提出了 GeoSEE，这是一种可以使用由大型语言模型 (LLM) 驱动的统一管道估算各种社会经济指标的方法。GeoSEE 接收一组不同的信息模块（包括从卫星图像预先构建的模块），并针对每个指标和国家/地区选择要使用的模块进行估算。此选择由 LLM 的先验社会地理知识指导，其功能类似于领域专家的见解。然后，系统在以基于自然语言的文本格式汇总来自所选模块的结果后，通过上下文学习计算目标指标。对处于不同发展阶段的国家/地区进行的全面评估表明，我们的方法在无监督和少样本情况下均优于其他预测模型。这种方法在数据匮乏的发展中国家或欠发达国家的可靠性能，以及其成本效益，凸显了其在全球范围内持续支持和监测可持续发展目标（如减贫和公平增长）进展的潜力。 
**|
|**2024-06-14**|**Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity**|[2406.09790](http://arxiv.org/abs/2406.09790)|null|**语义文本相似度（STS）是计算语言学的一个关键研究方向，是衡量嵌入模型编码能力的关键指标。在预训练语言模型和对比学习技术的推动下，领先的句子表示方法在 SentEval 的 7 个 STS 基准测试中已经可以达到约 86 的平均 Spearman 相关系数得分。然而，进一步的改进变得越来越微不足道，现有的方法在这些任务上的平均得分都没有超过 87。本文深入分析了这一现象，得出结论：使用对比学习的 Spearman 相关系数得分上限为 87.5。为了突破这一上限，我们提出了一种名为 Pcc-tuning 的创新方法，该方法采用皮尔逊相关系数作为损失函数，以优化模型性能，超越对比学习。实验结果表明，Pcc-tuning 明显优于以往最先进的策略，将 Spearman 相关系数得分提高到 90 以上。 
**|
|**2024-06-14**|**Unsupervised Monocular Depth Estimation Based on Hierarchical Feature-Guided Diffusion**|[2406.09782](http://arxiv.org/abs/2406.09782)|null|**无监督单目深度估计由于其无需真值即可训练的能力而受到广泛关注。在现实场景中，图像可能会由于天气条件和相机固有局限性的影响而变得模糊或噪声。因此，开发稳健的深度估计模型尤为重要。受益于生成网络的训练策略，基于生成的方法通常表现出增强的鲁棒性。鉴于此，我们采用生成网络中收敛性良好的扩散模型进行无监督单目深度估计。此外，我们提出了一种分层特征引导的去噪模块。该模块通过充分利用图像特征来指导去噪过程，显著丰富了模型学习和解释深度分布的能力。此外，我们探索了重投影中的隐式深度，并设计了一种隐式深度一致性损失。该损失函数用于增强模型的性能并确保视频序列内深度的尺度一致性。我们在 KITTI、Make3D 和我们自己收集的 SIMIT 数据集上进行了实验。结果表明，我们的方法在基于生成模型中表现出色，同时也展现出非凡的鲁棒性。 
**|
|**2024-06-14**|**Fine-Grained Urban Flow Inference with Multi-scale Representation Learning**|[2406.09710](http://arxiv.org/abs/2406.09710)|null|**细粒度城市流量推断 (FUFI) 是一项旨在提高交通效率和安全性的关键交通服务。FUFI 可以仅基于观察到的粗粒度数据推断出细粒度的城市交通流量。然而，大多数现有方法侧重于单尺度静态地理信息对 FUFI 的影响，而忽略了城市内不同尺度区域之间的相互作用和动态信息。不同尺度的地理特征可以从相同的空间区域捕获冗余信息。为了有效地学习跨越时间和空间的多尺度信息，我们提出了一种有效的细粒度城市流量推断模型 UrbanMSR，该模型使用自监督对比学习来获得邻域级和城市级地理信息的动态多尺度表示，并融合多尺度表示以提高细粒度精度。多尺度表示的融合增强了细粒度。我们通过对三个真实世界数据集的广泛实验来验证性能。与最先进方法相比，结果证明了所提出模型的优越性。 
**|

<p align=right>(<a href=#updated-on-20240618>back to top</a>)</p>

