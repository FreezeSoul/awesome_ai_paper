---
layout: default
---

## Updated on 2025.09.20
> Usage instructions: [here](./docs/README.md#usage)

## 多模态

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-09-18**|[Calibration-Aware Prompt Learning for Medical Vision-Language Models](http://arxiv.org/abs/2509.15226)|null|医用视觉-语言模型 (Med-VLM) 通过利用大规模图像-文本预训练，在各种医学影像任务中表现出卓越的性能。然而，它们的置信度校准在很大程度上尚未被探索，因此仍然是一个重大挑战。因此，未校准的预测可能导致过度自信的错误，从而损害临床信任和决策可靠性。为解决这个问题，我们引入了CalibPrompt，这是首个在提示微调期间校准Med-VLM的框架。CalibPrompt在标记数据稀缺的情况下，通过精心设计的校准目标，优化了一组少量的可学习提示。首先，我们研究了一种旨在将平滑准确度与预测模型置信度对齐的正则化器。其次，我们引入了一种角分离损失，以最大化文本特征接近度，从而提高多模态Med-VLM置信度估计的可靠性。在四个公开可用的Med-VLM和五个不同的医学影像数据集上进行的大量实验表明，CalibPrompt在不显著影响原始准确率的情况下持续改进了校准。我们的代码可在 https://github.com/iabh1shekbasu/CalibPrompt 获取。|
|**2025-09-18**|[Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation](http://arxiv.org/abs/2509.15225)|null|我们引入VocAlign，这是一种专为开放词汇语义分割中的视觉语言模型（VLM）设计的新型无源域适应框架。我们的方法采用师生范式，并辅以词汇对齐策略，通过引入额外的类别概念来改进伪标签生成。为确保效率，我们使用低秩适应（LoRA）来微调模型，在保留其原有能力的同时最小化计算开销。此外，我们为学生模型提出了一种Top-K类别选择机制，该机制显著降低了内存需求，同时进一步提升了适应性能。我们的方法在CityScapes数据集上实现了显著的6.11 mIoU提升，并在零样本分割基准上展现出卓越性能，为开放词汇设置下的无源域适应树立了新标杆。|
|**2025-09-18**|[ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data](http://arxiv.org/abs/2509.15221)|**[link](https://github.com/YangYzzzz/ScaleCUAWebCrawler)**|视觉-语言模型（VLMs）使得能够自主操作图形用户界面（GUIs）的计算机使用智能体（CUAs）成为可能，展现出巨大潜力，然而，进展受限于缺乏大规模、开源的计算机使用数据和基础模型。在这项工作中，我们介绍了ScaleCUA，这是迈向扩展开源CUA的一步。它提供了一个大规模数据集，涵盖6个操作系统和3个任务领域，该数据集通过结合自动化智能体和人类专家的闭环管道构建而成。经过这些扩展数据的训练，ScaleCUA能够跨平台无缝操作。具体而言，它在基线上取得了显著提升（WebArena-Lite-v2上提升26.6，ScreenSpot-Pro上提升10.7），并创造了新的SOTA（最先进）结果（MMBench-GUI L1-Hard上达到94.4%，OSWorld-G上达到60.6%，WebArena-Lite-v2上达到47.4%）。这些发现强调了数据驱动扩展对于通用计算机使用智能体而言的强大能力。我们将发布数据、模型和代码以促进未来的研究：https://github.com/OpenGVLab/ScaleCUA。|
|**2025-09-18**|[Generalizable Geometric Image Caption Synthesis](http://arxiv.org/abs/2509.15217)|null|多模态大语言模型具有多种实际应用，这些应用要求强大的推理能力。尽管取得了最新进展，这些模型在解决复杂几何问题方面仍然面临困难。一个关键挑战源于缺乏用于理解几何图像的高质量图像-文本对数据集。此外，大多数基于模板的数据合成流程通常无法泛化到超出其预定义模板的问题。在本文中，我们通过将可验证奖励强化学习（RLVR）这一互补过程引入数据生成流程，弥合了这一差距。通过采用RLVR来细化从50种基本几何关系合成的几何图像的描述，并利用源自数学问题解决任务的奖励信号，我们的流程成功捕获了几何问题解决的关键特征。这使得任务泛化能力更强，并带来了显著的改进。此外，即使在分布外场景中，所生成的数据集也增强了多模态大语言模型的通用推理能力，在MathVista和MathVerse数据集中使用非几何输入图像的统计、算术、代数和数值任务中，准确率提高了2.8%-4.8%，同时在MMMU数据集的艺术、设计、技术和工程任务中，准确率提高了2.4%-3.9%。|
|**2025-09-18**|[What's the Best Way to Retrieve Slides? A Comparative Study of Multimodal, Caption-Based, and Hybrid Retrieval Techniques](http://arxiv.org/abs/2509.15211)|null|幻灯片演示文稿作为弥合演示幻灯片和书面文档之间鸿沟的数字报告，是学术和企业环境中普遍的信息传达媒介。它们结合了文本、图像和图表的多模态特性，给检索增强生成系统带来了挑战，其中检索质量直接影响下游性能。传统的幻灯片检索方法通常涉及对不同模态进行单独索引，这会增加复杂性并可能丢失上下文信息。本文研究了各种有效的幻灯片检索方法，包括ColPali等视觉后期交互嵌入模型、视觉重排序器的使用，以及将密集检索与BM25结合并通过文本重排序器和倒数排名融合等融合方法进一步增强的混合检索技术。本文还评估了一种新颖的基于视觉-语言模型（VLM）的字幕生成流水线，该流水线与视觉后期交互技术相比，显著降低了嵌入存储需求，同时保持了可比的检索性能。我们的分析扩展到这些方法的实际方面，评估它们的运行时性能、存储需求以及检索效率，从而为选择和开发用于实际应用的高效鲁棒幻灯片检索系统提供了实用指导。|
|**2025-09-18**|[Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding](http://arxiv.org/abs/2509.15178)|null|时空视频定位（STVG）旨在根据输入的文本查询来定位视频中的时空管。在本文中，我们利用多模态大语言模型（MLLMs）来探索STVG中的零样本解决方案。我们揭示了关于MLLMs的两个关键见解：(1) MLLMs倾向于动态分配被称为“定位token”的特殊token，用于定位文本查询；(2) MLLMs经常由于无法充分整合文本查询中的线索（例如，属性、动作）进行推理而遭受次优的定位性能。基于这些见解，我们提出了一种基于MLLM的STVG零样本框架，其中包含新颖的分解时空高亮（DSTH）和时序增强组装（TAS）策略，以释放MLLMs的推理能力。DSTH策略首先将原始查询解耦为属性和动作子查询，用于在空间和时间上查询目标的存在。它随后使用一个新颖的logit引导重注意力（LRA）模块，通过正则化每个子查询的token预测，学习潜在变量作为空间和时间提示。这些提示分别突出属性和动作线索，引导模型的注意力到可靠的空间和时间相关的视觉区域。此外，由于属性子查询的空间定位应具有时间一致性，我们引入了TAS策略，利用原始视频帧和时序增强帧作为输入来组装预测，以帮助提高时间一致性。我们在各种MLLMs上评估了我们的方法，并表明它在三个常见的STVG基准测试中超越了SOTA方法。代码将可在https://github.com/zaiquanyang/LLaVA_Next_STVG获取。|
|**2025-09-18**|[An Evaluation-Centric Paradigm for Scientific Visualization Agents](http://arxiv.org/abs/2509.15160)|null|多模态大语言模型（MLLMs）的最新进展使得日益复杂的自主可视化智能体能够将用户意图转化为数据可视化。然而，衡量进展和比较不同智能体仍然具有挑战性，尤其是在科学可视化（SciVis）领域，因为缺乏用于评估实际能力的全面、大规模基准。本立场论文探讨了SciVis智能体所需的各种评估类型，概述了相关挑战，提供了一个简单的概念验证评估示例，并讨论了评估基准如何促进智能体的自我改进。我们倡导更广泛的合作，以开发一个SciVis智能体评估基准，该基准不仅能评估现有能力，而且能推动创新并激发该领域的未来发展。|
|**2025-09-18**|[Exploring How Audio Effects Alter Emotion with Foundation Models](http://arxiv.org/abs/2509.15151)|null|音频效果（FX），如混响、失真、调制和动态范围处理，在音乐聆听过程中塑造情感反应方面发挥着关键作用。虽然先前的研究已检验了低级音频特征与情感感知之间的联系，但音频FX对情感的系统性影响仍未得到充分探索。这项工作研究了如何利用基础模型——即在多模态数据上预训练的大规模神经网络架构——来分析这些效果。这些模型编码了音乐结构、音色和情感意义之间丰富的关联，为探究声音设计技术的情感影响提供了一个强大的框架。通过对深度学习模型中的嵌入应用各种探测方法，我们检验了音频FX与估计情感之间复杂、非线性的关系，揭示了与特定效果相关的模式，并评估了基础音频模型的鲁棒性。我们的发现旨在增进对音频制作实践感知影响的理解，对音乐认知、表演和情感计算具有启示意义。|
|**2025-09-18**|[From Pixels to Urban Policy-Intelligence: Recovering Legacy Effects of Redlining with a Multimodal LLM](http://arxiv.org/abs/2509.15132)|null|本文展示了多模态大语言模型 (MLLM) 如何拓展城市测量能力并支持基于地点的政策干预措施的跟踪。GPT-4o 利用结构化的“先推理后估计”流程在街景图像上推断出社区贫困和树冠覆盖，我们将其嵌入准实验设计中以评估20世纪30年代“红线政策”的遗留影响。GPT-4o 再现了“红线政策”预期的不利社会环境遗留影响，其估计结果与权威来源统计上无显著差异，并且它优于传统的基于像素的分割基线，这与整体场景推理能够提取超越单纯对象计数的更高阶信息的观点相符。这些结果将 MLLM 定位为政策级别的社区测量工具，并促使在更广泛的政策评估场景中进行验证。|
|**2025-09-18**|[Forecasting and Visualizing Air Quality from Sky Images with Vision-Language Models](http://arxiv.org/abs/2509.15076)|null|空气污染仍然是对公众健康和环境可持续性的严峻威胁，然而传统监测系统常受限于有限的空间覆盖范围和可及性。本文提出了一种人工智能驱动的智能体，该智能体基于天空图像预测环境空气污染水平，并利用生成建模合成逼真的污染情景可视化效果。我们的方法结合了统计纹理分析与监督学习进行污染分类，并利用视觉-语言模型（VLM）引导的图像生成来生成空气质量状况的可解释表示。生成的视觉效果模拟了不同程度的污染，为用户界面提供了基础，以提高透明度并支持明智的环境决策。这些输出可以无缝集成到智能应用中，旨在增强态势感知并鼓励基于实时预测的行为响应。我们使用城市天空图像数据集验证了我们的方法，并证明了其在污染水平估计和语义一致的视觉合成方面的有效性。系统设计进一步融入了以人为中心的用户体验原则，以确保空气质量预测的可访问性、清晰度和公众参与。为支持可扩展和节能的部署，未来的迭代将整合一种通过基于FPGA的增量学习进行增强的绿色CNN架构，从而实现边缘平台上的实时推理。|

## 大模型PEFT

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-09-18**|[Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation](http://arxiv.org/abs/2509.15225)|null|我们提出VocAlign，一种专门为开放词汇语义分割中的VLMs设计的、新颖的无源域适应框架。我们的方法采用学生-教师范式，并通过词汇对齐策略进行增强，该策略通过整合额外的类别概念来改进伪标签生成。为确保效率，我们使用低秩适应（LoRA）来微调模型，在保留其原始能力的同时最小化计算开销。此外，我们为学生模型提出了一种Top-K类别选择机制，该机制显著减少了内存需求，同时进一步提高了适应性能。我们的方法在CityScapes数据集上实现了显著的6.11 mIoU提升，并在零样本分割基准上表现出卓越性能，为开放词汇设置下的无源域适应树立了新标准。|
|**2025-09-18**|[Adaptive LoRA Experts Allocation and Selection for Federated Fine-Tuning](http://arxiv.org/abs/2509.15087)|null|大语言模型（LLM）在各种任务中展现出令人印象深刻的能力，但针对领域特定应用对其进行微调通常需要大量的领域特定数据，这些数据可能分布在多个组织中。联邦学习（FL）提供了一种保护隐私的解决方案，但在应用于LLM时面临计算限制的挑战。低秩适应（LoRA）已成为一种参数高效的微调方法，但单个LoRA模块往往难以处理跨越不同领域的异构数据。本文解决了联邦LoRA微调中的两个关键挑战：1. 确定跨异构客户端的LoRA专家的最优数量和分配；2. 使客户端能够根据其特定的数据特征选择性地利用这些专家。我们提出了FedLEASE（联邦自适应LoRA专家分配与选择），这是一种新颖的框架，它基于表示相似性自适应地聚类客户端，以分配和训练领域特定的LoRA专家。它还引入了一种自适应的top- $M$ 专家混合机制，允许每个客户端选择所利用专家的最优数量。我们在多样化的基准数据集上进行的广泛实验表明，FedLEASE在异构客户端设置中显著优于现有的联邦微调方法，同时保持了通信效率。|
|**2025-09-18**|[Explicit vs. Implicit Biographies: Evaluating and Adapting LLM Information Extraction on Wikidata-Derived Texts](http://arxiv.org/abs/2509.14943)|null|文本隐含性在自然语言处理（NLP）中一直是一个挑战，传统方法依赖于显式陈述来识别实体及其关系。从“Zuhdi attends church every Sunday”这句话中，Zuhdi与基督教之间的关系对于人类读者来说是显而易见的，但当必须自动推断时，这便构成了一个挑战。大语言模型（LLMs）已被证明在文本理解和信息抽取（IE）等NLP下游任务中是有效的。本研究考察了文本隐含性如何影响LLaMA 2.3、DeepSeekV1和Phi1.5等预训练大语言模型的信息抽取任务。我们生成了包含1万条传记信息的隐含和显式表述的两个合成数据集，以衡量其对LLM性能的影响，并分析微调隐含数据是否能提高模型在隐含推理任务中的泛化能力。本研究展示了一项关于LLMs在信息抽取中内部推理过程的实验，特别是在处理隐含和显式上下文方面。结果表明，使用LoRA（低秩适应）对LLM模型进行微调可提高其从隐含文本中抽取信息的性能，有助于提高模型的可解释性和可靠性。|
|**2025-09-18**|[LLM4MG: Adapting Large Language Model for Multipath Generation via Synesthesia of Machines](http://arxiv.org/abs/2509.14711)|null|基于机器联觉（SoM），首次将大语言模型（LLM）应用于多径生成（LLM4MG）。针对典型的第六代（6G）车-基础设施（V2I）场景，构建了一个新的多模态感知-通信数据集，命名为SynthSoM-V2I，其中包含信道多径信息、毫米波（mmWave）雷达感知数据、RGB-D图像和光探测与测距（LiDAR）点云。基于SynthSoM-V2I数据集，所提出的LLM4MG利用大语言模型Meta AI (LLaMA) 3.2通过多模态感知数据进行多径生成。所提出的LLM4MG通过特征提取和融合网络，将多模态特征空间与LLaMA语义空间对齐。为进一步实现从预训练LLaMA到通过多模态感知数据进行多径生成的通用知识迁移，本文利用了低秩适应（LoRA）参数高效微调和传播感知提示工程。仿真结果表明，所提出的LLM4MG在视距（LoS）/非视距（NLoS）分类方面（准确率达92.76%）、多径功率/时延生成精度方面（归一化均方误差（NMSE）分别为0.099/0.032），以及跨车辆交通密度（VTD）、跨频段和跨场景泛化能力方面，均优于传统的基于深度学习的方法。所提出的LLM4MG的实用性通过真实世界泛化得到了验证。高精度多径生成对于系统设计的必要性也通过信道容量比较得到了证明。|
|**2025-09-18**|[Catch Me If You Can? Not Yet: LLMs Still Struggle to Imitate the Implicit Writing Styles of Everyday Authors](http://arxiv.org/abs/2509.14543)|**[link](https://github.com/jaaack-wang/llms-implicit-writing-styles-imitation)**|随着大型语言模型（LLMs）日益集成到个人写作工具中，一个关键问题浮出水面：LLMs能否仅凭少量示例忠实地模仿个人的写作风格？个人风格通常是微妙且隐含的，这使得它难以通过提示词明确指定，但对于生成与用户偏好对齐的内容至关重要。本研究对最先进的LLMs通过上下文学习（in-context learning）从少量用户撰写的样本中模仿个人写作风格的能力进行了全面评估。我们引入了一系列互补的评估指标——包括作者归属、作者验证、风格匹配和AI检测——以稳健地评估风格模仿能力。我们的评估涵盖了每个模型超过40000次的生成，跨越新闻、电子邮件、论坛和博客等领域，并包含了400多位真实作者的写作样本。结果表明，虽然LLMs能够近似新闻和电子邮件等结构化格式中的用户风格，但它们在处理博客和论坛中细致入微、非正式的写作时表现不佳。对各种提示策略（例如示例数量）的进一步分析揭示了有效个性化方面的关键局限性。我们的发现强调了个性化LLM适应方面存在的根本性差距，以及需要改进技术来支持隐含的、风格一致的生成。为了帮助未来的研究并提高可复现性，我们开源了我们的数据和代码。|
|**2025-09-18**|[CLAIP-Emo: Parameter-Efficient Adaptation of Language-supervised models for In-the-Wild Audiovisual Emotion Recognition](http://arxiv.org/abs/2509.14527)|null|真实场景下的视听情感识别（AVER）仍受姿态变化、遮挡和背景噪声的阻碍。现有方法主要依赖于大规模领域特定预训练，这成本高昂且通常与真实世界的情感数据不匹配。为解决此问题，我们提出了CLAIP-Emo，一个模块化框架，它将真实场景下的AVER重新定义为语言监督基础模型（CLIP/CLAP）的参数高效适应。具体而言，它（i）通过冻结CLIP/CLAP骨干网络并通过LoRA进行情感导向适应（更新总参数的\ensuremath{\le}4.0%）来保留语言监督先验知识，（ii）非对称地分配时间建模，采用轻量级Transformer处理视觉动态，同时对音频韵律应用均值池化，以及（iii）应用一个简单的融合头进行预测。在DFEW和MAFW数据集上，CLAIP-Emo (ViT-L/14) 仅用8M训练参数就达到了80.14%和61.18%的加权平均召回率，创造了新的最先进水平。我们的发现表明，语言监督基础模型的参数高效适应为真实场景下的AVER提供了一种可扩展的替代方案，以替代领域特定预训练。代码和模型将在此处提供：\href{https://github.com/MSA-LMC/CLAIP-Emo}{https://github.com/MSA-LMC/CLAIP-Emo}。|
|**2025-09-17**|[Large Language Model-Empowered Decision Transformer for UAV-Enabled Data Collection](http://arxiv.org/abs/2509.13934)|null|部署无人机 (UAV) 从空间分布设备进行可靠且节能的数据收集，在支持多样化的物联网 (IoT) 应用方面具有巨大潜力。然而，无人机有限的续航能力和通信范围使得智能轨迹规划成为必要。尽管强化学习 (RL) 已被广泛探索用于无人机轨迹优化，但其交互性在真实世界环境中带来了高成本和高风险。离线 RL 缓解了这些问题，但仍易受不稳定训练影响，并高度依赖专家质量数据集。为解决这些挑战，我们提出了一个无人机轨迹规划与资源分配联合问题，以最大化数据收集的能源效率。资源分配子问题首先被转化为等价的线性规划公式，并以多项式时间复杂度得到最优解。随后，我们提出了一个大型语言模型 (LLM) 赋能的批评者正则化决策 Transformer (DT) 框架，称之为 LLM-CRDT，以学习有效的无人机控制策略。在 LLM-CRDT 中，我们整合了批评者网络来正则化 DT 模型训练，从而将 DT 的序列建模能力与基于批评者的价值指导相结合，以实现从次优数据集中学习有效策略。此外，为缓解 Transformer 模型对数据的高需求特性，我们采用预训练 LLM 作为 DT 模型的 Transformer 主干，并采纳参数高效微调策略 LoRA，从而在小规模数据集和低计算开销下实现对无人机控制任务的快速适应。大量仿真表明，LLM-CRDT 优于基准在线和离线 RL 方法，与当前最先进的 DT 方法相比，能源效率提高高达 36.7%。|
|**2025-09-17**|[Mixture of Low-Rank Adapter Experts in Generalizable Audio Deepfake Detection](http://arxiv.org/abs/2509.13878)|null|Wav2Vec2等基础模型在语音任务（包括音频深度伪造检测）中的表征学习方面表现出色。然而，在对一组固定的真实和伪造音频片段进行微调后，它们通常无法泛化到训练中未出现的新颖深度伪造方法。为解决此问题，我们提出了一种LoRA专家混合方法，该方法将多个低秩适配器（LoRA）集成到模型的注意力层中。一种路由机制选择性地激活专门的专家，从而增强了对不断演变的深度伪造攻击的适应性。实验结果表明，我们的方法在域内和域外场景中均优于标准微调，相对于基线模型降低了等错误率。值得注意的是，我们最佳的MoE-LoRA模型将平均域外EER从8.55%降低到6.08%，证明了其在实现可泛化的音频深度伪造检测方面的有效性。|
|**2025-09-18**|[Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications](http://arxiv.org/abs/2509.13775)|null|本文探讨了我们对阿拉伯方言识别 (ADI) 中不同数据高效和参数高效方法的探索。具体来说，我们研究了各种软提示策略，包括 prefix-tuning、prompt-tuning、P-tuning 和 P-tuning V2，以及 LoRA 重参数化。对于数据高效策略，我们分析了结合零样本和少样本推理的硬提示，以分析大型语言模型 (LLMs) 的方言识别能力。对于参数高效的 PEFT 方法，我们使用阿拉伯语专用的编码器模型在几个主要数据集上进行了实验。我们还在开源的仅解码器模型、一个通用多语言模型 (Phi-3.5) 和一个阿拉伯语专用模型 (SILMA) 上分析了 n-shot 推理。我们观察到，LLMs 在少样本或零样本设置中通常难以区分方言细微差别。软提示编码器变体表现更好，而基于 LoRA 的微调模型表现最佳，甚至超越了完全微调。|
|**2025-09-17**|[Latent Traits and Cross-Task Transfer: Deconstructing Dataset Interactions in LLM Fine-tuning](http://arxiv.org/abs/2509.13624)|null|大语言模型正越来越多地部署到各种应用中。这通常包括大语言模型在训练期间未曾遇到的任务。这意味着枚举并获取所有任务的高质量训练数据是不可行的。因此，我们通常需要依赖于使用具有不同特征的数据集的迁移学习，并预测分布外请求。受此实际需求的启发，我们提出了一个分析框架，通过构建迁移学习矩阵和降维来剖析这些跨任务交互。我们训练并分析了10个模型，以识别潜在能力（例如，推理、情感分类、自然语言理解、算术）并发现迁移学习的副作用。我们的发现揭示，性能提升往往难以用基于表层数据集相似性或源数据质量的解释来阐明。相反，源数据集的隐藏统计因素，例如类别分布和生成长度倾向性，以及特定的语言特征，实际上更具影响力。这项工作为理解迁移学习的复杂动态提供了见解，为更可预测和更有效的大语言模型适应铺平了道路。|

## 大模型强化学习

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-09-18**|[Generalizable Geometric Image Caption Synthesis](http://arxiv.org/abs/2509.15217)|null|多模态大语言模型拥有各种要求强大推理能力的实际应用。尽管最近取得了进展，这些模型在解决复杂几何问题方面仍然面临挑战。一个关键挑战源于缺乏用于理解几何图像的高质量图像-文本对数据集。此外，大多数基于模板的数据合成管道通常无法泛化到超出其预定义模板的问题。在本文中，我们通过将可验证奖励强化学习 (RLVR) 这一互补过程引入数据生成管道来弥补这一空白。通过采用RLVR来细化从50种基本几何关系合成的几何图像的描述，并利用源自数学问题解决任务的奖励信号，我们的管道成功捕捉了几何问题解决的关键特征。这使得任务泛化能力得到提升，并带来了显著改进。此外，即使在分布外场景中，所生成的数据集也增强了多模态大语言模型的通用推理能力，在MathVista和MathVerse数据集中针对非几何输入图像的统计、算术、代数和数值任务中，准确率提高了2.8%-4.8%，同时在MMMU的艺术、设计、技术和工程任务中也实现了2.4%-3.9%的改进。|
|**2025-09-18**|[FlowRL: Matching Reward Distributions for LLM Reasoning](http://arxiv.org/abs/2509.15207)|null|我们提出FlowRL：在大语言模型（LLM）强化学习（RL）中，通过流平衡来匹配完整的奖励分布，而非最大化奖励。近期的先进推理模型采用奖励最大化方法（例如，PPO和GRPO），这些方法倾向于过度优化主导奖励信号，同时忽视不那么频繁但有效的推理路径，从而降低了多样性。相比之下，我们将标量奖励转换为使用可学习配分函数的归一化目标分布，然后最小化策略与目标分布之间的逆KL散度。我们将这一思想实现为一种流平衡优化方法，该方法促进多样化探索和可泛化的推理轨迹。我们在数学和代码推理任务上进行了实验：FlowRL在数学基准测试中，相较于GRPO平均实现了10.0%的显著提升，相较于PPO平均实现了5.1%的显著提升，并在代码推理任务上表现持续更好。这些结果突出表明，奖励分布匹配是迈向LLM强化学习中高效探索和多样化推理的关键一步。|
|**2025-09-18**|[Evolving Language Models without Labels: Majority Drives Selection, Novelty Promotes Variation](http://arxiv.org/abs/2509.15194)|**[link](https://github.com/YujunZhou/EVOL-RL)**|大型语言模型（LLM）正越来越多地通过基于可验证奖励的强化学习（RLVR）进行训练，然而，实际部署需要模型能够在没有标签或外部评判的情况下进行自我改进。现有的无标签方法，如置信度最小化、自我一致性或多数投票目标，能稳定学习但会逐渐减少探索，导致熵坍塌：生成内容变得更短、多样性降低且脆弱。与先前方法（例如测试时强化学习（TTRL），其主要使模型适应当前的无标签数据集）不同，我们的目标更广阔：在不牺牲模型固有的探索能力和泛化能力（即进化）的情况下实现普遍改进。我们形式化了这个问题，并提出了面向进化的无标签强化学习（EVOL-RL），它是一种在无标签设置下将稳定性与变异性相结合的简单规则。EVOL-RL将多数投票答案作为稳定锚点（选择），同时添加了新颖性感知奖励，该奖励偏好推理与已生成内容不同（变异）的响应，并在语义空间中进行衡量。EVOL-RL使用GRPO实现，还利用非对称裁剪来保留强信号和熵正则化器来维持探索。这种多数选择+新颖变异的设计可以防止坍塌，保持更长、信息量更大的思维链，并提高pass@1和pass@n。EVOL-RL持续优于仅基于多数投票的TTRL基线；例如，在无标签AIME24上训练，将Qwen3-4B-Base模型在AIME25上的pass@1从TTRL的4.6%提升到16.4%，pass@16从18.5%提升到37.9%。EVOL-RL不仅防止了多样性坍塌，还实现了更强的跨领域泛化能力（例如，GPQA）。此外，我们证明EVOL-RL在RLVR设置中也能提升性能，突显了其广泛适用性。|
|**2025-09-18**|[Self-Improving Embodied Foundation Models](http://arxiv.org/abs/2509.15155)|**[link](https://github.com/self-improving-efms/self-improving-efms.github.io)**|基于海量网络数据训练的基础模型彻底改变了机器人技术，但其在低级控制中的应用仍主要局限于行为克隆。借鉴大型语言模型微调中强化学习阶段的成功经验，我们提出了一种用于机器人的两阶段后训练方法。第一阶段为监督微调（SFT），它利用行为克隆和剩余步数预测目标来微调预训练的基础模型。在第二阶段，即自我改进阶段，剩余步数预测使得能够提取形态良好的奖励函数和鲁棒的成功检测器，从而使机器人集群能够在最少人工监督下自主练习下游任务。通过在真实世界和模拟机器人实体上进行的大量实验，我们新颖的后训练方案在具身基础模型上取得了显著成果。首先，我们证明了SFT和自我改进的结合比扩展监督学习的模仿数据收集效率显著更高，并能带来成功率显著提升的策略。进一步的消融实验强调，海量网络预训练和自我改进的结合是实现这种样本效率的关键。其次，我们证明了我们提出的组合独特地解锁了一种当前方法无法实现的能力：自主练习和获取新技能，这些技能的泛化能力远超训练中使用的模仿学习数据集中观察到的行为。这些发现突出了将预训练基础模型与在线自我改进相结合，以实现在机器人技术中自主技能获取的变革性潜力。我们的项目网站可在 https://self-improving-efms.github.io 找到。|
|**2025-09-18**|[Stochastic Bilevel Optimization with Heavy-Tailed Noise](http://arxiv.org/abs/2509.14952)|null|本论文研究了平滑双层优化问题，其中下层问题是强凸的，上层问题可能为非凸。我们关注随机设置，即算法可以访问带有重尾噪声的无偏随机梯度评估，这在许多机器学习应用中普遍存在，例如训练大型语言模型和强化学习。我们提出了一种嵌套循环归一化随机双层近似（N $^2$SBA）算法，用于找到一个$\epsilon$-驻点，其随机一阶预言机（SFO）复杂度为$\tilde{\mathcal{O}}\big(\kappa^{\frac{7p-3}{p-1}} \sigma^{\frac{p}{p-1}} \epsilon^{-\frac{4 p - 2}{p-1}}\big)$，其中$\kappa$是条件数，$p\in(1,2]$是噪声中心矩的阶数，$\sigma$是噪声水平。此外，我们将我们的思想专门应用于求解非凸-强凹极小极大优化问题，实现了$\epsilon$-驻点，其SFO复杂度为$\tilde{\mathcal O}\big(\kappa^{\frac{2p-1}{p-1}} \sigma^{\frac{p}{p-1}} \epsilon^{-\frac{3p-2}{p-1}}\big)$。上述所有上限在有界方差设置的特殊情况（即$p=2$ ）下均与已知最佳结果相匹配。|
|**2025-09-18**|[Empathy-R1: A Chain-of-Empathy and Reinforcement Learning Framework for Long-Form Mental Health Support](http://arxiv.org/abs/2509.14851)|null|同理心对于有效的心理健康支持至关重要，尤其是在处理长篇咨询文本（LCTs）时。然而，现有的大型语言模型（LLMs）通常生成的回复在语义上很流畅，但缺乏真正心理支持所需的结构化推理能力，尤其是在中文语境下。为了弥合这一鸿沟，我们引入了Empathy-R1，这是一个新颖的框架，它将同理心链（CoE）推理过程与强化学习（RL）相结合，以提升LCTs的回复质量。受认知行为疗法的启发，我们的CoE范式引导模型顺序推理求助者的情绪、原因和意图，使其思维过程既透明又可解释。我们的框架得益于一个新的大规模中文数据集Empathy-QA和两阶段训练过程。首先，监督微调灌输了CoE的推理结构。随后，在专用奖励模型的指导下，强化学习优化了最终回复的治疗相关性和上下文适宜性。实验表明，Empathy-R1在关键自动指标上取得了强大性能。更重要的是，人工评估证实了其优越性，显示出对强大基线的明显偏好，并在我们的新基准上实现了44.30%的Win@1比率。通过实现可解释且上下文细致入微的回复，Empathy-R1代表了在开发负责任且真正有益于心理健康支持的人工智能方面的一项重大进展。|
|**2025-09-18**|[ToolSample: Dual Dynamic Sampling Methods with Curriculum Learning for RL-based Tool Learning](http://arxiv.org/abs/2509.14718)|null|虽然强化学习（RL）越来越多地用于基于LLM的工具学习，但其效率常受到过多的简单样本的阻碍，这些样本随着训练的进行提供的学习价值逐渐递减。现有的动态采样技术不适用于工具学习固有的多任务结构和细粒度奖励机制。本文提出了带有课程学习的动态采样（DSCL）框架，该框架专门设计用于解决这一挑战，通过针对工具学习的独特特点：其多个相互依赖的子任务和多值奖励函数。DSCL包含两个核心组件：基于奖励的动态采样，它利用多维奖励统计数据（均值和方差）来优先处理有价值的数据；以及基于任务的动态课程学习，它自适应地将训练重点放在掌握程度较低的子任务上。通过广泛的实验，我们证明DSCL相较于强大的基线方法显著提升了训练效率和模型性能，在BFCLv3基准上取得了3.29%的提升。我们的方法提供了一种定制的解决方案，有效利用了工具学习中复杂的奖励信号和子任务动态，以取得卓越的成果。|
|**2025-09-18**|[RationAnomaly: Log Anomaly Detection with Rationality via Chain-of-Thought and Reinforcement Learning](http://arxiv.org/abs/2509.14693)|null|日志构成了表明软件系统运行状态的一种证据形式。自动化日志异常检测对于确保现代软件系统的可靠性至关重要。然而，现有方法面临显著局限性：传统深度学习模型缺乏可解释性和泛化能力，而利用大型语言模型的方法常常因不可靠性和事实不准确性而受阻。为解决这些问题，我们提出了RationAnomaly，一个新颖的框架，它通过协同思维链（CoT）微调与强化学习来增强日志异常检测。我们的方法首先使用CoT引导的监督微调灌输专家级的推理模式，该微调基于通过严格的专家驱动过程校正的高质量数据集。随后，一个采用多方面奖励函数的强化学习阶段优化了准确性和逻辑一致性，有效缓解了幻觉现象。实验结果表明，RationAnomaly优于最先进的基线，在关键基准测试中实现了更高的F1分数，同时提供透明、分步的分析输出。我们已发布相应的资源，包括代码和数据集。|
|**2025-09-18**|[LEED: A Highly Efficient and Scalable LLM-Empowered Expert Demonstrations Framework for Multi-Agent Reinforcement Learning](http://arxiv.org/abs/2509.14680)|null|多智能体强化学习（MARL）在复杂环境中的智能决策方面具有巨大的潜力。然而，随着智能体数量的增加，它面临着协调性和可扩展性瓶颈。为了解决这些问题，我们提出了用于多智能体强化学习的基于大型语言模型赋能的专家演示框架（LEED）。LEED由两个组件组成：一个演示生成（DG）模块和一个策略优化（PO）模块。具体而言，DG模块利用大型语言模型生成与环境交互的指令，从而产生高质量的演示。PO模块采用去中心化训练范式，其中每个智能体利用生成的演示来构建专家策略损失，并将其与自身的策略损失相结合。这使得每个智能体能够基于专家知识和个体经验有效地个性化和优化其局部策略。实验结果表明，与最先进的基线相比，LEED在样本效率、时间效率和鲁棒的可扩展性方面表现出卓越的性能。|
|**2025-09-17**|[Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents](http://arxiv.org/abs/2509.14480)|null|有效的交互式工具使用要求智能体掌握工具集成推理（TIR）：这是一个涉及多轮规划和长上下文对话管理的复杂过程。为了训练智能体应对这一动态过程，特别是在多模态场景中，我们引入了一个支持交错语音-文本推演的强化学习（RL）沙盒环境。我们的核心策略，轮次级裁决强化学习（TARL），通过采用大型语言模型（LLM）作为评判者提供轮次级评估，解决了长周期任务中信用分配的挑战。为了增强探索，我们将混合任务训练课程与数学推理问题相结合。这种统一方法使基于文本的 $\tau$ -bench 上的任务通过率比强大的强化学习基线提高了6%以上。关键的是，我们展示了我们的框架适用于为智能体任务微调多模态基础模型。通过在交错语音-文本推演上训练基础多模态LLM，我们赋予其工具使用能力，为更自然、语音驱动的交互式智能体铺平了道路。|

## 大模型持续学习

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-09-18**|[The Energy-Efficient Hierarchical Neural Network with Fast FPGA-Based Incremental Learning](http://arxiv.org/abs/2509.15097)|null|深度学习，特别是在基础模型和大语言模型（LLM）等大规模架构中，其不断增长的计算和能源需求对可持续性构成了严峻挑战。传统的基于梯度的训练方法效率低下，需要大量的迭代更新并消耗高功耗。为解决这些局限性，我们提出了一种结合分层分解、基于FPGA的直接方程求解和增量学习的混合框架。我们的方法将神经网络分为两个功能层级：较低层通过FPGA上的单步方程求解进行优化，以实现高效且可并行化的特征提取；而较高层采用自适应增量学习，以支持持续更新而无需完全重新训练。在此基础上，我们引入了复合LLM框架，该框架明确地在两个层级中部署LLM模块。较低层的LLM处理具有最小能量开销的可重用表示学习，而较高层的LLM通过能量感知更新进行自适应决策。这种集成设计增强了可扩展性，减少了冗余计算，并符合可持续AI的原则。理论分析和架构见解表明，我们的方法显著降低了计算成本，同时保持了高模型性能，使其非常适合在能量受限环境中进行边缘部署和实时适应。|
|**2025-09-18**|[Forecasting and Visualizing Air Quality from Sky Images with Vision-Language Models](http://arxiv.org/abs/2509.15076)|null|空气污染仍然对公众健康和环境可持续性构成严峻威胁，然而传统监测系统常受限于有限的空间覆盖范围和可及性。本文提出了一种人工智能驱动的智能体，它能从天空图像中预测环境空气污染水平，并利用生成式建模合成逼真的污染情景可视化。我们的方法结合了统计纹理分析与监督学习进行污染分类，并利用视觉-语言模型（VLM）引导的图像生成来产生空气质量状况的可解释表示。生成的视觉效果模拟了不同程度的污染，为面向用户的界面提供了基础，从而提高透明度并支持知情的环境决策。这些输出可以无缝集成到智能应用中，旨在增强态势感知并鼓励基于实时预测的行为响应。我们使用城市天空图像数据集验证了我们的方法，并证明了其在污染水平估计和语义一致的视觉合成方面的有效性。系统设计进一步融入了以人为中心的用户体验原则，以确保空气质量预测的可访问性、清晰度和公众参与。为支持可扩展和节能的部署，未来版本将集成一种绿色CNN架构，该架构通过基于FPGA的增量学习得到增强，从而实现在边缘平台上的实时推理。|
|**2025-09-18**|[Seeing 3D Through 2D Lenses: 3D Few-Shot Class-Incremental Learning via Cross-Modal Geometric Rectification](http://arxiv.org/abs/2509.14958)|null|3D数字内容的快速增长使得开放世界场景中的可扩展识别系统成为必要。然而，现有3D类别增量学习方法在极端数据稀缺情况下，由于几何不对齐和纹理偏差而表现不佳。尽管最近的方法将3D数据与2D基础模型（例如CLIP）相结合，但它们受到纹理偏向投影和几何-纹理线索不加区分融合引起的语义模糊影响，导致决策原型不稳定和灾难性遗忘。为了解决这些问题，我们提出了跨模态几何校正（CMGR），这是一个通过利用CLIP的层次空间语义来增强3D几何保真度的框架。具体而言，我们引入了一个结构感知几何校正模块，通过注意力驱动的几何融合，将3D部分结构与CLIP的中间空间先验进行分层对齐。此外，一个纹理放大模块合成最小但具有判别性的纹理，以抑制噪声并增强跨模态一致性。为了进一步稳定增量原型，我们采用了一个基-新判别器来隔离几何变异。大量实验表明，我们的方法显著改善了3D少样本类别增量学习，在跨域和域内设置下实现了卓越的几何一致性以及对纹理偏差的鲁棒性。|
|**2025-09-18**|[Cross-Modal Knowledge Distillation for Speech Large Language Models](http://arxiv.org/abs/2509.14930)|null|在这项工作中，我们首次系统性评估了语音大语言模型中的灾难性遗忘和模态不均衡性，结果表明，引入语音能力会降低知识和推理能力，即使输入仍然是文本形式的，并且当使用语音查询时，性能会进一步下降。为了解决这些挑战，我们提出了一种跨模态知识蒸馏框架，该框架利用文本到文本和语音到文本两种通道，将知识从基于文本的教师模型迁移到语音大语言模型中。在对话和音频理解任务上进行的大量实验验证了我们方法在保留文本知识、改善跨模态对齐和增强基于语音交互的推理能力方面的有效性。|
|**2025-09-18**|[Trade-offs in Cross-Domain Generalization of Foundation Model Fine-Tuned for Biometric Applications](http://arxiv.org/abs/2509.14921)|null|CLIP等基础模型在多样化的视觉任务中展示了卓越的零样本和少样本迁移能力。然而，当针对人脸识别（FR）、形变攻击检测（MAD）和呈现攻击检测（PAD）等高度专业化的生物识别任务进行微调时，这些模型可能会遭受过度专业化的问题。因此，它们可能会失去其基础优势之一，即跨领域泛化能力。在本工作中，我们通过评估三个针对人脸识别、形变攻击检测和呈现攻击检测进行微调的CLIP实例，系统地量化了这些权衡。我们在零样本和线性探针协议下，以及常见的人脸识别、形变攻击检测和呈现攻击检测基准上，对每个适应模型以及原始CLIP基线模型在14个通用视觉数据集上进行了评估。我们的结果表明，微调模型会遭受过度专业化，尤其是在针对复杂的人脸识别任务进行微调时。此外，我们的结果指出，任务复杂度和分类头设计（多类别的人脸识别与二分类的形变攻击检测和呈现攻击检测）与灾难性遗忘的程度相关。采用ViT-L骨干网络的FRoundation模型在大型人脸识别基准IJB-C上优于其他方法，实现了高达58.52%的性能提升。然而，它在ImageNetV2上的性能大幅下降，仅达到51.63%，而基线CLIP模型则达到69.84%。此外，更大的CLIP架构比其较小变体始终保留了模型更多的原始泛化能力，这表明增加的模型容量可能有助于缓解过度专业化。|
|**2025-09-18**|[OnlineMate: An LLM-Based Multi-Agent Companion System for Cognitive Support in Online Learning](http://arxiv.org/abs/2509.14803)|null|在在线学习环境中，学生常常缺乏个性化的同伴互动，而这种互动在支持认知发展和学习投入方面起着关键作用。尽管先前的研究利用大型语言模型（LLMs）为学生模拟了交互式动态学习环境，但这些互动仍仅限于对话交流，缺乏对学习者个性化学习和认知状态的洞察和适应。因此，学生对与AI学习伙伴的讨论兴趣较低，并且难以从此类互动中获得启发。为了解决这一挑战，我们提出了OnlineMate，一个由LLMs驱动并融合了心智理论（ToM）的多智能体学习伙伴系统。OnlineMate能够模拟同伴般的智能体角色，在协作讨论中适应学习者的认知状态，并推断他们的心理状态，例如误解、困惑或动机。通过整合心智理论能力，系统能够动态调整其互动策略，以支持高阶思维和认知的发展。在模拟学习场景中的实验结果表明，OnlineMate有效地促进了深度学习和讨论，同时增强了在线教育环境中的认知投入。|
|**2025-09-18**|[AgentCompass: Towards Reliable Evaluation of Agentic Workflows in Production](http://arxiv.org/abs/2509.14647)|null|随着大型语言模型（LLMs）在自动化复杂的、多智能体工作流方面日益广泛的应用，组织面临着来自错误、涌现行为和系统性故障的日益增加的风险，而这些是当前评估方法未能捕捉到的。我们提出了AgentCompass，这是首个专门为智能体工作流的部署后监控和调试而设计的评估框架。AgentCompass通过一个结构化的、多阶段的分析流程（包括错误识别与分类、主题聚类、定量评分和策略性总结）来模拟专家调试器的推理过程。该框架通过一个双重记忆系统（情景记忆和语义记忆）得到进一步增强，该系统能够在不同执行之间实现持续学习。通过与设计伙伴的合作，我们展示了该框架在实际部署中的实用性，然后根据公开可用的TRAIL基准来验证其效能。AgentCompass在关键指标上取得了最先进的成果，同时揭示了人工标注中遗漏的关键问题，强调了其作为一种强大的、以开发者为中心的工具的作用，用于生产环境中智能体系统的可靠监控和改进。|
|**2025-09-17**|[CL $^2$GEC: A Multi-Discipline Benchmark for Continual Learning in Chinese Literature Grammatical Error Correction](http://arxiv.org/abs/2509.13672)|null|在多个学术领域对自动化写作辅助日益增长的需求，凸显了对能够跨学科适应的鲁棒中文语法纠错（CGEC）系统的必要性。然而，现有CGEC研究在很大程度上缺乏针对多学科专业写作的专用基准，并忽视了持续学习（CL）作为处理特定领域语言变异和防止灾难性遗忘的有前景的解决方案。为了填补这一关键空白，我们引入了CL$^2$GEC，这是首个用于中文文献语法纠错的持续学习基准，旨在评估跨多个学术领域的自适应CGEC。我们的基准包含10,000个人工标注句子，涵盖10个学科，每个学科都展现出独特的语言风格和错误模式。CL$^2$ GEC专注于在持续学习设置下评估语法纠错，模拟顺序暴露于不同学术领域，以反映真实世界的编辑动态。我们使用标准GEC指标和适应任务级别变异的持续学习指标，评估了大型语言模型在顺序微调、参数高效适应和四种代表性CL算法下的表现。实验结果表明，基于正则化的方法比基于回放或朴素顺序方法能更有效地缓解遗忘。我们的基准为未来在跨不同学术领域的自适应语法纠错研究提供了严谨的基础。|
|**2025-09-10**|[A Role-Aware Multi-Agent Framework for Financial Education Question Answering with LLMs](http://arxiv.org/abs/2509.09727)|null|问答 (QA) 在金融教育中扮演核心角色，然而现有的大型语言模型 (LLM) 方法往往未能捕捉到解决金融问题所需的细致入微且专业化的推理。金融领域要求多步定量推理、熟悉领域特定术语以及理解现实世界情景。我们提出了一个多智能体框架，该框架利用基于角色的提示 (role-based prompting) 来提高在领域特定问答 (QA) 上的性能。我们的框架包含一个基础生成器 (Base Generator)、一个证据检索器 (Evidence Retriever) 和一个专家评审员智能体 (Expert Reviewer)，它们通过单次迭代 (single-pass iteration) 协同工作以生成一个精炼的答案。我们使用来自在线学习平台 Study.com 的 3,532 个专家设计的金融教育问题对我们的框架进行了评估。我们利用检索增强生成 (RAG) 从 6 本金融教科书中获取上下文证据，并为领域专家评审员设计了提示策略。我们的实验表明，基于批判的精炼 (critique-based refinement) 将答案准确率相较于零样本思维链 (zero-shot Chain-of-Thought) 基线提高了 6.6-8.3%，其中 Gemini-2.0-Flash 取得了最高性能。此外，我们的方法使 GPT-4o-mini 能够达到与经过金融领域微调的 FinGPT-mt_Llama3-8B_LoRA 模型相当的性能。我们的结果展示了一种提升金融问答 (QA) 的成本效益方法，并为多智能体金融大型语言模型 (LLM) 系统的进一步研究提供了见解。|
|**2025-09-10**|[Ubiquitous Intelligence Via Wireless Network-Driven LLMs Evolution](http://arxiv.org/abs/2509.08400)|null|我们引入泛在智能作为一种范式，其中大语言模型(LLMs)在无线网络驱动的生态系统中演进。与静态模型部署不同，这种方法通过网络和LLMs之间的协同，实现了可扩展和持续的智能提升。无线网络支持系统编排的终身学习，而LLMs则推动了更具适应性和响应性的下一代网络发展。这种协同演进凸显了向自我完善系统的转变，在多样化和资源受限的环境中持续提升能力。|

## Transformer

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-09-18**|[Attention Beyond Neighborhoods: Reviving Transformer for Graph Clustering](http://arxiv.org/abs/2509.15024)|null|注意力机制已成为现代神经网络的基石，推动了各个领域的突破。然而，它们在图结构数据上的应用，即捕获拓扑连接至关重要的地方，与图神经网络（GNNs）相比，仍未得到充分探索且表现不佳，尤其是在图聚类任务中。GNN倾向于过度强调邻域聚合，导致节点表示的同质化。相反，Transformer倾向于过度全局化，突出遥远的节点却牺牲了有意义的局部模式。这种二分法提出了一个关键问题：注意力机制对于无监督图学习是否本质上是冗余的？为了解决这个问题，我们进行了一项全面的实证分析，揭示了GNN和Transformer在图聚类中的互补弱点。受这些见解的启发，我们提出了注意力图聚类网络（AGCN），这是一种新颖的架构，重新诠释了“图即注意力”的理念。AGCN直接将注意力机制嵌入到图结构中，实现了有效的全局信息提取，同时保持了对局部拓扑线索的敏感性。我们的框架结合了理论分析，对比了AGCN与GNN和Transformer的行为，并引入了两项创新：（1）一种KV缓存机制以提高计算效率，以及（2）一种成对边际对比损失以提升注意力空间的判别能力。大量的实验结果表明，AGCN优于最先进的方法。|
|**2025-09-18**|[Exploring the Global-to-Local Attention Scheme in Graph Transformers: An Empirical Study](http://arxiv.org/abs/2509.14863)|null|图形Transformer (GT) 在图表示学习中展现出巨大潜力。GT的架构通常将图神经网络 (GNN) 与全局注意力机制结合，这种结合方式要么是并行，要么是作为注意力机制的前置，从而产生局部-全局或局部到全局的注意力方案。然而，由于全局注意力机制主要捕获节点间的长距离依赖，这些集成方案可能遭受信息损失，即GNN学习到的局部邻域信息可能被注意力机制稀释。因此，我们提出G2LFormer，它采用一种新颖的全局到局部注意力方案，其中浅层网络层使用注意力机制捕获全局信息，而深层网络层采用GNN模块学习局部结构信息，从而防止节点忽略其直接邻居。我们引入了一种有效的跨层信息融合策略，以允许局部层保留来自全局层的有益信息并缓解信息损失，同时在可扩展性方面具有可接受的权衡。为了验证全局到局部注意力方案的可行性，我们将G2LFormer与最先进的线性GT和GNN在节点级和图级任务上进行了比较。结果表明，G2LFormer表现出优异的性能，同时保持线性复杂度。|
|**2025-09-18**|[Stochastic Clock Attention for Aligning Continuous and Ordered Sequences](http://arxiv.org/abs/2509.14678)|null|我们为连续且有序的序列构建了一种注意力机制，该机制明确地作为对齐模型发挥作用，而对齐模型是许多序列到序列任务的核心。标准的缩放点积注意力依赖于位置编码和掩码，但它不强制连续性或单调性，而这些对于帧同步目标至关重要。我们提出了针对源和目标的学习到的非负时钟，并将注意力建模为这些时钟相遇的概率；一个路径积分推导得到了一个闭式、类高斯的评分规则，该规则对因果、平滑、近对角线的对齐具有内在偏置，且无需外部位置正则化器。该框架支持两种互补的机制：当全局长度可用时，使用归一化时钟进行并行解码；以及使用非归一化时钟进行自回归解码——两者都是几乎无需参数的即插即用替代品。在Transformer文本到语音测试平台中，这种构造产生了更稳定的对齐，并提高了对全局时间缩放的鲁棒性，同时与缩放点积基线相比，准确性持平或有所提高。我们推测其适用于其他连续目标，包括视频和时序信号建模。|
|**2025-09-18**|[SpeechMLC: Speech Multi-label Classification](http://arxiv.org/abs/2509.14677)|null|本文提出了一种多标签分类框架，用于检测语音样本中的多种说话风格。与以往主要关注识别单一目标风格的研究不同，我们的框架能在一个统一的结构中有效捕获各种说话者特征，使其适用于通用的人机交互应用。所提出的框架在一个Transformer解码器内部集成了交叉注意力机制，以从输入语音中提取与每个目标标签相关的显著特征。为了缓解多标签语音数据集中固有的数据不平衡问题，我们采用了一种基于语音生成模型的数据增强技术。我们通过在已见和未见语料库上的多项客观评估验证了我们模型的有效性。此外，我们通过考虑人类标注一致性对模型性能的影响，分析了人类感知对分类准确性的影响。|
|**2025-09-17**|[White Aggregation and Restoration for Few-shot 3D Point Cloud Semantic Segmentation](http://arxiv.org/abs/2509.13907)|null|少样本三维点云分割 (FS-PCS) 旨在仅给定少量标记样本的情况下，预测未标记点云的每个点的标签。为了从有限的支持集中提取判别性表示，现有方法使用最远点采样等传统算法构建了原型。然而，我们指出其初始随机性显著影响 FS-PCS 性能，并且原型生成过程尽管普遍存在但仍未得到充分探索。这促使我们研究一种基于注意力机制的先进原型生成方法。尽管其潜力巨大，我们发现普通模块存在可学习原型令牌与支持特征之间的分布差距问题。为了克服这个问题，我们提出了白化聚合与恢复模块 (WARM)，它通过将交叉注意力夹在白化和着色变换之间来解决错位问题。具体而言，白化在注意力过程之前将支持特征与原型令牌对齐，随后着色将原始分布恢复到经过注意力的令牌。这种简单而有效的设计实现了鲁棒的注意力，从而通过捕获支持特征之间的语义关系生成具有代表性的原型。我们的方法在多个 FS-PCS 基准测试上以显著优势取得了最先进的性能，通过大量实验证明了其有效性。|
|**2025-09-17**|[ST-LINK: Spatially-Aware Large Language Models for Spatio-Temporal Forecasting](http://arxiv.org/abs/2509.13753)|null|交通预测是智能交通系统中的一个关键问题。在近期研究中，大语言模型（LLMs）已成为一种有前景的方法，但其主要为序列化token处理而定制的固有设计在有效捕捉空间依赖性方面带来了显著挑战。具体来说，LLMs在建模空间关系方面的固有局限性以及其与图结构空间数据在架构上的不兼容性仍未得到充分解决。为了克服这些局限性，我们引入了ST-LINK，一个旨在增强大语言模型捕捉时空依赖性能力的新颖框架。其关键组成部分是空间增强注意力机制（SE-Attention）和记忆检索前馈网络（MRFFN）。SE-Attention扩展了旋转位置嵌入，以将空间相关性作为直接的旋转变换整合到注意力机制中。这种方法在保留LLM固有序列处理结构的同时，最大化了空间学习。同时，MRFFN动态检索并利用关键历史模式，以捕捉复杂的时序依赖性并提高长期预测的稳定性。在基准数据集上进行的全面实验表明，ST-LINK超越了传统的深度学习和LLM方法，并能有效捕捉规律交通模式和突发变化。|
|**2025-09-16**|[SAGA: Selective Adaptive Gating for Efficient and Expressive Linear Attention](http://arxiv.org/abs/2509.12817)|null|尽管Transformer架构在建模长距离依赖方面表现出色，使其在视觉任务中得到广泛应用，但基于softmax的注意力机制的二次复杂度带来了主要瓶颈，尤其是在处理高分辨率图像时。线性注意力通过将注意力计算从 $(QK)V$重新表述为$Q(KV)$，从而将复杂度从$\mathcal{O}(N^2)$降低到$\mathcal{O}(N)$，同时保留了全局感受野，提供了一种有前景的替代方案。然而，大多数现有方法均匀地压缩历史键值（KV）信息，这可能导致特征冗余以及与查询（Q）的方向对齐丢失。这种均匀压缩导致低秩$KV$特征图，从而导致与softmax注意力相比的性能差距。为了缓解这一局限性，我们提出了用于高效且富有表现力的线性注意力的选择性自适应门控（SAGA），该方法引入了输入自适应的可学习门控，以选择性地调节信息聚合到$KV$特征图中。这些门控增强了语义多样性，并缓解了传统线性注意力中固有的低秩约束。此外，我们提出了一种高效的Hadamard积分解方法用于门控计算，该方法不引入额外的内存开销。实验表明，SAGA在分辨率为$1280 \times 1280$ 时，与PVT-T相比，在吞吐量方面实现了1.76倍的提升，在峰值GPU内存方面实现了2.69倍的降低。此外，它在ImageNet数据集上的top-1准确率提高了高达4.4%，证明了计算效率和模型有效性。|
|**2025-09-16**|[BATR-FST: Bi-Level Adaptive Token Refinement for Few-Shot Transformers](http://arxiv.org/abs/2509.12768)|null|视觉Transformer (ViT) 在计算机视觉应用中展现出巨大潜力。然而，它们在小样本学习中的性能受限于细化token级交互、难以处理有限训练数据以及建立强大归纳偏置等挑战。现有方法常依赖不灵活的token匹配或基本相似性度量，这限制了全局上下文的有效融合和局部特征的细化。为解决这些挑战，我们提出针对小样本Transformer的双层自适应Token细化 (BATR-FST)，这是一种两阶段方法，能逐步改进token表示并为小样本分类保持鲁棒的归纳偏置。在预训练阶段，掩码图像建模 (MIM) 通过重建被掩码的图像区域，为视觉Transformer (ViT) 提供可迁移的块级表示，为后续适应奠定鲁棒基础。在元微调阶段，BATR-FST 融合了一个双层自适应Token细化模块，该模块利用Token聚类来捕获局部交互，通过不确定性感知Token加权优先处理可靠特征，并采用双层注意力机制来平衡簇内和簇间关系，从而促进彻底的token细化。此外，图Token传播确保了支持集和查询集实例之间的语义一致性，而类别分离惩罚则保持了不同类别边界，增强了判别能力。在三个基准小样本数据集上进行的大量实验表明，BATR-FST 在1-shot和5-shot场景中均取得了优异结果，并改进了基于Transformer的小样本分类。|
|**2025-09-15**|[Dynamic Relational Priming Improves Transformer in Multivariate Time Series](http://arxiv.org/abs/2509.12196)|null|Transformer模型中的标准注意力机制采用静态的token表示，这些表示在每一层的所有成对计算中保持不变。这限制了它们在表示上与每对token交互中潜在的多元关系动态的对齐。虽然它们在关系相对同质的领域表现出色，但标准注意力机制的静态关系学习难以捕捉多元时间序列（MTS）数据中多样化、异构的通道间依赖关系——在单个系统中，不同通道对之间的交互可能受完全不同的物理定律或时间动态支配。为了更好地调整注意力机制以适应此类领域现象，我们提出了带有动态关系预置（prime attention）的注意力机制。与标准注意力机制不同，在标准注意力机制中，每个token在其所有成对交互中都呈现相同的表示，而prime attention通过可学习的调制动态地（或按每次交互）调整每个token，以最好地捕捉每对token独特的关联动态，从而为该特定关系优化每次成对交互。prime attention的这种表示可塑性使得在MTS中有效提取关系特定信息成为可能，同时保持与标准注意力机制相同的渐近计算复杂度。我们的结果表明，prime attention在各项基准测试中始终优于标准注意力机制，实现了高达6.5%的预测准确性提升。此外，我们发现与标准注意力机制相比，prime attention在使用减少高达40%的序列长度时，取得了相当或更优的性能，进一步证明了其卓越的关系建模能力。|
|**2025-09-14**|[Length-Aware Rotary Position Embedding for Text-Speech Alignment](http://arxiv.org/abs/2509.11084)|null|许多近期文本到语音（TTS）系统基于Transformer架构，并采用交叉注意力机制用于文本-语音对齐。在这些系统中，旋转位置编码（RoPE）常被用于编码文本和语音表示中的位置信息。在这项工作中，我们引入了长度感知RoPE（LARoPE），作为RoPE的一个简单而有效的扩展，能够改善文本-语音对齐。与依赖绝对索引的RoPE不同，LARoPE使用长度归一化索引计算查询（query）和键（key）位置之间的相对距离。实验结果表明，LARoPE持续优于RoPE，提供了更快的损失收敛、更准确的文本-语音对齐和更高的整体TTS质量。此外，LARoPE对发音时长变化表现出更强的鲁棒性，并在长达30秒的扩展语音生成中保持稳定性能，而RoPE则出现显著性能下降。值得注意的是，我们的方法在标准零样本TTS基准测试上，词错误率达到了最先进水平。|

## 生成模型

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-09-18**|[Lightweight and Accurate Multi-View Stereo with Confidence-Aware Diffusion Model](http://arxiv.org/abs/2509.15220)|null|为了从标定图像重建三维几何，基于学习的多视图立体（MVS）方法通常执行多视图深度估计，然后将深度图融合为网格或点云。为了提高计算效率，许多方法会初始化一个粗糙深度图，然后逐步以更高分辨率对其进行细化。最近，扩散模型在生成任务中取得了巨大成功。扩散模型从随机噪声开始，通过迭代去噪过程逐步恢复样本。在本文中，我们提出了一种新颖的MVS框架，将扩散模型引入MVS。具体来说，我们将深度细化公式化为一个条件扩散过程。考虑到深度估计的判别性特征，我们设计了一个条件编码器来指导扩散过程。为了提高效率，我们提出了一种结合轻量级2D U-Net和卷积GRU的新颖扩散网络。此外，我们提出了一种新颖的基于置信度的采样策略，以根据扩散模型估计的置信度自适应地采样深度假设。基于我们新颖的MVS框架，我们提出了两种新颖的MVS方法：DiffMVS和CasDiffMVS。DiffMVS在运行时间和GPU内存方面达到了最先进的效率，并取得了有竞争力的性能。CasDiffMVS在DTU、Tanks & Temples和ETH3D数据集上实现了最先进的性能。代码可在以下网址获取：https://github.com/cvg/diffmvs。|
|**2025-09-18**|[RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation](http://arxiv.org/abs/2509.15212)|**[link](https://github.com/alibaba-damo-academy/RynnVLA-001)**|本文提出了RynnVLA-001，一个基于人类演示的大规模视频生成式预训练构建的视觉-语言-动作（VLA）模型。我们提出了一种新颖的两阶段预训练方法。第一阶段，即以自我为中心的视频生成式预训练，利用1200万个以自我为中心的操作视频训练一个图像到视频模型，以初始帧和语言指令为条件预测未来帧。第二阶段，即以人为中心的轨迹感知建模，通过联合预测未来的关键点轨迹来扩展此方法，从而有效地弥合了视觉帧预测与动作预测之间的鸿沟。此外，为了增强动作表示，我们提出了ActionVAE，这是一个变分自编码器，它将动作序列压缩成紧凑的潜在嵌入，从而降低了VLA输出空间的复杂性。在相同的下游机器人数据集上进行微调时，RynnVLA-001取得了优于最先进基线方法的卓越性能，证明了所提出的预训练策略为VLA模型提供了更有效的初始化。|
|**2025-09-18**|[Fair-GPTQ: Bias-Aware Quantization for Large Language Models](http://arxiv.org/abs/2509.15206)|null|大型生成语言模型的高内存需求使得量化技术备受关注，该技术通过将模型权重映射到低精度整数来降低计算成本、内存使用和延迟。GPTQ等方法能有效最小化量化过程中的输入-权重乘积误差；然而，最近的实证研究表明，它们可能增加有偏输出并降低公平性基准测试上的性能，目前尚不清楚是哪些特定权重导致了这个问题。在这项工作中，我们通过在量化目标中添加明确的群体公平性约束，在量化与模型公平性之间建立了新的联系，并引入了Fair-GPTQ，这是第一个明确设计用于减少大型语言模型中不公平性的量化方法。所添加的约束指导舍入操作的学习，以实现对受保护群体偏见更少的文本生成。具体来说，我们关注涉及职业偏见的刻板印象生成以及跨越性别、种族和宗教的歧视性语言。Fair-GPTQ对性能影响极小，在零样本基准测试上至少能保持90%的基线准确率，相对于半精度模型减少了不公平性，并保留了4比特量化的内存和速度优势。我们还将Fair-GPTQ的性能与现有去偏方法进行了比较，发现在种族刻板印象基准测试上，其性能与迭代零空间投影去偏方法相当。总的来说，这些结果验证了我们针对带有群体偏置项的量化问题的理论解决方案，突出了其在生成模型量化时减少群体偏置的适用性，并表明我们的方法还可以进一步用于分析量化过程中通道和权重层面对公平性的贡献。|
|**2025-09-18**|[Fast and Fluent Diffusion Language Models via Convolutional Decoding and Rejective Fine-tuning](http://arxiv.org/abs/2509.15188)|null|自回归（AR）语言模型逐个token生成文本，这限制了它们的推理速度。基于扩散的语言模型提供了一种有前景的替代方案，因为它们可以并行解码多个token。然而，我们发现了当前扩散语言模型中的一个关键瓶颈：长解码窗口问题，即远离输入上下文生成的token经常变得不相关或重复。像半自回归这样的先前解决方案通过将窗口分成块来解决这个问题，但这牺牲了速度和双向性，从而消除了扩散模型的主要优势。为了克服这个问题，我们提出了卷积解码（Conv），这是一种基于归一化的方法，它在不进行硬性分段的情况下缩小了解码窗口，从而带来了更好的流畅性和灵活性。此外，我们引入了基于拒绝规则的微调（R2FT），这是一种事后训练方案，可以更好地对齐远离上下文位置的token。我们的方法在开放式生成基准测试（例如，AlpacaEval）中，在扩散语言模型基线中取得了最先进的结果，且步长显著低于先前工作，证明了速度和质量的双重提升。|
|**2025-09-18**|[Understand Before You Generate: Self-Guided Training for Autoregressive Image Generation](http://arxiv.org/abs/2509.15185)|null|近期研究证明了高质量视觉表征在图像生成中的重要性，并突出了生成模型在图像理解方面的局限性。作为一种最初为自然语言设计的生成范式，自回归模型也面临着类似的挑战。在这项工作中，我们首次系统地研究了将下一个token预测范式应用于视觉领域的机制。我们确定了三个阻碍高层视觉语义学习的关键特性：局部和条件依赖性、步间语义不一致性以及空间不变性不足。我们表明，通过在训练过程中引入自监督目标，这些问题可以得到有效解决，从而形成了一种新颖的训练框架：自回归模型自引导训练（ST-AR）。ST-AR无需依赖预训练表征模型，显著增强了自回归模型的图像理解能力，并提升了生成质量。具体而言，ST-AR在LlamaGen-L上实现了约42%的FID提升，在LlamaGen-XL上实现了49%的FID提升，同时保持了相同的采样策略。|
|**2025-09-18**|[A Race Bias Free Face Aging Model for Reliable Kinship Verification](http://arxiv.org/abs/2509.15177)|**[link](https://github.com/bardiya2254kariminia/Age-Transformation-Without-Racial-Bias-Kinship-Verification)**|亲属关系验证中的年龄差距问题是指父母和子女照片之间的时间差。此外，他们的同龄照片通常难以获得，且人脸老化模型存在种族偏见，这会影响照片的逼真度。因此，我们提出了一种人脸老化GAN模型RA-GAN，它由两个新模块RACEpSp和特征混合器组成，旨在生成无种族偏见的图像。这些无偏见的合成照片被用于亲属关系验证，以研究验证同龄父母-子女图像的效果。实验表明，在种族准确性方面，我们的RA-GAN在所有年龄组中平均优于SAM-GAN 13.14%，并在60岁以上年龄组中优于CUSP-GAN 9.1%。此外，RA-GAN在所有年龄组中保留主体身份的能力优于SAM-GAN和CUSP-GAN。此外，我们证明将KinFaceW-I和KinFaceW-II数据集中的父母和子女图像转换为同龄可以提高所有年龄组的验证准确性。在KinFaceW-I数据集上，使用我们的RA-GAN，父子、父女、母子和母女等亲属关系的准确性分别提高了5.22%、5.12%、1.63%和0.41%。此外，在KinFaceW-II数据集上，父女、父子和母子关系的准确性分别提高了2.9%、0.39%和1.6%。代码可在Github上获取。|
|**2025-09-18**|[Watermarking and Anomaly Detection in Machine Learning Models for LORA RF Fingerprinting](http://arxiv.org/abs/2509.15170)|null|射频指纹识别（RFFI）通过无线设备模拟电路的微小差异来区分它们，从而避免繁重的密码认证。尽管基于频谱图的深度学习提高了准确性，但模型仍然容易受到复制、篡改和规避的攻击。我们提出了一个更强大的RFFI系统，它结合了用于所有权证明的水印技术和用于发现可疑输入的异常检测。使用基于对数梅尔频谱图的ResNet-34，我们嵌入了三种水印：一个简单触发器、一个对噪声和滤波具有鲁棒性的对抗性训练触发器，以及一个隐藏的梯度/权重签名。一个带有Kullback-Leibler（KL）热启动和free-bits的卷积变分自编码器（VAE）用于标记离分布查询。在LoRa数据集上，我们的系统实现了94.6%的准确率、98%的水印成功率和0.94的AUROC，提供了可验证、防篡改的认证。|
|**2025-09-18**|[AnoF-Diff: One-Step Diffusion-Based Anomaly Detection for Forceful Tool Use](http://arxiv.org/abs/2509.15153)|null|多元时间序列异常检测对于识别意外事件至关重要，在机器学习领域已被探索了几十年。然而，将这些方法直接应用于强力工具使用任务的数据具有挑战性，因为现实世界中的流式传感器数据本质上是嘈杂的，表现出非平稳行为，并且在不同任务和工具之间存在差异。为了解决这些挑战，我们提出了一种名为AnoF-Diff的方法，该方法基于扩散模型从时间序列数据中提取力矩特征，并利用力矩特征来检测异常。我们将我们的方法与四项强力工具使用任务上的其他最先进方法在F1分数和受试者工作特征曲线下面积（AUROC）方面进行了比较，结果表明我们的方法具有更好的性能，并且对噪声数据集更鲁棒。我们还提出了一种基于一步扩散的并行异常分数评估方法，并展示了我们的方法如何在多项强力工具使用实验中用于在线异常检测。|
|**2025-09-18**|[WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance](http://arxiv.org/abs/2509.15130)|null|近期视频扩散模型因其丰富的潜在世界先验知识，在空间智能任务中展现出强大潜力。然而，这种潜力受到其有限的可控性和几何不一致性的阻碍，在它们的强大先验知识与3D/4D任务中的实际应用之间造成了差距。因此，现有方法通常依赖于重新训练或微调，这可能导致预训练知识退化并产生高昂的计算成本。为此，我们提出了WorldForge，一个免训练、推理时框架，由三个紧密耦合的模块组成。步内递归细化在推理过程中引入了一种递归细化机制，该机制在每个去噪步骤中反复优化网络预测，以实现精确的轨迹注入。流门控潜在融合利用光流相似性，在潜在空间中将运动与外观解耦，并选择性地将轨迹引导注入到运动相关通道中。双路径自校正引导比较有引导和无引导的去噪路径，以自适应地纠正由噪声或未对齐的结构信号引起的轨迹漂移。这些组件共同作用，在无需训练的情况下注入细粒度、轨迹对齐的引导，实现了精确的运动控制和逼真的内容生成。在各种基准上进行的大量实验验证了我们方法在真实感、轨迹一致性和视觉保真度方面的优越性。这项工作引入了一种新颖的即插即用范式用于可控视频合成，为利用生成先验知识进行空间智能提供了一个新视角。|
|**2025-09-18**|[Learning Mechanistic Subtypes of Neurodegeneration with a Physics-Informed Variational Autoencoder Mixture Model](http://arxiv.org/abs/2509.15124)|**[link](https://github.com/sanpinnawala/BrainPhys)**|建模神经退行性疾病的潜在机制需要能够从稀疏、高维神经影像数据中捕捉异质且空间变化的动态的方法。将基于偏微分方程（PDE）的物理知识与机器学习相结合，相较于经典数值方法，提供了增强的可解释性和实用性。然而，当前物理集成机器学习方法仅限于考虑单个PDE，这严重限制了它们在多种机制导致不同组（即亚型）疾病中的应用，并加剧了模型误设定和退化的问题。在本文中，我们提出了一种深度生成模型，用于学习由基于物理的PDEs控制的潜在动态模型混合，超越了假设单一PDE结构的传统方法。我们的方法将反应扩散PDEs集成到变分自编码器（VAE）混合模型框架中，支持从神经影像数据中推断可解释潜在变量（例如扩散系数和反应速率）的亚型。我们在合成基准上评估了我们的方法，并展示了其在从正电子发射断层扫描（PET）数据中揭示阿尔茨海默病进展的机制亚型方面的潜力。|

