---
layout: default
---

## Updated on 2025.09.19
> Usage instructions: [here](./docs/README.md#usage)

## 多模态

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-09-18**|[Calibration-Aware Prompt Learning for Medical Vision-Language Models](http://arxiv.org/abs/2509.15226)|null|医疗视觉语言模型（Med-VLMs）通过利用大规模图像-文本预训练，在各种医学影像任务中展现出卓越的性能。然而，它们的置信度校准在很大程度上仍未被探索，因此仍然是一个重大挑战。因此，错误的预测会导致过度自信的错误，损害临床信任和决策的可靠性。为了解决这个问题，我们提出了CalibPrompt，这是第一个在提示调优过程中校准Med-VLMs的框架。CalibPrompt在稀疏标记数据体制下，通过精心设计的校准目标来优化少量可学习的提示。首先，我们研究了一种正则化器，它试图将平滑精度与预测模型的置信度对齐。其次，我们引入了一个角度分离损失，以最大化文本特征的接近度，从而提高多模态Med-VLMs置信度估计的可靠性。在四个公开可用的Med-VLMs和五个不同的医学影像数据集上进行的广泛实验表明，CalibPrompt在不显著影响准确率的情况下，始终能提高校准性能。我们的代码可在https://github.com/iabh1shekbasu/CalibPrompt获取。|
|**2025-09-18**|[Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation](http://arxiv.org/abs/2509.15225)|null|我们提出了一种新颖的无源域适应框架 VocAlign，该框架专为开放词汇语义分割中的视觉语言模型 (VLM) 设计。我们的方法采用学生-教师范式，并辅以词汇对齐策略，通过引入额外的类别概念来改进伪标签生成。为确保效率，我们使用低秩适应 (LoRA) 来微调模型，在最小化计算开销的同时保留其原始能力。此外，我们为学生模型提出了一种 Top-K 类别选择机制，该机制显著降低了内存需求，同时进一步提高了适应性能。我们的方法在 CityScapes 数据集上实现了显著的 6.11 mIoU 提升，并在零样本分割基准上展现出卓越的性能，为开放词汇设置下的无源适应树立了新的标杆。|
|**2025-09-18**|[ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data](http://arxiv.org/abs/2509.15221)|**[link](https://github.com/YangYzzzz/ScaleCUAWebCrawler)**|视觉语言模型（VLMs）已实现能够自主操作图形用户界面（GUIs）的计算机使用代理（CUAs），展现出巨大潜力，但由于缺乏大规模开源计算机使用数据和基础模型，进展受到限制。在本工作中，我们提出了 ScaleCUA，这是朝着扩展开源 CUA 迈出的重要一步。它提供了一个涵盖 6 个操作系统和 3 个任务领域的大规模数据集，该数据集通过一个结合自动化代理和人类专家的闭环流水线构建而成。在扩展后的数据上进行训练，ScaleCUA 可以在不同平台间无缝操作。具体而言，它在 WebArena-Lite-v2 上取得了显著的性能提升（+26.6），在 ScreenSpot-Pro 上取得了显著的性能提升（+10.7），并创下了新的最先进成果（MMBench-GUI L1-Hard 上为 94.4%，OSWorld-G 上为 60.6%，WebArena-Lite-v2 上为 47.4%）。这些发现强调了数据驱动扩展对于通用计算机使用代理的强大能力。我们将发布数据、模型和代码以推动未来的研究：https://github.com/OpenGVLab/ScaleCUA。|
|**2025-09-18**|[Generalizable Geometric Image Caption Synthesis](http://arxiv.org/abs/2509.15217)|null|多模态大语言模型在各种实际应用中展现出强大的推理能力。尽管近期取得了显著进展，但在解决复杂的几何问题方面仍存在困难。一个关键挑战源于缺乏高质量的图像-文本对数据集来理解几何图像。此外，大多数基于模板的数据合成流程通常难以泛化到预定义模板之外的问题。本文通过引入一个互补的、可验证奖励的强化学习（RLVR）过程来改进数据生成流程。通过采用RLVR对从50种基本几何关系合成的几何图像进行标题优化，并利用源自数学问题求解任务的奖励信号，我们的流程成功捕捉了解决几何问题的关键特征，从而实现了更好的任务泛化并带来了显著的改进。此外，即使在分布外场景下，生成的数据集也能增强多模态大语言模型的通用推理能力，在MathVista和MathVerse的非几何输入图像的统计、算术、代数和数值任务上，准确率提高了2.8%-4.8%，在MMMU的艺术、设计、技术和工程任务上，准确率提高了2.4%-3.9%。|
|**2025-09-18**|[What's the Best Way to Retrieve Slides? A Comparative Study of Multimodal, Caption-Based, and Hybrid Retrieval Techniques](http://arxiv.org/abs/2509.15211)|null|幻灯片是介于演示文稿和书面文档之间的数字报告，在学术和企业环境中是传递信息的常用媒介。其多模态特性，结合了文本、图像和图表，给检索增强生成系统带来了挑战，因为检索的质量直接影响下游性能。传统的幻灯片检索方法通常涉及对模态进行单独索引，这会增加复杂性并丢失上下文信息。本文研究了多种有效的幻灯片检索方法，包括像 ColPali 这样的视觉后期交互嵌入模型、视觉重排器的使用，以及结合了密集检索和 BM25 的混合检索技术，这些技术还通过文本重排器和倒数排名融合（Reciprocal Rank Fusion）等融合方法得到增强。我们还评估了一个新颖的基于视觉语言模型（Vision-Language Models）的字幕生成流程，该流程与视觉后期交互技术相比，显著降低了嵌入存储需求，同时检索性能相当。我们的分析还扩展到这些方法的实际应用方面，在评估检索效果的同时，还评估了它们的运行时性能和存储需求，从而为实际应用中选择和开发高效、稳健的幻灯片检索系统提供了实用指导。|
|**2025-09-18**|[Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding](http://arxiv.org/abs/2509.15178)|null|时空视频基础定位（Spatio-temporal video grounding, STVG）旨在根据输入的文本查询来定位视频的时空区域。本文中，我们利用多模态大语言模型（MLLMs）来探索STVG的零样本解决方案。我们揭示了关于MLLMs的两个关键洞察：（1）MLLMs倾向于动态分配特殊标记，称为“基础标记”（grounding tokens），用于基础定位文本查询；（2）由于无法充分整合文本查询中的线索（例如，属性、动作）进行推理，MLLMs常常存在基础定位不佳的问题。基于这些洞察，我们提出了一种基于MLLM的STVG零样本框架，该框架包含新颖的分解时空高亮（decomposed spatio-temporal highlighting, DSTH）和时域增强组装（temporal-augmented assembling, TAS）策略，以释放MLLMs的推理能力。DSTH策略首先将原始查询分解为属性和动作子查询，用于在空间和时间上查询目标的存在。然后，它使用新颖的logit引导再注意力（logit-guided re-attention, LRA）模块，通过对每个子查询的标记预测进行正则化来学习作为空间和时间提示的潜在变量。这些提示分别突出属性和动作线索，将模型的注意力引导至可靠的时空相关视觉区域。此外，由于属性子查询的空间基础定位应具有时间一致性，我们引入了TAS策略，使用原始视频帧和时域增强帧作为输入来组装预测，以帮助提高时间一致性。我们在各种MLLMs上评估了我们的方法，并在三个通用的STVG基准测试上表明，我们的方法优于最先进的方法。代码将在https://github.com/zaiquanyang/LLaVA_Next_STVG 提供。|
|**2025-09-18**|[An Evaluation-Centric Paradigm for Scientific Visualization Agents](http://arxiv.org/abs/2509.15160)|null|近期，多模态大语言模型（MLLMs）的进步使得能够将用户意图转化为数据可视化的、日益复杂的自主可视化代理成为可能。然而，衡量进展和比较不同代理仍然具有挑战性，尤其是在科学可视化（SciVis）领域，因为缺乏全面、大规模的基准来评估真实世界的能力。本文探讨了 SciVis 代理所需的各种评估类型，概述了相关挑战，提供了一个简单的概念验证评估示例，并讨论了评估基准如何促进代理的自我改进。我们提倡更广泛的合作，开发一个 SciVis 代理评估基准，该基准不仅能评估现有能力，还能推动该领域的创新和未来发展。|
|**2025-09-18**|[Exploring How Audio Effects Alter Emotion with Foundation Models](http://arxiv.org/abs/2509.15151)|null|混响、失真、调制和动态范围处理等音频效果（FX）在塑造听音乐时的情绪反应方面起着至关重要的作用。虽然之前的研究已经检验了低级音频特征与情感感知之间的联系，但音频效果对情绪的系统性影响仍未得到充分探索。本研究调查了如何利用基础模型——在多模态数据上预训练的大规模神经网络架构——来分析这些效果。这些模型编码了音乐结构、音色和情感含义之间丰富的关联，为探测声音设计技术的 the emotional consequences of sound design techniques 提供了强大的框架。通过将各种探测方法应用于深度学习模型的嵌入，我们考察了音频效果与估计情绪之间复杂、非线性的关系，揭示了与特定效果相关的模式，并评估了基础音频模型的鲁棒性。我们的研究结果旨在增进对音频制作实践的感知影响的理解，并对音乐认知、表演和情感计算产生影响。|
|**2025-09-18**|[From Pixels to Urban Policy-Intelligence: Recovering Legacy Effects of Redlining with a Multimodal LLM](http://arxiv.org/abs/2509.15132)|null|本文展示了多模态大型语言模型（MLLM）如何能够扩展城市测量能力并支持对基于地点的政策干预进行跟踪。通过在街景图像上采用结构化的“推理-然后估计”流水线，GPT-4o 推断出社区贫困和树冠覆盖情况，我们将其纳入一项准实验设计中，以评估 20 世纪 30 年代红线政策的遗留影响。GPT-4o 恢复了红线政策预期的不利的社会环境遗留影响，其估计值与权威来源在统计学上无法区分，并且优于传统的基于像素的分割基线，这与整体场景推理能够提取超越单纯物体计数的更高阶信息的观点一致。这些结果表明 MLLM 可以作为政策级别的工具用于社区测量，并鼓励在更广泛的政策评估环境中进行验证。|
|**2025-09-18**|[Forecasting and Visualizing Air Quality from Sky Images with Vision-Language Models](http://arxiv.org/abs/2509.15076)|null|空气污染仍然是对公众健康和环境可持续性的严峻威胁，但传统的监测系统通常受到空间覆盖范围和可访问性的限制。本文提出了一种由人工智能驱动的代理，该代理可以从天空图像预测环境空气污染水平，并使用生成模型合成逼真的污染场景可视化。我们的方法结合了统计纹理分析和监督学习进行污染分类，并利用视觉语言模型（VLM）指导的图像生成来产生可解释的空气质量状况表示。生成的视觉效果模拟了不同程度的污染，为改善透明度和支持知情的环境决策的面向用户的界面奠定了基础。这些输出可以无缝集成到旨在增强态势感知和鼓励基于实时预测的行为响应的智能应用程序中。我们使用城市天空图像数据集验证了我们的方法，并证明了其在污染水平估计和语义一致的视觉合成方面的有效性。系统设计还融入了以人为本的用户体验原则，以确保空气质量预测的可访问性、清晰度和公众参与度。为了支持可扩展且节能的部署，未来的迭代将采用基于FPGA的增量学习增强的绿色CNN架构，从而能够在边缘平台上进行实时推理。|

## 大模型PEFT

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-09-18**|[Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation](http://arxiv.org/abs/2509.15225)|null|我们提出 VocAlign，一个新颖的无源域适应框架，专为开放词汇语义分割中的视觉语言模型（VLMs）设计。我们的方法采用了一个由词汇对齐策略增强的学生-教师范式，通过引入额外的类别概念来改进伪标签生成。为确保效率，我们使用低秩适应（LoRA）来微调模型，在最小化计算开销的同时保留其原始能力。此外，我们为学生模型提出了一种 Top-K 类别选择机制，显著降低了内存需求，同时进一步提高了适应性能。我们的方法在 CityScapes 数据集上实现了显著的 6.11 mIoU 提升，并在零样本分割基准上展示了卓越的性能，为开放词汇设置下的无源适应树立了新标准。|
|**2025-09-18**|[Adaptive LoRA Experts Allocation and Selection for Federated Fine-Tuning](http://arxiv.org/abs/2509.15087)|null|大型语言模型（LLM）在各种任务中都展现出了令人印象深刻的能力，但针对特定领域应用对其进行微调通常需要大量的特定领域数据，而这些数据可能分布在多个组织中。联邦学习（FL）提供了一种隐私保护的解决方案，但在应用于 LLM 时面临计算约束的挑战。低秩自适应（LoRA）已成为一种参数高效的微调方法，但单个 LoRA 模块在处理跨不同领域的异构数据时常常力不从心。本文解决了联邦 LoRA 微调中的两个关键挑战：1. 确定异构客户端之间 LoRA 专家数量的最优值和分配方案；2. 使客户端能够根据其特定的数据特征选择性地利用这些专家。我们提出了 FedLEASE（Federated adaptive LoRA Expert Allocation and SElection），一个新颖的框架，它根据表示相似性自适应地对客户端进行聚类，以分配和训练特定领域的 LoRA 专家。它还引入了一个自适应的 Top- $M$ 混合专家机制，允许每个客户端选择最优的利用专家数量。我们在各种基准数据集上进行的广泛实验表明，FedLEASE 在异构客户端环境中显著优于现有的联邦微调方法，同时保持了通信效率。|
|**2025-09-18**|[Explicit vs. Implicit Biographies: Evaluating and Adapting LLM Information Extraction on Wikidata-Derived Texts](http://arxiv.org/abs/2509.14943)|null|文本隐含性一直是自然语言处理（NLP）中的一个挑战，传统方法依赖于显式陈述来识别实体及其关系。从句子“Zuhdi每星期天去教堂”中，Zuhdi与基督教的关系对于人类读者来说是显而易见的，但如果必须自动推断，则会带来挑战。大型语言模型（LLM）在文本理解和信息抽取（IE）等NLP下游任务中已被证明是有效的。本研究考察了文本隐含性对预训练LLM（LLaMA 2.3、DeepSeekV1和Phi1.5）中IE任务的影响。我们生成了两个包含10k个生物信息显式和隐式表达的合成数据集，以衡量其对LLM性能的影响，并分析了使用隐式数据进行微调是否能提高它们在隐式推理任务中的泛化能力。本研究提出了一个关于LLM在IE中内部推理过程的实验，特别是在处理隐式和显式上下文时。结果表明，使用LoRA（低秩适配）对LLM模型进行微调可以提高它们从隐式文本中抽取信息的能力，从而提高模型的解释性和可靠性。|
|**2025-09-18**|[LLM4MG: Adapting Large Language Model for Multipath Generation via Synesthesia of Machines](http://arxiv.org/abs/2509.14711)|null|首次基于机器联觉（SoM），对大语言模型（LLM）进行多路径生成（LLM4MG）的适配。考虑到典型的第六代（6G）车路协同（V2I）场景，构建了一个新的多模态感知通信数据集SynthSoM-V2I，该数据集包含信道多路径信息、毫米波（mmWave）雷达感知数据、RGB-D图像和激光雷达（LiDAR）点云。基于SynthSoM-V2I数据集，提出的LLM4MG利用大语言模型Meta AI（LLaMA）3.2通过多模态感知数据进行多路径生成。提出的LLM4MG通过特征提取和融合网络，将多模态特征空间与LLaMA语义空间对齐。为了进一步实现预训练LLaMA在多模态感知数据多路径生成方面的通用知识迁移，采用了低秩适应（LoRA）参数高效微调和感知传播提示工程。仿真结果表明，提出的LLM4MG在视距（LoS）/非视距（NLoS）分类（准确率92.76%）、多路径功率/时延生成精度（归一化均方误差NMSE为0.099/0.032）以及跨车辆交通密度（VTD）、跨频段和跨场景泛化方面优于传统的基于深度学习的方法。所提出的LLM4MG的实用性通过真实世界泛化得到验证。通过信道容量比较也证明了高精度多路径生成对系统设计的必要性。|
|**2025-09-18**|[Catch Me If You Can? Not Yet: LLMs Still Struggle to Imitate the Implicit Writing Styles of Everyday Authors](http://arxiv.org/abs/2509.14543)|**[link](https://github.com/jaaack-wang/llms-implicit-writing-styles-imitation)**|随着大型语言模型（LLMs）日益融入个人写作工具，一个关键问题随之而来：LLMs能否仅凭少数示例就能忠实模仿个人的写作风格？个人风格通常是微妙且隐含的，难以通过提示词指定，但对于以用户为中心的生成至关重要。本研究对最先进的LLMs通过少量用户创作样本进行上下文学习来模仿个人写作风格的能力进行了全面评估。我们引入了一套互补的指标——包括作者归属、作者验证、风格匹配和AI检测——以稳健地评估风格模仿能力。我们的评估涵盖了每个模型超过40000次生成，涉及新闻、电子邮件、论坛和博客等领域，覆盖了400多位真实作者的写作样本。结果表明，尽管LLMs可以在新闻和电子邮件等结构化格式中近似用户风格，但在博客和论坛的细微、非正式写作方面存在困难。对演示数量等各种提示策略的进一步分析揭示了有效个性化的关键局限性。我们的研究结果凸显了LLM个性化适应方面的根本差距，以及支持隐式、风格一致生成的改进技术的必要性。为了支持未来的研究和可复现性，我们开源了我们的数据和代码。|
|**2025-09-18**|[CLAIP-Emo: Parameter-Efficient Adaptation of Language-supervised models for In-the-Wild Audiovisual Emotion Recognition](http://arxiv.org/abs/2509.14527)|null|野外视听情感识别（AVER）仍然受到姿态变化、遮挡和背景噪声的限制。现有方法主要依赖于大规模领域特定预训练，这成本高昂且常常与真实世界情感数据不匹配。为了解决这个问题，我们提出了CLAIP-Emo，一个模块化框架，将野外AVER重新构想为语言监督基础模型（CLIP/CLAP）的参数高效适应。具体来说，它（i）通过冻结CLIP/CLAP骨干网络并使用LoRA（更新的总参数 $\le$ 4.0%）进行面向情感的适应来保留语言监督先验，（ii）不对称地分配时间建模，使用轻量级Transformer处理视觉动态，同时对音频韵律应用平均池化，以及（iii）应用一个简单的融合头进行预测。在DFEW和MAFW数据集上，CLAIP-Emo（ViT-L/14）仅用8M训练参数就实现了80.14%和61.18%的加权平均召回率，创造了新的最先进水平。我们的研究结果表明，语言监督基础模型的参数高效适应为真实世界AVER提供了比领域特定预训练更具可扩展性的替代方案。代码和模型将在https://github.com/MSA-LMC/CLAIP-Emo提供。|
|**2025-09-17**|[Large Language Model-Empowered Decision Transformer for UAV-Enabled Data Collection](http://arxiv.org/abs/2509.13934)|null|在支持多样化物联网（IoT）应用方面，利用无人机（UAV）为空间分布的设备进行可靠且节能的数据收集具有巨大潜力。然而，无人机的续航能力和通信范围有限，这使得智能轨迹规划变得十分必要。尽管强化学习（RL）已被广泛用于无人机轨迹优化，但其交互性在现实环境中会带来高昂的成本和风险。离线强化学习（Offline RL）可以缓解这些问题，但仍然容易出现训练不稳定以及高度依赖专家级数据集。为了应对这些挑战，我们提出了一个联合无人机轨迹规划和资源分配问题，以最大化数据收集的能源效率。首先，我们将资源分配子问题转化为等效的线性规划问题，并以多项式时间复杂度最优地解决。然后，我们提出了一种由大语言模型（LLM）赋能的、经过判别器正则化的决策变换器（DT）框架，称为LLM-CRDT，以学习有效的无人机控制策略。在LLM-CRDT中，我们引入了判别器网络来正则化决策变换器模型的训练，从而将决策变换器的序列建模能力与基于判别器的价值引导相结合，以实现从次优数据集学习有效策略。此外，为了缓解Transformer模型对数据量的需求，我们采用预训练的大语言模型作为决策变换器模型的Transformer骨干，并采用参数高效的微调策略，即LoRA，从而能够用小规模数据集和低计算开销快速适应无人机控制任务。大量的仿真表明，LLM-CRDT的性能优于基准的在线和离线强化学习方法，与当前最先进的决策变换器方法相比，能源效率提高了36.7%。|
|**2025-09-17**|[Mixture of Low-Rank Adapter Experts in Generalizable Audio Deepfake Detection](http://arxiv.org/abs/2509.13878)|null|诸如Wav2Vec2之类的基础模型在语音任务的表示学习方面表现出色，包括音频深度伪造检测。然而，在对一组固定的真实和伪造音频剪辑进行微调后，它们通常无法泛化到训练中未包含的新型深度伪造方法。为了解决这个问题，我们提出了一种LoRA专家混合方法，将多个低秩适配器（LoRA）集成到模型的注意力层中。一种路由机制选择性地激活专业专家，增强了对不断演变的深度伪造攻击的适应性。实验结果表明，我们的方法在同域和跨域场景中均优于标准微调，相对于基线模型降低了等效错误率。值得注意的是，我们最好的MoE-LoRA模型将平均跨域EER从8.55%降低到6.08%，证明了其在实现可泛化的音频深度伪造检测方面的有效性。|
|**2025-09-18**|[Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications](http://arxiv.org/abs/2509.13775)|null|本文讨论了我们对阿拉伯语方言识别（ADI）中不同数据高效和参数高效方法的探索。具体来说，我们研究了各种软提示策略，包括前缀调整、提示调整、P-tuning 和 P-tuning V2，以及 LoRA 再参数化。对于数据高效策略，我们使用零样本和少样本推理来分析硬提示，以评估大型语言模型（LLMs）的方言识别能力。对于参数高效的 PEFT 方法，我们使用阿拉伯语特定的编码器模型在几个主要数据集上进行了实验。我们还分析了在开源解码器模型、通用多语言模型（Phi-3.5）和阿拉伯语特定模型（SILMA）上的 n-shot 推理。我们观察到，LLMs 在少样本或零样本设置下通常难以区分方言的细微差别。软提示编码器变体表现更好，而基于 LoRA 的微调模型表现最佳，甚至超越了完全微调。|
|**2025-09-17**|[Latent Traits and Cross-Task Transfer: Deconstructing Dataset Interactions in LLM Fine-tuning](http://arxiv.org/abs/2509.13624)|null|大型语言模型正越来越多地部署到各种应用中。这通常包括大型语言模型在训练期间未遇到的任务。这意味着枚举和获取所有任务的高质量训练数据是不可行的。因此，我们通常需要依赖具有不同特征的数据集的迁移学习，并预期出现分布外请求。出于这种实际需求的驱动，我们提出了一种分析框架，构建了一个迁移学习矩阵和降维技术，以剖析这些跨任务交互。我们训练并分析了 10 个模型，以识别潜在能力（例如，推理、情感分类、自然语言理解、算术），并发现了迁移学习的副作用。我们的研究结果表明，性能提升常常无法用表面上的数据集相似性或源数据质量来解释。相反，源数据集的隐藏统计因素，如类别分布和生成长度倾向，以及特定的语言特征，实际上更具影响力。这项工作为迁移学习的复杂动态提供了见解，为更可预测和更有效的语言模型适应铺平了道路。|

## 大模型强化学习

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-09-18**|[Generalizable Geometric Image Caption Synthesis](http://arxiv.org/abs/2509.15217)|null|多模态大语言模型在各种实际应用中都需要强大的推理能力。尽管近期取得了进展，但这些模型在解决复杂的几何问题方面仍然存在困难。一个关键挑战源于缺乏高质量的图像-文本对数据集来理解几何图像。此外，大多数基于模板的数据合成管道通常无法泛化到其预定义模板之外的问题。在本文中，我们通过将可验证奖励强化学习（RLVR）的互补过程引入数据生成管道来弥合这一差距。通过采用 RLVR 来改进从 50 种基本几何关系合成的几何图像的字幕，并使用源自数学解题任务的奖励信号，我们的管道成功捕捉了解决几何问题的关键特征。这使得任务泛化能力更好，并取得了非平凡的改进。此外，即使在分布外场景中，生成的数据集也能增强多模态大语言模型的通用推理能力，在 MathVista 和 MathVerse 的具有非几何输入图像的统计、算术、代数和数值任务上，准确率提高了 $2.8\%\text{-}4.8\%$，在 MMMU 的艺术、设计、技术和工程任务上，准确率提高了 $2.4\%\text{-}3.9\%$ 。|
|**2025-09-18**|[FlowRL: Matching Reward Distributions for LLM Reasoning](http://arxiv.org/abs/2509.15207)|null|我们提出FlowRL：通过流平衡匹配完整的奖励分布，而非在大型语言模型（LLM）强化学习（RL）中最大化奖励。最近先进的推理模型采用奖励最大化方法（例如PPO和GRPO），这些方法倾向于过度优化占主导地位的奖励信号，而忽略了不频繁但有效的推理路径，从而降低了多样性。相比之下，我们将标量奖励转化为一个可学习的划分函数产生的归一化目标分布，然后最小化策略与目标分布之间的反向KL散度。我们将此思想实现为一种流平衡优化方法，该方法促进了多样化的探索和可泛化的推理轨迹。我们在数学和代码推理任务上进行了实验：FlowRL在数学基准测试上比GRPO平均提高了10.0%，比PPO提高了5.1%，并在代码推理任务上表现一致优于它们。这些结果凸显了奖励分布匹配是LLM强化学习中高效探索和多样化推理的关键一步。|
|**2025-09-18**|[Evolving Language Models without Labels: Majority Drives Selection, Novelty Promotes Variation](http://arxiv.org/abs/2509.15194)|null|大型语言模型（LLM）越来越多地采用可验证奖励的强化学习（RLVR）进行训练，然而，实际部署要求模型能够在没有标签或外部裁判的情况下进行自我改进。现有的无标签方法，如置信度最小化、自洽性或多数投票目标，虽然能稳定学习，但会逐渐缩小探索范围，导致熵崩溃：生成内容变得更短、多样性减少且脆弱。与主要适应手头即时无标签数据集的测试时强化学习（TTRL）等先前方法不同，我们的目标更广泛：在不牺牲模型固有的探索能力和泛化能力（即演化）的情况下实现通用改进。我们形式化了这个问题，并提出了面向演化和无标签的强化学习（EVOL-RL），这是一个在无标签设置下结合稳定性和变异性的简单规则。EVOL-RL将多数投票的答案作为稳定的锚点（选择），同时增加了一个新颖性感知奖励，该奖励有利于在语义空间中测量其推理与已生成内容不同的响应（变异）。EVOL-RL采用GRPO实现，还使用不对称裁剪来保留强信号，并使用熵正则化器来维持搜索。这种多数投票用于选择+新颖性用于变异的设计可以防止崩溃，保持更长、更具信息量的思维链，并提高pass@1和pass@n。EVOL-RL始终优于仅多数投票的TTRL基线；例如，在无标签的AIME24上训练将Qwen3-4B-Base的AIME25 pass@1从TTRL的4.6%提高到16.4%，pass@16从18.5%提高到37.9%。EVOL-RL不仅防止了多样性崩溃，还解锁了跨领域（例如GPQA）的更强泛化能力。此外，我们证明了EVOL-RL在RLVR设置下也能提高性能，突显了其广泛的适用性。|
|**2025-09-18**|[Self-Improving Embodied Foundation Models](http://arxiv.org/abs/2509.15155)|null|基于网络规模数据训练的基础模型彻底改变了机器人学，但其在低层控制中的应用仍主要局限于行为克隆。受大型语言模型在强化学习阶段微调成功的启发，我们提出了一种用于机器人学的两阶段后训练方法。第一阶段，监督微调（SFT），使用 a) 行为克隆和 b) 剩余步数预测目标来微调预训练的基础模型。在第二阶段，自我改进，剩余步数预测使得能够提取一个形状良好的奖励函数和一个鲁棒的成功检测器，从而使机器人车队能够以最少的人工监督自主练习下游任务。通过在真实世界和模拟机器人实体上的广泛实验，我们新颖的后训练方法在具身基础模型上取得了显著成果。首先，我们证明了 SFT 和自我改进的结合比扩展用于监督学习的模仿数据收集更具样本效率，并且能够产生成功率显著更高的策略。进一步的消融研究强调，网络规模预训练和自我改进的结合是实现这种样本效率的关键。接下来，我们证明了我们提出的组合独特地实现了一种当前方法无法实现的能力：自主练习并获得新技能，这些技能的泛化能力远远超出了训练期间使用的模仿学习数据集所观察到的行为。这些发现突显了将预训练的基础模型与在线自我改进相结合以实现机器人自主技能获取的变革潜力。我们的项目网站位于 https://self-improving-efms.github.io 。|
|**2025-09-18**|[Stochastic Bilevel Optimization with Heavy-Tailed Noise](http://arxiv.org/abs/2509.14952)|null|本文研究了光滑双层优化问题，其中低层问题是强凸的，而高层问题可能不是凸的。我们关注的是随机设置，算法可以访问带有重尾噪声的无偏随机梯度评估，这在许多机器学习应用中很普遍，例如训练大型语言模型和强化学习。我们提出了一种嵌套循环归一化随机双层近似（N $^2$SBA）方法，用于寻找一个 $\epsilon$-平稳点，其随机一阶预言机（SFO）复杂度为 $\tilde{\mathcal{O}}\big(\kappa^{\frac{7p-3}{p-1}} \sigma^{\frac{p}{p-1}} \epsilon^{-\frac{4 p - 2}{p-1}}\big)$，其中 $\kappa$ 是条件数，$p\in(1,2]$ 是噪声的中心矩阶数，$\sigma$ 是噪声水平。此外，我们将我们的思想专门化用于解决非凸-强凹的最小最大优化问题，实现了 $\epsilon$-平稳点，其 SFO 复杂度为 $\tilde{\mathcal O}\big(\kappa^{\frac{2p-1}{p-1}} \sigma^{\frac{p}{p-1}} \epsilon^{-\frac{3p-2}{p-1}}\big)$。以上所有上界都与有界方差设置（即 $p=2$ ）下的最佳已知结果相匹配。|
|**2025-09-18**|[Empathy-R1: A Chain-of-Empathy and Reinforcement Learning Framework for Long-Form Mental Health Support](http://arxiv.org/abs/2509.14851)|null|共情对于有效的心理健康支持至关重要，尤其是在处理长咨询文本（LCT）时。然而，现有的语言大模型（LLMs）生成的回复虽然语义流畅，但缺乏真正心理支持所需的结构化推理，尤其是在中文语境下。为了弥合这一差距，我们提出了Empathy-R1，一个创新的框架，它将共情链（CoE）推理过程与强化学习（RL）相结合，以提高LCT回复的质量。受认知行为疗法的启发，我们的CoE范式引导模型依次推理求助者的情绪、原因和意图，使其思考过程透明且可解释。我们的框架由一个新大规模中文数据集Empathy-QA和一个两阶段训练过程提供支持。首先，监督微调灌输CoE的推理结构。随后，由专用奖励模型指导的RL，进一步优化最终回复的治疗相关性和语境恰当性。实验表明，Empathy-R1在关键的自动评估指标上取得了强大的性能。更重要的是，人工评估证实了其优越性，显示出相比强大基线模型的明显偏好，并在我们的新基准上实现了44.30%的Win@1率。通过实现可解释且具有语境细微差别的回复，Empathy-R1在开发负责任且真正有益于心理健康支持的人工智能方面取得了重大进展。|
|**2025-09-18**|[ToolSample: Dual Dynamic Sampling Methods with Curriculum Learning for RL-based Tool Learning](http://arxiv.org/abs/2509.14718)|null|虽然强化学习（RL）越来越多地用于基于LLM的工具学习，但其效率常常受到大量简单样本的阻碍，这些样本随着训练的进行提供的学习价值越来越小。现有的动态采样技术不适合工具学习固有的多任务结构和细粒度奖励机制。本文提出了结合课程学习的动态采样（DSCL）框架，该框架专门设计用于解决这一挑战，针对工具学习的独特性质：其多个相互依赖的子任务和多值奖励函数。DSCL包含两个核心组件：基于奖励的动态采样，它使用多维奖励统计（均值和方差）来优先处理有价值的数据；以及基于任务的动态课程学习，它自适应地将训练集中在掌握程度较低的子任务上。通过广泛的实验，我们证明DSCL在BFCLv3基准测试中取得了3.29%的提升，显著提高了训练效率和模型性能，优于强大的基线方法。我们的方法提供了一个量身定制的解决方案，有效地利用工具学习中的复杂奖励信号和子任务动态来实现卓越的成果。|
|**2025-09-18**|[RationAnomaly: Log Anomaly Detection with Rationality via Chain-of-Thought and Reinforcement Learning](http://arxiv.org/abs/2509.14693)|null|日志是指示软件系统运行状态的一种证据形式。自动化日志异常检测对于确保现代软件系统的可靠性至关重要。然而，现有方法面临显著局限：传统的深度学习模型缺乏可解释性和泛化能力，而利用大型语言模型的方法则常常受到不可靠性和事实不准确性的困扰。为解决这些问题，我们提出了 RationAnomaly，一个通过协同推理链（Chain-of-Thought, CoT）微调与强化学习来增强日志异常检测的新颖框架。我们的方法首先通过基于 CoT 的监督微调来注入类似专家的推理模式，该微调基于通过严谨的专家驱动过程校正的高质量数据集。随后，具有多方面奖励函数的强化学习阶段优化准确性和逻辑一致性，有效减轻了幻觉。实验表明，RationAnomaly 的性能优于最先进的基线方法，在关键基准测试中取得了更高的 F1 分数，并提供了透明的、循序渐进的分析输出。我们已发布相应的资源，包括代码和数据集。|
|**2025-09-18**|[LEED: A Highly Efficient and Scalable LLM-Empowered Expert Demonstrations Framework for Multi-Agent Reinforcement Learning](http://arxiv.org/abs/2509.14680)|null|多智能体强化学习（MARL）在复杂环境中的智能决策方面展现出巨大潜力。然而，随着智能体数量的增加，它会遇到协调和可扩展性瓶颈。为了解决这些问题，我们提出了用于多智能体强化学习的 LLM 赋能专家演示框架 (LEED)。LEED 由两个组件组成：演示生成 (DG) 模块和策略优化 (PO) 模块。具体来说，DG 模块利用大型语言模型生成与环境交互的指令，从而产生高质量的演示。PO 模块采用去中心化训练范式，其中每个智能体利用生成的演示来构建专家策略损失，然后将其与自身的策略损失相结合。这使得每个智能体能够根据专家知识和个人经验有效地个性化和优化其本地策略。实验结果表明，与最先进的基线相比，LEED 在样本效率、时间效率和鲁棒可扩展性方面均取得了优越的性能。|
|**2025-09-17**|[Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents](http://arxiv.org/abs/2509.14480)|null|有效的交互式工具使用需要智能体掌握工具集成推理（TIR），这是一个涉及多轮规划和长上下文对话管理的复杂过程。为了训练智能体完成这个动态过程，尤其是在多模态环境中，我们引入了一个用于强化学习（RL）的沙盒环境，该环境支持交错的语音-文本回放。我们的核心策略，回合级仲裁强化学习（TARL），通过使用大型语言模型（LLM）作为裁判来提供回合级评估，从而解决了长时任务中的信用分配挑战。为了增强探索，我们将混合任务训练课程与数学推理问题相结合。这种统一的方法将基于文本的 $\tau$ -bench上的任务通过率比强大的RL基线提高了6%以上。关键的是，我们证明了我们的框架适用于微调用于智能体任务的多模态基础模型。通过在交错的语音-文本回放上训练一个基础多模态LLM，我们赋予它工具使用能力，为更自然、语音驱动的交互式智能体铺平了道路。|

## 大模型持续学习

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-09-18**|[The Energy-Efficient Hierarchical Neural Network with Fast FPGA-Based Incremental Learning](http://arxiv.org/abs/2509.15097)|null|深度学习日益增长的计算和能源需求，尤其是在基础模型和大型语言模型（LLMs）等大规模架构中，对可持续性提出了重大挑战。传统的基于梯度的训练方法效率低下，需要大量的迭代更新和高功耗。为了应对这些限制，我们提出了一种混合框架，该框架结合了分层分解、基于FPGA的直接方程求解和增量学习。我们的方法将神经网络分为两个功能层：较低层通过FPGA上的单步方程求解进行优化，以实现高效且可并行的特征提取；而较高层则采用自适应增量学习，支持在不完全重新训练的情况下进行持续更新。在此基础上，我们引入了复合LLM框架，该框架明确地将LLM模块部署在两个层次上。较低层的LLM以最小的能源开销处理可重用表示学习，而较高层的LLM通过节能更新执行自适应决策。这种集成设计增强了可扩展性，减少了冗余计算，并符合可持续AI的原则。理论分析和架构洞察表明，我们的方法在保持高模型性能的同时显著降低了计算成本，非常适合在能源受限环境下的边缘部署和实时适应。|
|**2025-09-18**|[Forecasting and Visualizing Air Quality from Sky Images with Vision-Language Models](http://arxiv.org/abs/2509.15076)|null|空气污染仍然是公众健康和环境可持续性的严峻威胁，但传统的监测系统在空间覆盖和可及性方面常常受到限制。本文提出了一种由人工智能驱动的代理，该代理可以根据天空图像预测环境空气污染水平，并利用生成模型合成逼真的污染场景可视化。我们的方法结合了统计纹理分析和监督学习进行污染分类，并利用视觉语言模型（VLM）引导的图像生成来产生可解释的空气质量状况表示。生成的视觉效果模拟了不同程度的污染，为用户界面奠定了基础，从而提高了透明度并支持知情的环境决策。这些输出可以无缝集成到旨在增强态势感知和鼓励基于实时预测的行为响应的智能应用程序中。我们使用城市天空图像数据集验证了我们的方法，并证明了其在污染水平估算和语义一致的视觉合成方面的有效性。该系统设计还融入了以人为中心的体验设计原则，以确保空气质量预测的可访问性、清晰度和公众参与度。为了支持可扩展且节能的部署，未来的迭代将采用增强了基于FPGA的增量学习的绿色CNN架构，从而在边缘平台上实现实时推理。|
|**2025-09-18**|[Seeing 3D Through 2D Lenses: 3D Few-Shot Class-Incremental Learning via Cross-Modal Geometric Rectification](http://arxiv.org/abs/2509.14958)|null|3D数字内容的快速增长对开放世界场景下的可扩展识别系统提出了需求。然而，现有的3D类增量学习方法在极端数据稀缺的情况下，由于几何错位和纹理偏差而面临困难。尽管近期的一些方法将3D数据与2D基础模型（如CLIP）相结合，但它们会因纹理偏差的投影和几何-纹理线索的无差别融合而导致语义模糊，进而引起不稳定的决策原型和灾难性遗忘。为了解决这些问题，我们提出了跨模态几何校正（CMGR）框架，该框架利用CLIP的层次化空间语义来增强3D几何保真度。具体而言，我们引入了一个结构感知几何校正模块，通过注意力驱动的几何融合，将3D部件结构与CLIP的中间空间先验进行层次化对齐。此外，一个纹理增强模块合成最小但具有区分性的纹理，以抑制噪声并强化跨模态一致性。为了进一步稳定增量原型，我们采用了一个基础-新颖判别器来分离几何变化。广泛的实验表明，我们的方法显著提高了3D少样本类增量学习的性能，在跨域和域内设置中实现了卓越的几何一致性和对纹理偏差的鲁棒性。|
|**2025-09-18**|[Cross-Modal Knowledge Distillation for Speech Large Language Models](http://arxiv.org/abs/2509.14930)|null|在本研究中，我们首次对语音大型语言模型中的灾难性遗忘和模态不均等进行了系统性评估，结果表明，即使输入保持文本形式，引入语音能力也会损害知识和推理能力，并且在语音查询时性能会进一步下降。为了应对这些挑战，我们提出了一种跨模态知识蒸馏框架，该框架利用文本到文本和语音到文本通道，将知识从基于文本的教师模型转移到语音大型语言模型。在对话和音频理解任务上进行的广泛实验证明了我们方法在保留文本知识、改善跨模态对齐以及增强基于语音交互中的推理能力方面的有效性。|
|**2025-09-18**|[Trade-offs in Cross-Domain Generalization of Foundation Model Fine-Tuned for Biometric Applications](http://arxiv.org/abs/2509.14921)|null|CLIP等基础模型在多种视觉任务上展现了卓越的零样本和少样本迁移能力。然而，当针对高度专业化的生物识别任务、人脸识别（FR）、人脸图像变形攻击检测（MAD）和活体检测（PAD）进行微调时，这些模型可能会出现过度专业化的问题，从而失去其基础优势之一——跨域泛化能力。在本研究中，我们通过评估三个经微调以适应FR、MAD和PAD任务的CLIP实例，系统地量化了这些权衡。我们使用零样本和线性探测协议，在14个通用视觉数据集以及常见的FR、MAD和PAD基准上，评估了每个适配模型以及原始CLIP基线。结果表明，微调模型确实存在过度专业化的问题，尤其是在针对复杂FR任务进行微调时。此外，我们的结果也指出，任务复杂度和分类头设计（多类别的FR vs. 二分类的MAD和PAD）与灾难性遗忘的程度相关。采用ViT-L骨干网络的基础模型在大型FR基准IJB-C上表现优于其他方法，最高提升了58.52%。然而，它在ImageNetV2上的性能大幅下降，仅达到51.63%，而基线CLIP模型则达到了69.84%。此外，更大的CLIP架构比较小的变体能更持续地保留模型原始的泛化能力，这表明增加模型容量可能有助于缓解过度专业化问题。|
|**2025-09-18**|[OnlineMate: An LLM-Based Multi-Agent Companion System for Cognitive Support in Online Learning](http://arxiv.org/abs/2509.14803)|null|在线学习环境中，学生常常缺乏个性化的同伴互动，而这种互动在支持认知发展和学习参与度方面起着至关重要的作用。尽管以往的研究利用大型语言模型（LLMs）为学生模拟交互式动态学习环境，但这些交互仅限于对话交流，缺乏对学习者个体化学习和认知状态的洞察和适应。因此，学生对与人工智能学习伙伴的讨论兴趣不高，并且难以从这些互动中获得灵感。为了应对这一挑战，我们提出了OnlineMate，一个由LLMs驱动并整合了心智理论（ToM）的多智能体学习伴侣系统。OnlineMate能够模拟同伴式的智能体角色，在协作讨论中适应学习者的认知状态，并推断其心理状态，如误解、困惑或动机。通过融入心智理论能力，该系统可以动态调整其交互策略，以支持高阶思维和认知的发展。在模拟学习场景中的实验结果表明，OnlineMate能有效促进深度学习和讨论，同时增强在线教育环境中的认知参与度。|
|**2025-09-18**|[AgentCompass: Towards Reliable Evaluation of Agentic Workflows in Production](http://arxiv.org/abs/2509.14647)|null|随着大型语言模型（LLMs）在自动化复杂多智能体工作流中的应用日益广泛，组织面临着由错误、涌现行为和系统性故障带来的日益增长的风险，而当前评估方法未能捕捉到这些风险。我们提出了 AgentCompass，这是第一个专门为智能体工作流的部署后监控和调试设计的评估框架。AgentCompass 通过一个结构化的多阶段分析流程对专家调试者的推理过程进行建模：错误识别与分类、主题聚类、量化评分和战略性总结。该框架进一步配备了双记忆系统——情景记忆和语义记忆——从而能够跨执行实现持续学习。通过与设计合作伙伴的合作，我们在真实部署场景中展示了该框架的实用性，并在其效用得到公共可用的 TRAIL 基准测试验证。AgentCompass 在关键指标上取得了最先进的结果，同时发现了人工标注中遗漏的关键问题，从而凸显了其作为可靠监控和改进生产环境中智能体系统的强大、以开发者为中心的工具的作用。|
|**2025-09-17**|[CL $^2$GEC: A Multi-Discipline Benchmark for Continual Learning in Chinese Literature Grammatical Error Correction](http://arxiv.org/abs/2509.13672)|null|不断增长的对不同学术领域自动化写作辅助的需求，凸显了对能够跨学科适应的鲁棒的中文语法纠错（CGEC）系统的需求。然而，现有的CGEC研究很大程度上缺乏针对多学科学术写作的专门基准，忽视了持续学习（CL）作为处理领域特定语言变异和防止灾难性遗忘的有前途的解决方案。为了填补这一关键空白，我们提出了CL$^2$GEC，这是首个用于中文文学语法纠错的持续学习基准，旨在评估跨多个学术领域的适应性CGEC。我们的基准包含10,000个跨10个学科的人工标注句子，每个学科都表现出独特的语言风格和错误模式。CL$^2$ GEC专注于在持续学习设置下评估语法错误纠正，模拟对不同学术学科的顺序暴露，以反映现实世界的编辑动态。我们使用标准GEC指标和适应任务级别变化的持续学习指标，在顺序微调、参数高效适应和四种代表性CL算法下评估大型语言模型。实验结果表明，基于正则化的方法比基于重放或朴素的顺序方法更有效地减轻遗忘。我们的基准为跨不同学术领域的适应性语法纠错的未来研究提供了严格的基础。|
|**2025-09-10**|[A Role-Aware Multi-Agent Framework for Financial Education Question Answering with LLMs](http://arxiv.org/abs/2509.09727)|null|问答（QA）在金融教育中扮演着核心角色，但现有的大型语言模型（LLM）方法往往无法捕捉金融问题解决所需的细致和专业推理。金融领域需要多步量化推理、熟悉领域特定术语以及理解现实世界场景。我们提出了一个多智能体框架，利用基于角色的提示来增强领域特定问答的性能。我们的框架包含一个基础生成器、一个证据检索器和一个专家审稿人智能体，它们在一个单遍迭代中协同工作以生成优化答案。我们在 Study.com（一个在线学习平台）上由专家设计的 3,532 个金融教育问题集上评估了我们的框架。我们利用检索增强生成（RAG）从 6 本金融教科书中获取上下文证据，并采用提示策略来指导领域专家审稿人。我们的实验表明，与零样本思维链（Chain-of-Thought）基线相比，基于批评的优化将答案准确性提高了 6.6-8.3%，其中 Gemini-2.0-Flash 表现最佳。此外，我们的方法使 GPT-4o-mini 能够达到与经过金融微调的 FinGPT-mt_Llama3-8B_LoRA 相当的性能。我们的结果展示了一种提高金融问答能力的高成本效益方法，并为金融领域多智能体 LLM 系统的进一步研究提供了见解。|
|**2025-09-10**|[Ubiquitous Intelligence Via Wireless Network-Driven LLMs Evolution](http://arxiv.org/abs/2509.08400)|null|我们将泛在智能定义为一个范式，即大型语言模型（LLMs）在无线网络驱动的生态系统中演进。与静态的模型部署不同，这种方法通过网络与LLMs之间的协调，实现了可扩展和持续的智能提升。无线网络支持系统编排的终身学习，而LLMs则推动了下一代网络发展，使其更具适应性和响应性。这种共同演进凸显了向自改进系统转变的趋势，从而在多样化和资源受限的环境中维持能力增长。|

## Transformer

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-09-18**|[Attention Beyond Neighborhoods: Reviving Transformer for Graph Clustering](http://arxiv.org/abs/2509.15024)|null|注意力机制已成为现代神经网络的基石，在各个领域推动了突破。然而，将其应用于图结构数据，其中捕获拓扑连接至关重要，与图神经网络（GNN）相比，其应用仍未得到充分探索且表现不佳，尤其是在图聚类任务中。GNN倾向于过分强调邻域聚合，导致节点表示的同质化。相反，Transformer倾向于过度全局化，突出远距离节点而牺牲有意义的局部模式。这种二分法引发了一个关键问题：注意力对于无监督图学习是否是固有的冗余？为了解决这个问题，我们进行了全面的实证分析，揭示了GNN和Transformer在图聚类中的互补性弱点。受这些见解的启发，我们提出了注意力图聚类网络（AGCN），一种新颖的架构，重新诠释了“图即注意力”的概念。AGCN将注意力机制直接嵌入到图结构中，能够有效地提取全局信息，同时保持对局部拓扑线索的敏感性。我们的框架结合了理论分析，以对比AGCN与GNN和Transformer的行为，并引入了两项创新：（1）KV缓存机制以提高计算效率，以及（2）成对裕度对比损失以增强注意力空间的判别能力。广泛的实验结果表明，AGCN的性能优于最先进的方法。|
|**2025-09-18**|[Exploring the Global-to-Local Attention Scheme in Graph Transformers: An Empirical Study](http://arxiv.org/abs/2509.14863)|null|图Transformer（GT）在图表示学习方面展现出巨大潜力。GT的架构通常将图神经网络（GNN）与全局注意力机制并行集成或作为注意力机制的前身，从而产生局部-全局或局部到全局的注意力方案。然而，由于全局注意力机制主要捕获节点间的长程依赖关系，这些集成方案可能会出现信息丢失，GNN学习到的局部邻域信息可能会被注意力机制稀释。因此，我们提出了G2LFormer，其特点是采用一种新颖的全局到局部注意力方案，其中浅层网络使用注意力机制捕获全局信息，而深层则采用GNN模块学习局部结构信息，从而防止节点忽略其直接邻居。引入了一种有效的跨层信息融合策略，允许局部层保留全局层的有利信息并减轻信息丢失，同时在可伸缩性方面取得可接受的权衡。为了验证全局到局部注意力方案的可行性，我们在节点级和图级任务上将G2LFormer与最先进的线性GT和GNN进行了比较。结果表明，G2LFormer在保持线性复杂度的同时表现出优异的性能。|
|**2025-09-18**|[Stochastic Clock Attention for Aligning Continuous and Ordered Sequences](http://arxiv.org/abs/2509.14678)|null|我们为连续有序序列构建了一种注意力机制，该机制可作为对齐模型，这是许多序列到序列任务的核心。标准的缩放点积注意力依赖于位置编码和掩码，但并不强制执行连续性或单调性，而这对于帧同步目标至关重要。我们提出了学习到的非负时间“时钟”用于源端和目标端，并将注意力建模为这些时钟的相遇概率；路径积分推导产生了一个闭式、类似高斯的评分规则，该规则具有固有的因果、平滑、近对角线对齐的偏置，无需外部位置正则化器。该框架支持两种互补的模式：当全局长度可用时，用于并行解码的归一化时钟；以及用于自回归解码的非归一化时钟——这两种模式几乎不含参数，可直接替换。在 Transformer 文本到语音测试平台中，这种构建产生了更稳定的对齐，并提高了对全局时间缩放的鲁棒性，同时在准确性方面与缩放点积基线相当或有所提高。我们假设该方法也适用于其他连续目标，包括视频和时间信号建模。|
|**2025-09-18**|[SpeechMLC: Speech Multi-label Classification](http://arxiv.org/abs/2509.14677)|null|本文提出了一种多标签分类框架，用于检测语音样本中的多种说话风格。与以往主要关注识别单一目标风格的研究不同，我们的框架在一个统一的结构中有效捕捉各种说话者特征，使其适用于通用人机交互应用。所提出的框架将交叉注意力机制集成到Transformer解码器中，以从输入语音中提取与每个目标标签相关的显著特征。为了缓解多标签语音数据集中固有的数据不平衡问题，我们采用了一种基于语音生成模型的数据增强技术。我们通过在已见和未见语料库上的多项客观评估来验证我们模型的有效性。此外，我们通过考虑人类标签一致性对模型性能的影响，分析了人类感知对分类准确率的影响。|
|**2025-09-17**|[White Aggregation and Restoration for Few-shot 3D Point Cloud Semantic Segmentation](http://arxiv.org/abs/2509.13907)|null|少样本三维点云分割（FS-PCS）旨在仅给定少量标记示例的情况下，为未标记点云预测每点标签。为了从有限的支持集中提取判别性表示，现有方法已使用最远点采样等传统算法构建原型。然而，我们指出其初始随机性显著影响了FS-PCS性能，并且尽管原型生成过程普遍存在，但仍未得到充分探索。这促使我们研究一种基于注意力机制的先进原型生成方法。尽管其具有潜力，但我们发现标准的模块会因可学习的原型令牌与支持特征之间的分布差异而受到影响。为克服这一问题，我们提出了白化聚合与恢复模块（WARM），该模块通过在白化和着色变换之间夹杂交叉注意力来解决错位问题。具体来说，白化在注意力过程之前使支持特征与原型令牌对齐，随后着色将原始分布恢复到注意力令牌。这种简单而有效的设计实现了鲁棒的注意力，从而通过捕获支持特征之间的语义关系来生成代表性原型。我们的方法在多个FS-PCS基准测试中以显著优势取得了最先进的性能，并通过大量实验证明了其有效性。|
|**2025-09-17**|[ST-LINK: Spatially-Aware Large Language Models for Spatio-Temporal Forecasting](http://arxiv.org/abs/2509.13753)|null|交通预测是智能交通系统中的一个关键问题。在最近的研究中，大型语言模型（LLMs）已成为一种有前途的方法，但其主要为序列令牌处理而设计的内在机制，在有效捕捉空间依赖性方面带来了显著挑战。具体来说，LLMs在建模空间关系方面的固有局限性及其与图结构空间数据的架构不兼容性仍未得到解决。为了克服这些限制，我们提出了ST-LINK，一个增强大型语言模型捕捉时空依赖性能力的新框架。其关键组成部分是空间增强注意力（SE-Attention）和记忆检索前馈网络（MRFFN）。SE-Attention扩展了旋转位置嵌入，将空间相关性作为直接旋转变换整合到注意力机制中。这种方法在保留LLM固有的序列处理结构的同时，最大化了空间学习。同时，MRFFN动态检索和利用关键历史模式来捕捉复杂的时间依赖性并提高长期预测的稳定性。在基准数据集上进行的综合实验表明，ST-LINK优于传统的深度学习和LLM方法，并能有效捕捉规律性交通模式和突发变化。|
|**2025-09-16**|[SAGA: Selective Adaptive Gating for Efficient and Expressive Linear Attention](http://arxiv.org/abs/2509.12817)|null|Transformer架构擅长建模长距离依赖关系，这促使其在视觉任务中得到广泛应用，但基于softmax的注意力机制的二次复杂度带来了主要的瓶颈，尤其是在处理高分辨率图像时。线性注意力通过将注意力计算从 $(QK)V$ 重塑为 $Q(KV)$，提供了一种有前景的替代方案，从而将复杂度从 $\mathcal{O}(N^2)$ 降低到 $\mathcal{O}(N)$，同时保留了全局感受野。然而，大多数现有方法对历史键值（KV）信息进行统一压缩，这可能导致特征冗余以及与查询（Q）的方向对齐丢失。这种统一压缩导致了低秩 $KV$ 特征图，与softmax注意力相比存在性能差距。为了缓解这一限制，我们提出了**S**elective \textbf{A}daptive \textbf{GA}ting for Efficient and Expressive Linear Attention (SAGA)，它引入了输入自适应的可学习门控来选择性地调制信息聚合到 $KV$ 特征图中。这些门控增强了语义多样性，并缓解了传统线性注意力固有的低秩约束。此外，我们提出了一种高效的哈达玛积分解耦方法用于门控计算，该方法不会引入额外的内存开销。实验表明，在 $1280 \times 1280$ 的分辨率下，SAGA 相较于 PVT-T 在吞吐量方面提高了 1.76 倍，峰值 GPU 内存降低了 2.69 倍。此外，它在 ImageNet 数据集上的 top-1 准确率最高提高了 4.4%，证明了其计算效率和模型有效性。|
|**2025-09-16**|[BATR-FST: Bi-Level Adaptive Token Refinement for Few-Shot Transformers](http://arxiv.org/abs/2509.12768)|null|视觉 Transformer (ViT) 在计算机视觉应用中展现出巨大的潜力。然而，其在少样本学习方面的性能受到令牌级交互精炼的挑战、有限训练数据的困扰以及归纳偏置的不足等问题的限制。现有方法通常依赖于僵化的令牌匹配或基础相似性度量，这限制了全局上下文的有效整合和局部特征的精炼。为了应对这些挑战，我们提出了用于少样本 Transformer 的双层自适应令牌精炼 (BATR-FST)，这是一种渐进式改进令牌表示并为少样本分类保持强大归纳偏置的两阶段方法。在预训练阶段，掩码图像建模 (MIM) 通过重构掩码图像区域，为视觉 Transformer (ViT) 提供可迁移的块级表示，为后续的适应奠定坚实基础。在元微调阶段，BATR-FST 引入了一个双层自适应令牌精炼模块，该模块利用令牌聚类捕捉局部交互、不确定性感知令牌加权优先考虑可靠特征，以及双层注意力机制来平衡类内和类间关系，从而促进彻底的令牌精炼。此外，图令牌传播确保了支持集和查询集实例之间的语义一致性，而类别分离惩罚则保留了不同的类别边界，增强了判别能力。在三个基准少样本数据集上的广泛实验表明，BATR-FST 在 1-shot 和 5-shot 情景下均取得了优越的结果，并通过 Transformer 提升了少样本分类能力。|
|**2025-09-15**|[Dynamic Relational Priming Improves Transformer in Multivariate Time Series](http://arxiv.org/abs/2509.12196)|null|标准Transformer中的注意力机制采用静态的token表示，在每一层的所有成对计算中保持不变。这限制了它们与每个token-pair交互潜在的、多样的关系动力学的表示对齐。虽然它们在关系相对同质的领域表现出色，但标准的注意力静态关系学习难以捕捉多元时间序列（MTS）数据的多样化、异质性跨通道依赖性——其中单个系统内不同通道对的交互可能受完全不同的物理定律或时间动力学支配。为了更好地使注意力机制适应此类领域现象，我们提出了具有动态关系引导的注意力（prime attention）。与标准注意力中每个token在其所有成对交互中呈现相同表示不同，prime attention通过可学习的调制动态地（或每个交互地）定制每个token，以最好地捕捉每个token pair的独特关系动力学，从而优化每个成对交互以适应特定的关系。prime attention的这种表示可塑性能够在MTS中有效提取关系特定信息，同时保持与标准注意力相同的渐近计算复杂度。我们的结果表明，prime attention在基准测试中始终优于标准注意力，在预测准确性方面提高了高达6.5%。此外，我们发现prime attention使用比标准注意力少40%的序列长度即可达到相当或更优的性能，进一步证明了其卓越的关系建模能力。|
|**2025-09-14**|[Length-Aware Rotary Position Embedding for Text-Speech Alignment](http://arxiv.org/abs/2509.11084)|null|许多近期的文本到语音（TTS）系统都基于Transformer架构，并采用交叉注意力机制进行文本-语音对齐。在这些系统中，旋转位置嵌入（RoPE）常用于编码文本和语音表示中的位置信息。在这项工作中，我们提出了长度感知RoPE（LARoPE），它是RoPE一个简单而有效的扩展，可以改善文本-语音对齐。与依赖绝对索引的RoPE不同，LARoPE使用长度归一化索引计算查询和键位置之间的相对距离。实验结果表明，LARoPE的性能持续优于RoPE，具有更快的损失收敛速度、更准确的文本-语音对齐以及更高的总体TTS质量。此外，LARoPE在应对发音时长变化时表现出更强的鲁棒性，并在长达30秒的扩展语音生成中保持稳定性能，而RoPE则出现明显性能下降。值得注意的是，我们的方法在一个标准的零样本TTS基准测试中达到了最先进的词错误率。|

## 生成模型

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-09-18**|[Lightweight and Accurate Multi-View Stereo with Confidence-Aware Diffusion Model](http://arxiv.org/abs/2509.15220)|null|为了从校准后的图像重建三维几何，基于学习的多视图立体（MVS）方法通常先进行多视图深度估计，然后将深度图融合为网格或点云。为了提高计算效率，许多方法会初始化一个粗糙的深度图，然后在更高分辨率下逐渐细化。最近，扩散模型在生成任务中取得了巨大成功。扩散模型从随机噪声开始，通过迭代去噪过程逐渐恢复样本。在本文中，我们提出了一种新颖的MVS框架，将扩散模型引入MVS。具体来说，我们将深度细化表述为条件扩散过程。考虑到深度估计的判别性特征，我们设计了一个条件编码器来指导扩散过程。为了提高效率，我们提出了一种结合轻量级2D U-Net和卷积GRU的新型扩散网络。此外，我们提出了一种新颖的基于置信度的采样策略，以根据扩散模型估计的置信度自适应地采样深度假设。基于我们新颖的MVS框架，我们提出了两种新颖的MVS方法：DiffMVS和CasDiffMVS。DiffMVS在运行时和GPU内存方面实现了与最先进方法相当的性能。CasDiffMVS在DTU、Tanks & Temples和ETH3D上取得了最先进的性能。代码可在：https://github.com/cvg/diffmvs 获取。|
|**2025-09-18**|[RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation](http://arxiv.org/abs/2509.15212)|null|本文提出了 RynnVLA-001，一个基于大规模人类演示视频生成预训练构建的视觉-语言-动作 (VLA) 模型。我们提出了一种新颖的两阶段预训练方法。第一阶段，以自我为中心的视频生成预训练，在 1200 万个以自我为中心的操控视频上训练图像到视频模型，以预测以初始帧和语言指令为条件的未来帧。第二阶段，以人为中心的轨迹感知建模，通过联合预测未来的关键点轨迹来扩展这一点，从而有效地将视觉帧预测与动作预测联系起来。此外，为了增强动作表示，我们提出了 ActionVAE，一个变分自编码器，将动作序列压缩成紧凑的潜在嵌入，降低了 VLA 输出空间的复杂性。当在相同的下游机器人数据集上进行微调时，RynnVLA-001 在性能上优于最先进的基线，这表明所提出的预训练策略为 VLA 模型提供了更有效的初始化。|
|**2025-09-18**|[Fair-GPTQ: Bias-Aware Quantization for Large Language Models](http://arxiv.org/abs/2509.15206)|null|生成式语言模型的高内存需求已引起人们对量化的关注，量化通过将模型权重映射到低精度整数来降低计算成本、内存使用和延迟。GPTQ 等方法能有效最小化量化过程中的输入-权重乘积误差；然而，最近的实证研究表明，这些方法可能会增加有偏输出并降低公平性基准测试的性能，但仍不清楚具体哪些权重会导致此问题。在本研究中，我们通过在量化目标中添加显式的组公平性约束，建立了量化与模型公平性之间的新联系，并提出了 Fair-GPTQ，这是第一个明确设计用于减少大型语言模型中不公平现象的量化方法。添加的约束引导舍入操作的学习，以实现对受保护群体而言偏差更小的文本生成。具体而言，我们专注于涉及职业偏见的刻板印象生成以及跨越性别、种族和宗教的歧视性语言。Fair-GPTQ 对性能的影响极小，在零样本基准测试中至少保留了 90% 的基线准确率，与半精度模型相比降低了不公平性，并保留了 4 位量化的内存和速度优势。我们还将 Fair-GPTQ 的性能与现有的去偏方法进行了比较，发现在种族刻板印象基准测试上，其性能与迭代零空间投影去偏方法相当。总的来说，结果验证了我们对带有组偏差项的量化问题的理论解决方案，强调了其在生成模型量化时减少组偏差的适用性，并证明了我们的方法还可以用于分析量化过程中通道和权重级别对公平性的贡献。|
|**2025-09-18**|[Fast and Fluent Diffusion Language Models via Convolutional Decoding and Rejective Fine-tuning](http://arxiv.org/abs/2509.15188)|null|自回归（AR）语言模型一次生成一个 token，这限制了其推理速度。基于扩散的语言模型提供了一种有前途的替代方案，因为它们可以并行解码多个 token。然而，我们发现当前扩散语言模型存在一个关键瓶颈：长解码窗口问题，其中生成的远离输入上下文的 token 常常变得不相关或重复。像半自回归这样的先前解决方案通过将窗口分割成块来解决这个问题，但这会牺牲速度和双向性，消除了扩散模型的主要优势。为了克服这个问题，我们提出了卷积解码（Conv），这是一种基于归一化的方法，可以在没有硬分割的情况下缩小解码窗口，从而提高流畅性和灵活性。此外，我们还引入了基于拒绝规则的微调（R2FT），这是一种事后训练方案，可以更好地使远离上下文位置的 token 对齐。我们的方法在开放式生成基准（例如 AlpacaEval）上，在扩散语言模型基线中取得了最先进的结果，步长明显低于先前的工作，展示了速度和质量的改进。|
|**2025-09-18**|[Understand Before You Generate: Self-Guided Training for Autoregressive Image Generation](http://arxiv.org/abs/2509.15185)|null|近期研究表明，高质量的视觉表征在图像生成中至关重要，并指出了生成模型在图像理解方面的局限性。自回归模型作为一种最初为自然语言设计的生成范式，也面临着类似的挑战。在本研究中，我们首次系统地研究了将下一个词预测范式应用于视觉领域的机制。我们确定了三个阻碍高层视觉语义学习的关键属性：局部和条件依赖性、步间语义不一致性以及空间不变性缺陷。我们表明，通过在训练中引入自监督目标，可以有效地解决这些问题，从而形成一种新颖的训练框架，即自回归模型的自指导训练（ST-AR）。ST-AR无需依赖预训练的表征模型，显著增强了自回归模型的图像理解能力，并提高了生成质量。具体而言，在保持相同采样策略的情况下，ST-AR使LlamaGen-L的FID提高了约42%，LlamaGen-XL的FID提高了49%。|
|**2025-09-18**|[A Race Bias Free Face Aging Model for Reliable Kinship Verification](http://arxiv.org/abs/2509.15177)|null|亲属关系验证中的年龄差距是指父母和子女照片之间的时间差。此外，他们相同年龄的照片通常不可用，并且人脸年龄增长模型存在种族偏见，这会影响照片的相似度。因此，我们提出了一种人脸年龄增长GAN模型RA-GAN，它包含两个新模块：RACEpSp和特征混合器，以生成无种族偏见的图像。无偏见的合成照片用于亲属关系验证，以研究验证相同年龄父母子女图像的结果。实验表明，在所有年龄组中，我们的RA-GAN在种族准确性方面平均比SAM-GAN高13.14%，在60岁以上年龄组中比CUSP-GAN高9.1%。此外，在所有年龄组中，RA-GAN比SAM-GAN和CUSP-GAN更能保留被摄者的身份。此外，我们证明了将KinFaceW-I和KinFaceW-II数据集中的父母和子女图像转换为相同年龄可以提高所有年龄组的验证准确性。在KinFaceW-I上，使用RA-GAN在父子、父女、母子和母女关系上的准确性分别提高了5.22、5.12、1.63和0.41。此外，在KinFaceW-II上，父女、父子和母子关系上的准确性分别为2.9、0.39和1.6。代码可在Github上获取：https://github.com/bardiya2254kariminia/An-Age-Transformation-whitout-racial-bias-for-Kinship-verification|
|**2025-09-18**|[Watermarking and Anomaly Detection in Machine Learning Models for LORA RF Fingerprinting](http://arxiv.org/abs/2509.15170)|null|射频指纹识别（RFFI）通过模拟电路的微小差异来区分无线设备，从而避免了繁重的加密认证。虽然基于频谱图的深度学习提高了准确性，但模型仍然容易受到复制、篡改和规避的攻击。我们提出了一个更强的 RFFI 系统，结合了用于所有权证明的水印技术和用于检测可疑输入的异常检测。使用基于 Log-Mel 频谱图的 ResNet-34 模型，我们嵌入了三种水印：一个简单的触发器、一个经过对抗训练的、对噪声和滤波具有鲁棒性的触发器，以及一个隐藏的梯度/权重签名。一个具有 Kullback-Leibler (KL) 预热和 free-bits 标志的卷积变分自编码器（VAE）可以检测偏离分布的查询。在 LoRa 数据集上，我们的系统实现了 94.6% 的准确率、98% 的水印成功率和 0.94 的 AUROC，提供了可验证、防篡改的认证。|
|**2025-09-18**|[AnoF-Diff: One-Step Diffusion-Based Anomaly Detection for Forceful Tool Use](http://arxiv.org/abs/2509.15153)|null|多元时间序列异常检测对于识别意外事件至关重要，在机器学习领域已研究数十年。然而，将这些方法直接应用于强制性工具使用任务的数据具有挑战性，因为现实世界中的流式传感器数据往往固有地带有噪声，表现出非平稳行为，并且在不同任务和工具之间存在差异。为了应对这些挑战，我们提出了一种基于扩散模型的方法 AnoF-Diff，用于从时间序列数据中提取力-扭矩特征，并利用力-扭矩特征来检测异常。我们在四项强制性工具使用任务上，根据 F1 分数和接收者操作特征曲线下面积 (AUROC) 将我们的方法与其他最先进的方法进行了比较，结果表明我们的方法性能更好，并且对噪声数据集更具鲁棒性。我们还提出了一种基于一步扩散的并行异常分数评估方法，并演示了如何在多项强制性工具使用实验中将我们的方法用于在线异常检测。|
|**2025-09-18**|[WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance](http://arxiv.org/abs/2509.15130)|null|近期视频扩散模型因其丰富的潜在世界先验，在空间智能任务中展现出巨大潜力。然而，其有限的可控性和几何不一致性阻碍了这一潜力的发挥，导致其强大的先验知识与其在3D/4D任务中的实际应用之间存在差距。因此，当前的方法通常依赖于重新训练或微调，这存在降级预训练知识的风险并带来高昂的计算成本。为解决此问题，我们提出了WorldForge，一个无需训练、在推理时运行的框架，由三个紧密集成的模块组成。步内递归细化在推理过程中引入递归细化机制，在每个去噪步骤内反复优化网络预测，以实现精确的轨迹注入。流门控潜在融合利用光流相似性在潜在空间中分离运动和外观，并将轨迹引导选择性地注入到与运动相关的通道中。双路径自校正引导通过比较引导和未引导的去噪路径，自适应地校正由噪声或错位的结构信号引起的轨迹漂移。这些组件共同实现了在不进行训练的情况下注入细粒度、与轨迹对齐的引导，同时实现了精确的运动控制和照片级真实的内容生成。在各种基准测试上的大量实验验证了我们方法在真实感、轨迹一致性和视觉保真度方面的优越性。这项工作引入了一种新颖的可插拔式可控视频合成范式，为利用生成先验进行空间智能提供了新视角。|
|**2025-09-18**|[Learning Mechanistic Subtypes of Neurodegeneration with a Physics-Informed Variational Autoencoder Mixture Model](http://arxiv.org/abs/2509.15124)|null|神经退行性疾病潜在机制的建模需要能够从稀疏、高维神经影像数据中捕捉异质性和空间变化动力学的方法。将基于偏微分方程 (PDE) 的物理知识与机器学习相结合，可以比经典数值方法提供更强的可解释性和实用性。然而，当前集成了物理知识的机器学习方法仅限于考虑单个 PDE，这严重限制了它们在多种机制负责不同亚群（即亚型）的疾病中的应用，并加剧了模型误设和退化问题。在此，我们提出了一种深度生成模型，用于学习由基于物理的 PDE 控制的潜在动态模型混合体，超越了假设单一 PDE 结构的传统方法。我们的方法将反应-扩散 PDE 集成到变分自编码器 (VAE) 混合模型框架中，支持从神经影像数据中推断可解释的潜在变量（例如扩散率和反应速率）的亚型。我们在合成基准上评估了我们的方法，并证明了其从正电子发射断层扫描 (PET) 数据中揭示阿尔茨海默病进展的机制亚型的潜力。|

